2025-05-20 11:26:25 - INFO - saving to ./results/vgg_cifar10_binary
2025-05-20 11:26:25 - DEBUG - run arguments: Namespace(results_dir='./results', save='vgg_cifar10_binary', dataset='cifar10', model='vgg_cifar10_binary', input_size=None, model_config='', type='torch.cuda.FloatTensor', gpus='0', workers=8, epochs=100, start_epoch=0, batch_size=256, optimizer='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001, print_freq=10, resume='', evaluate=None)
2025-05-20 11:26:25 - INFO - creating model vgg_cifar10_binary
2025-05-20 11:26:25 - INFO - created model with configuration: {'input_size': None, 'dataset': 'cifar10'}
2025-05-20 11:26:25 - INFO - number of parameters: 10420874
2025-05-20 11:26:44 - INFO - training regime: {0: {'optimizer': 'Adam', 'betas': (0.9, 0.999), 'lr': 0.005}, 40: {'lr': 0.001}, 80: {'lr': 0.0005}, 100: {'lr': 0.0001}, 120: {'lr': 5e-05}, 140: {'lr': 1e-05}}
2025-05-20 11:26:44 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:26:44 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:26:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:26:57 - INFO - TRAINING - Epoch: [0][0/196]	Time 12.137 (12.137)	Data 0.848 (0.848)	Loss 2.7432 (2.7432)	Prec@1 10.156 (10.156)	Prec@5 50.391 (50.391)
2025-05-20 11:26:58 - INFO - TRAINING - Epoch: [0][10/196]	Time 0.145 (1.225)	Data 0.000 (0.081)	Loss 2.0144 (2.2478)	Prec@1 28.125 (19.602)	Prec@5 78.906 (69.886)
2025-05-20 11:26:59 - INFO - TRAINING - Epoch: [0][20/196]	Time 0.129 (0.703)	Data 0.000 (0.044)	Loss 2.0239 (2.1395)	Prec@1 28.125 (23.772)	Prec@5 78.125 (73.847)
2025-05-20 11:27:00 - INFO - TRAINING - Epoch: [0][30/196]	Time 0.129 (0.518)	Data 0.000 (0.030)	Loss 1.8825 (2.0701)	Prec@1 32.031 (25.932)	Prec@5 82.031 (76.222)
2025-05-20 11:27:02 - INFO - TRAINING - Epoch: [0][40/196]	Time 0.129 (0.423)	Data 0.000 (0.024)	Loss 1.7628 (2.0193)	Prec@1 33.594 (27.172)	Prec@5 88.672 (78.201)
2025-05-20 11:27:03 - INFO - TRAINING - Epoch: [0][50/196]	Time 0.130 (0.366)	Data 0.000 (0.020)	Loss 1.8541 (1.9844)	Prec@1 32.812 (28.523)	Prec@5 86.328 (79.343)
2025-05-20 11:27:04 - INFO - TRAINING - Epoch: [0][60/196]	Time 0.130 (0.327)	Data 0.007 (0.017)	Loss 1.8142 (1.9512)	Prec@1 33.594 (29.809)	Prec@5 85.156 (80.520)
2025-05-20 11:27:06 - INFO - TRAINING - Epoch: [0][70/196]	Time 0.129 (0.299)	Data 0.011 (0.015)	Loss 1.7536 (1.9251)	Prec@1 37.500 (30.672)	Prec@5 84.375 (81.421)
2025-05-20 11:27:07 - INFO - TRAINING - Epoch: [0][80/196]	Time 0.129 (0.278)	Data 0.000 (0.014)	Loss 1.7751 (1.8975)	Prec@1 34.766 (31.694)	Prec@5 87.500 (82.292)
2025-05-20 11:27:08 - INFO - TRAINING - Epoch: [0][90/196]	Time 0.124 (0.263)	Data 0.000 (0.013)	Loss 1.7295 (1.8751)	Prec@1 34.375 (32.473)	Prec@5 90.625 (82.976)
2025-05-20 11:27:10 - INFO - TRAINING - Epoch: [0][100/196]	Time 0.184 (0.252)	Data 0.008 (0.012)	Loss 1.5489 (1.8501)	Prec@1 44.531 (33.567)	Prec@5 92.969 (83.675)
2025-05-20 11:27:12 - INFO - TRAINING - Epoch: [0][110/196]	Time 0.137 (0.245)	Data 0.000 (0.012)	Loss 1.6808 (1.8288)	Prec@1 39.062 (34.488)	Prec@5 87.891 (84.259)
2025-05-20 11:27:13 - INFO - TRAINING - Epoch: [0][120/196]	Time 0.143 (0.237)	Data 0.016 (0.012)	Loss 1.5576 (1.8090)	Prec@1 45.312 (35.340)	Prec@5 90.625 (84.740)
2025-05-20 11:27:14 - INFO - TRAINING - Epoch: [0][130/196]	Time 0.129 (0.229)	Data 0.000 (0.012)	Loss 1.6114 (1.7929)	Prec@1 40.234 (35.958)	Prec@5 91.406 (85.138)
2025-05-20 11:27:16 - INFO - TRAINING - Epoch: [0][140/196]	Time 0.129 (0.222)	Data 0.000 (0.011)	Loss 1.5833 (1.7773)	Prec@1 44.141 (36.708)	Prec@5 90.625 (85.544)
2025-05-20 11:27:17 - INFO - TRAINING - Epoch: [0][150/196]	Time 0.130 (0.216)	Data 0.000 (0.010)	Loss 1.5742 (1.7619)	Prec@1 46.875 (37.355)	Prec@5 91.016 (85.919)
2025-05-20 11:27:18 - INFO - TRAINING - Epoch: [0][160/196]	Time 0.129 (0.211)	Data 0.000 (0.010)	Loss 1.4522 (1.7470)	Prec@1 54.297 (38.039)	Prec@5 92.578 (86.280)
2025-05-20 11:27:20 - INFO - TRAINING - Epoch: [0][170/196]	Time 0.129 (0.206)	Data 0.000 (0.010)	Loss 1.5248 (1.7373)	Prec@1 46.484 (38.421)	Prec@5 92.578 (86.497)
2025-05-20 11:27:21 - INFO - TRAINING - Epoch: [0][180/196]	Time 0.128 (0.202)	Data 0.000 (0.009)	Loss 1.5014 (1.7270)	Prec@1 46.875 (38.829)	Prec@5 93.359 (86.745)
2025-05-20 11:27:22 - INFO - TRAINING - Epoch: [0][190/196]	Time 0.132 (0.198)	Data 0.000 (0.009)	Loss 1.4115 (1.7148)	Prec@1 49.609 (39.320)	Prec@5 95.312 (87.015)
2025-05-20 11:27:27 - INFO - EVALUATING - Epoch: [0][0/40]	Time 0.828 (0.828)	Data 0.724 (0.724)	Loss 1.4664 (1.4664)	Prec@1 48.828 (48.828)	Prec@5 90.625 (90.625)
2025-05-20 11:27:27 - INFO - EVALUATING - Epoch: [0][10/40]	Time 0.074 (0.144)	Data 0.008 (0.069)	Loss 1.4654 (1.4739)	Prec@1 49.219 (49.538)	Prec@5 92.188 (91.761)
2025-05-20 11:27:28 - INFO - EVALUATING - Epoch: [0][20/40]	Time 0.079 (0.112)	Data 0.002 (0.039)	Loss 1.4749 (1.4629)	Prec@1 46.484 (49.926)	Prec@5 93.750 (91.871)
2025-05-20 11:27:29 - INFO - EVALUATING - Epoch: [0][30/40]	Time 0.068 (0.099)	Data 0.000 (0.027)	Loss 1.4400 (1.4647)	Prec@1 50.391 (49.572)	Prec@5 92.188 (92.112)
2025-05-20 11:27:30 - INFO - 
 Epoch: 1	Training Loss 1.7105 	Training Prec@1 39.502 	Training Prec@5 87.118 	Validation Loss 1.4651 	Validation Prec@1 49.610 	Validation Prec@5 92.230 

2025-05-20 11:27:30 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:27:30 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:27:30 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:27:31 - INFO - TRAINING - Epoch: [1][0/196]	Time 0.947 (0.947)	Data 0.852 (0.852)	Loss 1.5393 (1.5393)	Prec@1 45.703 (45.703)	Prec@5 90.625 (90.625)
2025-05-20 11:27:32 - INFO - TRAINING - Epoch: [1][10/196]	Time 0.145 (0.217)	Data 0.000 (0.083)	Loss 1.9221 (1.8587)	Prec@1 34.766 (34.197)	Prec@5 81.250 (82.812)
2025-05-20 11:27:34 - INFO - TRAINING - Epoch: [1][20/196]	Time 0.135 (0.181)	Data 0.000 (0.044)	Loss 1.7895 (1.8164)	Prec@1 35.547 (35.528)	Prec@5 85.938 (84.152)
2025-05-20 11:27:35 - INFO - TRAINING - Epoch: [1][30/196]	Time 0.158 (0.169)	Data 0.000 (0.033)	Loss 1.5675 (1.7638)	Prec@1 44.141 (37.538)	Prec@5 91.797 (85.811)
2025-05-20 11:27:37 - INFO - TRAINING - Epoch: [1][40/196]	Time 0.132 (0.164)	Data 0.020 (0.027)	Loss 1.5792 (1.7292)	Prec@1 46.484 (38.939)	Prec@5 91.016 (86.614)
2025-05-20 11:27:38 - INFO - TRAINING - Epoch: [1][50/196]	Time 0.130 (0.158)	Data 0.000 (0.022)	Loss 1.5414 (1.6940)	Prec@1 45.312 (40.288)	Prec@5 90.625 (87.370)
2025-05-20 11:27:39 - INFO - TRAINING - Epoch: [1][60/196]	Time 0.131 (0.154)	Data 0.000 (0.019)	Loss 1.6077 (1.6675)	Prec@1 45.312 (41.425)	Prec@5 89.062 (88.019)
2025-05-20 11:27:41 - INFO - TRAINING - Epoch: [1][70/196]	Time 0.130 (0.150)	Data 0.000 (0.016)	Loss 1.4717 (1.6468)	Prec@1 47.266 (42.199)	Prec@5 91.797 (88.551)
2025-05-20 11:27:42 - INFO - TRAINING - Epoch: [1][80/196]	Time 0.130 (0.148)	Data 0.007 (0.015)	Loss 1.5183 (1.6289)	Prec@1 44.922 (43.003)	Prec@5 90.625 (88.817)
2025-05-20 11:27:43 - INFO - TRAINING - Epoch: [1][90/196]	Time 0.130 (0.146)	Data 0.007 (0.013)	Loss 1.4715 (1.6107)	Prec@1 50.000 (43.789)	Prec@5 91.797 (89.161)
2025-05-20 11:27:45 - INFO - TRAINING - Epoch: [1][100/196]	Time 0.131 (0.145)	Data 0.012 (0.012)	Loss 1.3442 (1.5943)	Prec@1 53.516 (44.346)	Prec@5 94.922 (89.476)
2025-05-20 11:27:46 - INFO - TRAINING - Epoch: [1][110/196]	Time 0.129 (0.143)	Data 0.000 (0.012)	Loss 1.3163 (1.5773)	Prec@1 57.422 (45.020)	Prec@5 92.578 (89.731)
2025-05-20 11:27:47 - INFO - TRAINING - Epoch: [1][120/196]	Time 0.151 (0.143)	Data 0.000 (0.011)	Loss 1.3650 (1.5606)	Prec@1 51.172 (45.719)	Prec@5 93.359 (90.037)
2025-05-20 11:27:49 - INFO - TRAINING - Epoch: [1][130/196]	Time 0.145 (0.143)	Data 0.005 (0.011)	Loss 1.3270 (1.5462)	Prec@1 55.469 (46.359)	Prec@5 92.578 (90.306)
2025-05-20 11:27:50 - INFO - TRAINING - Epoch: [1][140/196]	Time 0.136 (0.143)	Data 0.007 (0.011)	Loss 1.3368 (1.5318)	Prec@1 55.078 (46.936)	Prec@5 94.141 (90.567)
2025-05-20 11:27:52 - INFO - TRAINING - Epoch: [1][150/196]	Time 0.132 (0.143)	Data 0.008 (0.010)	Loss 1.2958 (1.5160)	Prec@1 64.844 (47.667)	Prec@5 93.359 (90.827)
2025-05-20 11:27:53 - INFO - TRAINING - Epoch: [1][160/196]	Time 0.134 (0.142)	Data 0.000 (0.010)	Loss 1.4042 (1.5045)	Prec@1 52.344 (48.202)	Prec@5 93.359 (91.006)
2025-05-20 11:27:54 - INFO - TRAINING - Epoch: [1][170/196]	Time 0.143 (0.142)	Data 0.000 (0.009)	Loss 1.4682 (1.4935)	Prec@1 52.734 (48.721)	Prec@5 91.016 (91.182)
2025-05-20 11:27:56 - INFO - TRAINING - Epoch: [1][180/196]	Time 0.130 (0.141)	Data 0.000 (0.009)	Loss 1.3492 (1.4837)	Prec@1 55.469 (49.201)	Prec@5 92.578 (91.324)
2025-05-20 11:27:57 - INFO - TRAINING - Epoch: [1][190/196]	Time 0.130 (0.140)	Data 0.000 (0.008)	Loss 1.2861 (1.4717)	Prec@1 61.328 (49.744)	Prec@5 94.922 (91.513)
2025-05-20 11:27:58 - INFO - EVALUATING - Epoch: [1][0/40]	Time 0.480 (0.480)	Data 0.407 (0.407)	Loss 1.2689 (1.2689)	Prec@1 59.375 (59.375)	Prec@5 93.750 (93.750)
2025-05-20 11:27:59 - INFO - EVALUATING - Epoch: [1][10/40]	Time 0.079 (0.148)	Data 0.002 (0.073)	Loss 1.2623 (1.2080)	Prec@1 58.594 (61.222)	Prec@5 95.312 (95.241)
2025-05-20 11:28:00 - INFO - EVALUATING - Epoch: [1][20/40]	Time 0.072 (0.114)	Data 0.003 (0.039)	Loss 1.2385 (1.1956)	Prec@1 58.984 (61.682)	Prec@5 94.531 (95.238)
2025-05-20 11:28:01 - INFO - EVALUATING - Epoch: [1][30/40]	Time 0.081 (0.103)	Data 0.000 (0.027)	Loss 1.2608 (1.2018)	Prec@1 59.375 (61.391)	Prec@5 93.750 (95.262)
2025-05-20 11:28:02 - INFO - 
 Epoch: 2	Training Loss 1.4684 	Training Prec@1 49.872 	Training Prec@5 91.564 	Validation Loss 1.2068 	Validation Prec@1 60.920 	Validation Prec@5 95.350 

2025-05-20 11:28:02 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:28:02 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:28:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:28:03 - INFO - TRAINING - Epoch: [2][0/196]	Time 1.062 (1.062)	Data 0.948 (0.948)	Loss 1.2437 (1.2437)	Prec@1 58.203 (58.203)	Prec@5 95.312 (95.312)
2025-05-20 11:28:04 - INFO - TRAINING - Epoch: [2][10/196]	Time 0.140 (0.231)	Data 0.009 (0.103)	Loss 1.2972 (1.4117)	Prec@1 56.250 (53.054)	Prec@5 96.875 (93.146)
2025-05-20 11:28:06 - INFO - TRAINING - Epoch: [2][20/196]	Time 0.131 (0.187)	Data 0.000 (0.057)	Loss 1.2895 (1.3774)	Prec@1 60.938 (54.167)	Prec@5 96.094 (93.434)
2025-05-20 11:28:07 - INFO - TRAINING - Epoch: [2][30/196]	Time 0.133 (0.170)	Data 0.006 (0.039)	Loss 1.3534 (1.3645)	Prec@1 56.250 (54.511)	Prec@5 91.016 (93.372)
2025-05-20 11:28:08 - INFO - TRAINING - Epoch: [2][40/196]	Time 0.131 (0.161)	Data 0.000 (0.030)	Loss 1.2353 (1.3456)	Prec@1 59.766 (55.469)	Prec@5 96.094 (93.683)
2025-05-20 11:28:10 - INFO - TRAINING - Epoch: [2][50/196]	Time 0.139 (0.155)	Data 0.001 (0.025)	Loss 1.2455 (1.3269)	Prec@1 57.422 (56.242)	Prec@5 95.703 (93.903)
2025-05-20 11:28:11 - INFO - TRAINING - Epoch: [2][60/196]	Time 0.132 (0.152)	Data 0.000 (0.021)	Loss 1.1570 (1.3097)	Prec@1 64.062 (56.999)	Prec@5 96.875 (94.160)
2025-05-20 11:28:12 - INFO - TRAINING - Epoch: [2][70/196]	Time 0.131 (0.149)	Data 0.000 (0.019)	Loss 1.3128 (1.3001)	Prec@1 55.469 (57.350)	Prec@5 92.969 (94.207)
2025-05-20 11:28:14 - INFO - TRAINING - Epoch: [2][80/196]	Time 0.148 (0.149)	Data 0.012 (0.017)	Loss 1.2009 (1.2908)	Prec@1 61.719 (57.822)	Prec@5 94.922 (94.189)
2025-05-20 11:28:15 - INFO - TRAINING - Epoch: [2][90/196]	Time 0.144 (0.148)	Data 0.000 (0.016)	Loss 1.3189 (1.2825)	Prec@1 55.078 (58.169)	Prec@5 95.312 (94.342)
2025-05-20 11:28:17 - INFO - TRAINING - Epoch: [2][100/196]	Time 0.132 (0.147)	Data 0.000 (0.015)	Loss 1.1706 (1.2702)	Prec@1 61.328 (58.613)	Prec@5 96.484 (94.469)
2025-05-20 11:28:18 - INFO - TRAINING - Epoch: [2][110/196]	Time 0.133 (0.146)	Data 0.000 (0.014)	Loss 1.2238 (1.2637)	Prec@1 59.375 (58.861)	Prec@5 94.531 (94.538)
2025-05-20 11:28:19 - INFO - TRAINING - Epoch: [2][120/196]	Time 0.134 (0.145)	Data 0.000 (0.013)	Loss 1.1498 (1.2552)	Prec@1 63.281 (59.123)	Prec@5 96.094 (94.670)
2025-05-20 11:28:21 - INFO - TRAINING - Epoch: [2][130/196]	Time 0.132 (0.144)	Data 0.006 (0.012)	Loss 1.1925 (1.2475)	Prec@1 61.719 (59.441)	Prec@5 95.312 (94.731)
2025-05-20 11:28:22 - INFO - TRAINING - Epoch: [2][140/196]	Time 0.134 (0.143)	Data 0.000 (0.011)	Loss 1.1511 (1.2400)	Prec@1 60.938 (59.757)	Prec@5 95.703 (94.792)
2025-05-20 11:28:23 - INFO - TRAINING - Epoch: [2][150/196]	Time 0.133 (0.143)	Data 0.000 (0.011)	Loss 1.1097 (1.2371)	Prec@1 65.625 (59.882)	Prec@5 97.266 (94.831)
2025-05-20 11:28:25 - INFO - TRAINING - Epoch: [2][160/196]	Time 0.136 (0.142)	Data 0.008 (0.010)	Loss 1.1535 (1.2309)	Prec@1 63.672 (60.105)	Prec@5 96.094 (94.929)
2025-05-20 11:28:26 - INFO - TRAINING - Epoch: [2][170/196]	Time 0.151 (0.142)	Data 0.000 (0.010)	Loss 1.2460 (1.2272)	Prec@1 57.031 (60.284)	Prec@5 94.141 (94.977)
2025-05-20 11:28:28 - INFO - TRAINING - Epoch: [2][180/196]	Time 0.139 (0.142)	Data 0.000 (0.010)	Loss 1.1940 (1.2226)	Prec@1 60.156 (60.486)	Prec@5 96.094 (95.013)
2025-05-20 11:28:29 - INFO - TRAINING - Epoch: [2][190/196]	Time 0.134 (0.142)	Data 0.000 (0.009)	Loss 1.1047 (1.2174)	Prec@1 65.625 (60.735)	Prec@5 96.484 (95.092)
2025-05-20 11:28:30 - INFO - EVALUATING - Epoch: [2][0/40]	Time 0.726 (0.726)	Data 0.657 (0.657)	Loss 1.0811 (1.0811)	Prec@1 65.234 (65.234)	Prec@5 97.266 (97.266)
2025-05-20 11:28:31 - INFO - EVALUATING - Epoch: [2][10/40]	Time 0.078 (0.146)	Data 0.003 (0.072)	Loss 1.1171 (1.0760)	Prec@1 64.453 (65.767)	Prec@5 96.875 (96.804)
2025-05-20 11:28:32 - INFO - EVALUATING - Epoch: [2][20/40]	Time 0.083 (0.114)	Data 0.011 (0.040)	Loss 1.0832 (1.0656)	Prec@1 65.234 (67.132)	Prec@5 97.656 (96.708)
2025-05-20 11:28:33 - INFO - EVALUATING - Epoch: [2][30/40]	Time 0.070 (0.101)	Data 0.000 (0.028)	Loss 1.0808 (1.0689)	Prec@1 65.625 (66.935)	Prec@5 97.266 (96.749)
2025-05-20 11:28:34 - INFO - 
 Epoch: 3	Training Loss 1.2150 	Training Prec@1 60.820 	Training Prec@5 95.116 	Validation Loss 1.0737 	Validation Prec@1 66.590 	Validation Prec@5 96.730 

2025-05-20 11:28:34 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:28:34 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:28:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:28:34 - INFO - TRAINING - Epoch: [3][0/196]	Time 0.960 (0.960)	Data 0.846 (0.846)	Loss 1.0673 (1.0673)	Prec@1 68.359 (68.359)	Prec@5 97.266 (97.266)
2025-05-20 11:28:36 - INFO - TRAINING - Epoch: [3][10/196]	Time 0.146 (0.219)	Data 0.008 (0.082)	Loss 1.1727 (1.1716)	Prec@1 61.719 (62.038)	Prec@5 94.922 (95.597)
2025-05-20 11:28:37 - INFO - TRAINING - Epoch: [3][20/196]	Time 0.133 (0.180)	Data 0.007 (0.046)	Loss 1.1406 (1.1583)	Prec@1 63.672 (63.058)	Prec@5 95.312 (95.666)
2025-05-20 11:28:39 - INFO - TRAINING - Epoch: [3][30/196]	Time 0.142 (0.166)	Data 0.000 (0.032)	Loss 1.0577 (1.1510)	Prec@1 69.141 (63.508)	Prec@5 97.266 (95.665)
2025-05-20 11:28:40 - INFO - TRAINING - Epoch: [3][40/196]	Time 0.157 (0.161)	Data 0.012 (0.025)	Loss 1.1177 (1.1422)	Prec@1 65.234 (63.739)	Prec@5 97.266 (95.770)
2025-05-20 11:28:42 - INFO - TRAINING - Epoch: [3][50/196]	Time 0.151 (0.158)	Data 0.009 (0.022)	Loss 1.0558 (1.1345)	Prec@1 67.969 (64.085)	Prec@5 97.266 (95.703)
2025-05-20 11:28:43 - INFO - TRAINING - Epoch: [3][60/196]	Time 0.134 (0.155)	Data 0.009 (0.019)	Loss 1.1396 (1.1237)	Prec@1 61.719 (64.517)	Prec@5 94.922 (95.767)
2025-05-20 11:28:44 - INFO - TRAINING - Epoch: [3][70/196]	Time 0.133 (0.152)	Data 0.003 (0.016)	Loss 1.1482 (1.1161)	Prec@1 60.938 (64.893)	Prec@5 96.094 (95.835)
2025-05-20 11:28:46 - INFO - TRAINING - Epoch: [3][80/196]	Time 0.135 (0.150)	Data 0.000 (0.015)	Loss 1.1305 (1.1146)	Prec@1 66.406 (64.931)	Prec@5 95.312 (95.824)
2025-05-20 11:28:47 - INFO - TRAINING - Epoch: [3][90/196]	Time 0.135 (0.148)	Data 0.000 (0.013)	Loss 1.0400 (1.1109)	Prec@1 70.312 (65.239)	Prec@5 96.484 (95.832)
2025-05-20 11:28:48 - INFO - TRAINING - Epoch: [3][100/196]	Time 0.134 (0.147)	Data 0.008 (0.012)	Loss 1.1044 (1.1075)	Prec@1 64.453 (65.393)	Prec@5 97.266 (95.889)
2025-05-20 11:28:50 - INFO - TRAINING - Epoch: [3][110/196]	Time 0.135 (0.145)	Data 0.000 (0.011)	Loss 1.0342 (1.1050)	Prec@1 69.531 (65.460)	Prec@5 96.484 (95.949)
2025-05-20 11:28:51 - INFO - TRAINING - Epoch: [3][120/196]	Time 0.134 (0.145)	Data 0.000 (0.010)	Loss 1.1256 (1.1004)	Prec@1 61.328 (65.699)	Prec@5 96.094 (96.003)
2025-05-20 11:28:52 - INFO - TRAINING - Epoch: [3][130/196]	Time 0.133 (0.144)	Data 0.000 (0.010)	Loss 1.1314 (1.0986)	Prec@1 65.625 (65.747)	Prec@5 96.484 (96.067)
2025-05-20 11:28:54 - INFO - TRAINING - Epoch: [3][140/196]	Time 0.148 (0.144)	Data 0.003 (0.009)	Loss 1.0835 (1.0972)	Prec@1 65.234 (65.805)	Prec@5 97.656 (96.091)
2025-05-20 11:28:55 - INFO - TRAINING - Epoch: [3][150/196]	Time 0.147 (0.145)	Data 0.015 (0.010)	Loss 1.0668 (1.0933)	Prec@1 63.672 (65.928)	Prec@5 95.312 (96.151)
2025-05-20 11:28:57 - INFO - TRAINING - Epoch: [3][160/196]	Time 0.134 (0.144)	Data 0.000 (0.009)	Loss 1.0438 (1.0934)	Prec@1 69.922 (65.909)	Prec@5 95.312 (96.135)
2025-05-20 11:28:58 - INFO - TRAINING - Epoch: [3][170/196]	Time 0.135 (0.144)	Data 0.000 (0.009)	Loss 1.1556 (1.0921)	Prec@1 63.672 (65.977)	Prec@5 95.312 (96.155)
2025-05-20 11:28:59 - INFO - TRAINING - Epoch: [3][180/196]	Time 0.133 (0.143)	Data 0.000 (0.008)	Loss 1.0895 (1.0905)	Prec@1 66.016 (66.065)	Prec@5 98.047 (96.167)
2025-05-20 11:29:01 - INFO - TRAINING - Epoch: [3][190/196]	Time 0.131 (0.143)	Data 0.000 (0.008)	Loss 1.0682 (1.0887)	Prec@1 65.625 (66.153)	Prec@5 98.438 (96.204)
2025-05-20 11:29:02 - INFO - EVALUATING - Epoch: [3][0/40]	Time 0.925 (0.925)	Data 0.856 (0.856)	Loss 1.0096 (1.0096)	Prec@1 70.312 (70.312)	Prec@5 95.703 (95.703)
2025-05-20 11:29:03 - INFO - EVALUATING - Epoch: [3][10/40]	Time 0.079 (0.157)	Data 0.004 (0.083)	Loss 0.9694 (0.9904)	Prec@1 73.047 (71.058)	Prec@5 98.047 (97.017)
2025-05-20 11:29:04 - INFO - EVALUATING - Epoch: [3][20/40]	Time 0.077 (0.120)	Data 0.004 (0.045)	Loss 1.0294 (0.9817)	Prec@1 67.969 (70.703)	Prec@5 96.484 (96.968)
2025-05-20 11:29:05 - INFO - EVALUATING - Epoch: [3][30/40]	Time 0.071 (0.104)	Data 0.000 (0.031)	Loss 1.0276 (0.9837)	Prec@1 67.969 (70.565)	Prec@5 95.312 (97.064)
2025-05-20 11:29:06 - INFO - 
 Epoch: 4	Training Loss 1.0874 	Training Prec@1 66.200 	Training Prec@5 96.198 	Validation Loss 0.9838 	Validation Prec@1 70.640 	Validation Prec@5 97.020 

2025-05-20 11:29:06 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:29:06 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:29:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:29:07 - INFO - TRAINING - Epoch: [4][0/196]	Time 1.681 (1.681)	Data 1.547 (1.547)	Loss 1.0826 (1.0826)	Prec@1 66.016 (66.016)	Prec@5 97.266 (97.266)
2025-05-20 11:29:09 - INFO - TRAINING - Epoch: [4][10/196]	Time 0.145 (0.286)	Data 0.012 (0.147)	Loss 1.0600 (1.1193)	Prec@1 67.969 (64.169)	Prec@5 97.266 (95.916)
2025-05-20 11:29:10 - INFO - TRAINING - Epoch: [4][20/196]	Time 0.133 (0.214)	Data 0.005 (0.078)	Loss 1.0435 (1.0972)	Prec@1 67.578 (65.495)	Prec@5 97.656 (96.057)
2025-05-20 11:29:12 - INFO - TRAINING - Epoch: [4][30/196]	Time 0.132 (0.188)	Data 0.000 (0.053)	Loss 0.9166 (1.0730)	Prec@1 73.047 (66.608)	Prec@5 97.656 (96.283)
2025-05-20 11:29:13 - INFO - TRAINING - Epoch: [4][40/196]	Time 0.136 (0.175)	Data 0.004 (0.041)	Loss 0.9517 (1.0621)	Prec@1 74.219 (67.026)	Prec@5 96.875 (96.332)
2025-05-20 11:29:14 - INFO - TRAINING - Epoch: [4][50/196]	Time 0.133 (0.167)	Data 0.000 (0.033)	Loss 1.0270 (1.0499)	Prec@1 68.359 (67.578)	Prec@5 97.656 (96.507)
2025-05-20 11:29:16 - INFO - TRAINING - Epoch: [4][60/196]	Time 0.133 (0.161)	Data 0.007 (0.028)	Loss 1.0427 (1.0449)	Prec@1 66.797 (67.700)	Prec@5 96.484 (96.587)
2025-05-20 11:29:17 - INFO - TRAINING - Epoch: [4][70/196]	Time 0.134 (0.157)	Data 0.000 (0.024)	Loss 0.9618 (1.0427)	Prec@1 71.484 (67.837)	Prec@5 98.438 (96.682)
2025-05-20 11:29:18 - INFO - TRAINING - Epoch: [4][80/196]	Time 0.145 (0.155)	Data 0.011 (0.022)	Loss 0.8671 (1.0391)	Prec@1 77.344 (68.012)	Prec@5 99.609 (96.769)
2025-05-20 11:29:20 - INFO - TRAINING - Epoch: [4][90/196]	Time 0.148 (0.154)	Data 0.000 (0.020)	Loss 1.0386 (1.0355)	Prec@1 68.359 (68.226)	Prec@5 94.531 (96.751)
2025-05-20 11:29:21 - INFO - TRAINING - Epoch: [4][100/196]	Time 0.136 (0.153)	Data 0.000 (0.019)	Loss 1.0041 (1.0299)	Prec@1 69.141 (68.410)	Prec@5 97.656 (96.805)
2025-05-20 11:29:23 - INFO - TRAINING - Epoch: [4][110/196]	Time 0.135 (0.151)	Data 0.000 (0.018)	Loss 1.0166 (1.0307)	Prec@1 67.188 (68.352)	Prec@5 96.484 (96.784)
2025-05-20 11:29:24 - INFO - TRAINING - Epoch: [4][120/196]	Time 0.134 (0.149)	Data 0.000 (0.016)	Loss 1.1228 (1.0304)	Prec@1 63.281 (68.388)	Prec@5 94.922 (96.778)
2025-05-20 11:29:25 - INFO - TRAINING - Epoch: [4][130/196]	Time 0.128 (0.148)	Data 0.011 (0.015)	Loss 1.0352 (1.0258)	Prec@1 66.797 (68.610)	Prec@5 97.266 (96.836)
2025-05-20 11:29:27 - INFO - TRAINING - Epoch: [4][140/196]	Time 0.134 (0.147)	Data 0.000 (0.014)	Loss 0.9807 (1.0252)	Prec@1 72.656 (68.675)	Prec@5 99.219 (96.831)
2025-05-20 11:29:28 - INFO - TRAINING - Epoch: [4][150/196]	Time 0.134 (0.147)	Data 0.000 (0.014)	Loss 1.0493 (1.0226)	Prec@1 68.359 (68.817)	Prec@5 97.266 (96.865)
2025-05-20 11:29:29 - INFO - TRAINING - Epoch: [4][160/196]	Time 0.134 (0.146)	Data 0.000 (0.013)	Loss 0.8778 (1.0180)	Prec@1 73.828 (69.029)	Prec@5 98.438 (96.902)
2025-05-20 11:29:31 - INFO - TRAINING - Epoch: [4][170/196]	Time 0.127 (0.145)	Data 0.000 (0.012)	Loss 1.0487 (1.0159)	Prec@1 67.578 (69.122)	Prec@5 94.922 (96.896)
2025-05-20 11:29:32 - INFO - TRAINING - Epoch: [4][180/196]	Time 0.140 (0.145)	Data 0.000 (0.012)	Loss 1.0407 (1.0133)	Prec@1 66.406 (69.249)	Prec@5 98.438 (96.918)
2025-05-20 11:29:33 - INFO - TRAINING - Epoch: [4][190/196]	Time 0.133 (0.144)	Data 0.000 (0.011)	Loss 0.9316 (1.0106)	Prec@1 73.047 (69.357)	Prec@5 98.438 (96.924)
2025-05-20 11:29:35 - INFO - EVALUATING - Epoch: [4][0/40]	Time 0.876 (0.876)	Data 0.802 (0.802)	Loss 0.9525 (0.9525)	Prec@1 73.047 (73.047)	Prec@5 98.828 (98.828)
2025-05-20 11:29:36 - INFO - EVALUATING - Epoch: [4][10/40]	Time 0.089 (0.148)	Data 0.004 (0.075)	Loss 0.9243 (0.9435)	Prec@1 73.828 (72.408)	Prec@5 97.656 (97.195)
2025-05-20 11:29:36 - INFO - EVALUATING - Epoch: [4][20/40]	Time 0.071 (0.115)	Data 0.000 (0.041)	Loss 0.9139 (0.9325)	Prec@1 74.219 (72.898)	Prec@5 99.609 (97.154)
2025-05-20 11:29:37 - INFO - EVALUATING - Epoch: [4][30/40]	Time 0.070 (0.102)	Data 0.000 (0.028)	Loss 1.0220 (0.9363)	Prec@1 69.531 (72.568)	Prec@5 95.312 (97.253)
2025-05-20 11:29:38 - INFO - 
 Epoch: 5	Training Loss 1.0090 	Training Prec@1 69.438 	Training Prec@5 96.946 	Validation Loss 0.9394 	Validation Prec@1 72.350 	Validation Prec@5 97.330 

2025-05-20 11:29:38 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:29:38 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:29:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:29:39 - INFO - TRAINING - Epoch: [5][0/196]	Time 0.896 (0.896)	Data 0.802 (0.802)	Loss 1.0225 (1.0225)	Prec@1 69.141 (69.141)	Prec@5 97.266 (97.266)
2025-05-20 11:29:40 - INFO - TRAINING - Epoch: [5][10/196]	Time 0.136 (0.208)	Data 0.000 (0.078)	Loss 1.1153 (1.0087)	Prec@1 65.234 (69.780)	Prec@5 92.969 (97.266)
2025-05-20 11:29:42 - INFO - TRAINING - Epoch: [5][20/196]	Time 0.137 (0.175)	Data 0.001 (0.043)	Loss 0.9308 (0.9916)	Prec@1 70.312 (70.443)	Prec@5 98.438 (97.321)
2025-05-20 11:29:43 - INFO - TRAINING - Epoch: [5][30/196]	Time 0.138 (0.162)	Data 0.002 (0.030)	Loss 1.0622 (0.9938)	Prec@1 66.406 (70.035)	Prec@5 97.266 (97.165)
2025-05-20 11:29:45 - INFO - TRAINING - Epoch: [5][40/196]	Time 0.153 (0.158)	Data 0.012 (0.023)	Loss 0.9893 (0.9907)	Prec@1 73.047 (70.551)	Prec@5 96.094 (97.142)
2025-05-20 11:29:46 - INFO - TRAINING - Epoch: [5][50/196]	Time 0.135 (0.156)	Data 0.000 (0.019)	Loss 0.9260 (0.9885)	Prec@1 74.219 (70.672)	Prec@5 97.656 (97.074)
2025-05-20 11:29:47 - INFO - TRAINING - Epoch: [5][60/196]	Time 0.135 (0.153)	Data 0.000 (0.016)	Loss 0.9262 (0.9771)	Prec@1 73.047 (71.119)	Prec@5 98.438 (97.202)
2025-05-20 11:29:49 - INFO - TRAINING - Epoch: [5][70/196]	Time 0.134 (0.151)	Data 0.000 (0.014)	Loss 0.9162 (0.9728)	Prec@1 74.219 (71.314)	Prec@5 96.484 (97.266)
2025-05-20 11:29:50 - INFO - TRAINING - Epoch: [5][80/196]	Time 0.133 (0.149)	Data 0.000 (0.013)	Loss 0.9835 (0.9694)	Prec@1 71.094 (71.455)	Prec@5 98.828 (97.266)
2025-05-20 11:29:51 - INFO - TRAINING - Epoch: [5][90/196]	Time 0.132 (0.147)	Data 0.000 (0.011)	Loss 0.8470 (0.9666)	Prec@1 76.562 (71.583)	Prec@5 98.438 (97.309)
2025-05-20 11:29:53 - INFO - TRAINING - Epoch: [5][100/196]	Time 0.134 (0.146)	Data 0.000 (0.010)	Loss 0.9998 (0.9663)	Prec@1 67.578 (71.589)	Prec@5 97.266 (97.324)
2025-05-20 11:29:54 - INFO - TRAINING - Epoch: [5][110/196]	Time 0.133 (0.145)	Data 0.007 (0.010)	Loss 0.8521 (0.9679)	Prec@1 75.000 (71.463)	Prec@5 98.047 (97.290)
2025-05-20 11:29:55 - INFO - TRAINING - Epoch: [5][120/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.9914 (0.9666)	Prec@1 68.359 (71.549)	Prec@5 96.484 (97.285)
2025-05-20 11:29:57 - INFO - TRAINING - Epoch: [5][130/196]	Time 0.153 (0.143)	Data 0.011 (0.009)	Loss 0.9101 (0.9638)	Prec@1 71.875 (71.651)	Prec@5 98.047 (97.331)
2025-05-20 11:29:58 - INFO - TRAINING - Epoch: [5][140/196]	Time 0.146 (0.143)	Data 0.007 (0.009)	Loss 0.9530 (0.9623)	Prec@1 70.312 (71.698)	Prec@5 98.047 (97.343)
2025-05-20 11:30:00 - INFO - TRAINING - Epoch: [5][150/196]	Time 0.138 (0.144)	Data 0.003 (0.009)	Loss 0.8851 (0.9613)	Prec@1 73.828 (71.717)	Prec@5 98.047 (97.369)
2025-05-20 11:30:01 - INFO - TRAINING - Epoch: [5][160/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.9158 (0.9608)	Prec@1 75.000 (71.790)	Prec@5 98.438 (97.399)
2025-05-20 11:30:02 - INFO - TRAINING - Epoch: [5][170/196]	Time 0.135 (0.143)	Data 0.000 (0.008)	Loss 0.9601 (0.9596)	Prec@1 69.531 (71.822)	Prec@5 97.266 (97.373)
2025-05-20 11:30:04 - INFO - TRAINING - Epoch: [5][180/196]	Time 0.133 (0.142)	Data 0.000 (0.008)	Loss 0.9724 (0.9572)	Prec@1 71.094 (71.899)	Prec@5 97.266 (97.408)
2025-05-20 11:30:05 - INFO - TRAINING - Epoch: [5][190/196]	Time 0.134 (0.142)	Data 0.000 (0.008)	Loss 0.8713 (0.9550)	Prec@1 75.781 (71.957)	Prec@5 98.047 (97.397)
2025-05-20 11:30:07 - INFO - EVALUATING - Epoch: [5][0/40]	Time 0.761 (0.761)	Data 0.689 (0.689)	Loss 0.8666 (0.8666)	Prec@1 75.000 (75.000)	Prec@5 98.047 (98.047)
2025-05-20 11:30:07 - INFO - EVALUATING - Epoch: [5][10/40]	Time 0.072 (0.140)	Data 0.002 (0.067)	Loss 0.8496 (0.9074)	Prec@1 78.516 (73.509)	Prec@5 96.875 (97.443)
2025-05-20 11:30:08 - INFO - EVALUATING - Epoch: [5][20/40]	Time 0.081 (0.111)	Data 0.004 (0.037)	Loss 0.8631 (0.8929)	Prec@1 74.219 (74.237)	Prec@5 98.828 (97.470)
2025-05-20 11:30:09 - INFO - EVALUATING - Epoch: [5][30/40]	Time 0.070 (0.099)	Data 0.000 (0.026)	Loss 0.9524 (0.8978)	Prec@1 71.094 (74.282)	Prec@5 97.266 (97.555)
2025-05-20 11:30:10 - INFO - 
 Epoch: 6	Training Loss 0.9551 	Training Prec@1 71.960 	Training Prec@5 97.398 	Validation Loss 0.8994 	Validation Prec@1 73.990 	Validation Prec@5 97.580 

2025-05-20 11:30:10 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:30:10 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:30:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:30:12 - INFO - TRAINING - Epoch: [6][0/196]	Time 1.632 (1.632)	Data 1.464 (1.464)	Loss 0.9351 (0.9351)	Prec@1 72.266 (72.266)	Prec@5 97.266 (97.266)
2025-05-20 11:30:13 - INFO - TRAINING - Epoch: [6][10/196]	Time 0.142 (0.285)	Data 0.011 (0.139)	Loss 0.9933 (0.9380)	Prec@1 69.531 (71.768)	Prec@5 98.047 (97.408)
2025-05-20 11:30:15 - INFO - TRAINING - Epoch: [6][20/196]	Time 0.133 (0.217)	Data 0.000 (0.075)	Loss 0.8576 (0.9434)	Prec@1 75.391 (71.243)	Prec@5 99.219 (97.377)
2025-05-20 11:30:16 - INFO - TRAINING - Epoch: [6][30/196]	Time 0.149 (0.191)	Data 0.003 (0.051)	Loss 0.8979 (0.9345)	Prec@1 73.047 (72.051)	Prec@5 99.219 (97.530)
2025-05-20 11:30:17 - INFO - TRAINING - Epoch: [6][40/196]	Time 0.135 (0.177)	Data 0.000 (0.039)	Loss 0.9664 (0.9360)	Prec@1 74.219 (72.351)	Prec@5 97.656 (97.561)
2025-05-20 11:30:19 - INFO - TRAINING - Epoch: [6][50/196]	Time 0.134 (0.169)	Data 0.007 (0.032)	Loss 0.8956 (0.9339)	Prec@1 74.219 (72.518)	Prec@5 97.266 (97.580)
2025-05-20 11:30:20 - INFO - TRAINING - Epoch: [6][60/196]	Time 0.135 (0.163)	Data 0.002 (0.027)	Loss 0.9198 (0.9317)	Prec@1 75.781 (72.714)	Prec@5 96.875 (97.528)
2025-05-20 11:30:21 - INFO - TRAINING - Epoch: [6][70/196]	Time 0.134 (0.159)	Data 0.000 (0.023)	Loss 0.8919 (0.9290)	Prec@1 73.438 (72.739)	Prec@5 98.828 (97.568)
2025-05-20 11:30:23 - INFO - TRAINING - Epoch: [6][80/196]	Time 0.154 (0.156)	Data 0.000 (0.020)	Loss 0.8534 (0.9264)	Prec@1 75.391 (72.815)	Prec@5 96.875 (97.608)
2025-05-20 11:30:24 - INFO - TRAINING - Epoch: [6][90/196]	Time 0.143 (0.155)	Data 0.013 (0.019)	Loss 0.8169 (0.9245)	Prec@1 78.906 (72.940)	Prec@5 96.875 (97.609)
2025-05-20 11:30:25 - INFO - TRAINING - Epoch: [6][100/196]	Time 0.143 (0.154)	Data 0.014 (0.018)	Loss 0.9135 (0.9214)	Prec@1 72.656 (73.140)	Prec@5 96.484 (97.606)
2025-05-20 11:30:27 - INFO - TRAINING - Epoch: [6][110/196]	Time 0.133 (0.152)	Data 0.006 (0.017)	Loss 0.8774 (0.9202)	Prec@1 76.562 (73.258)	Prec@5 98.047 (97.621)
2025-05-20 11:30:28 - INFO - TRAINING - Epoch: [6][120/196]	Time 0.136 (0.151)	Data 0.000 (0.016)	Loss 0.9274 (0.9187)	Prec@1 74.219 (73.244)	Prec@5 97.266 (97.656)
2025-05-20 11:30:30 - INFO - TRAINING - Epoch: [6][130/196]	Time 0.133 (0.150)	Data 0.000 (0.015)	Loss 0.9054 (0.9182)	Prec@1 73.438 (73.351)	Prec@5 98.047 (97.668)
2025-05-20 11:30:31 - INFO - TRAINING - Epoch: [6][140/196]	Time 0.135 (0.149)	Data 0.000 (0.014)	Loss 0.9126 (0.9172)	Prec@1 73.438 (73.371)	Prec@5 98.047 (97.714)
2025-05-20 11:30:32 - INFO - TRAINING - Epoch: [6][150/196]	Time 0.133 (0.148)	Data 0.000 (0.013)	Loss 0.9038 (0.9158)	Prec@1 73.438 (73.466)	Prec@5 98.828 (97.713)
2025-05-20 11:30:34 - INFO - TRAINING - Epoch: [6][160/196]	Time 0.134 (0.147)	Data 0.000 (0.012)	Loss 0.9459 (0.9140)	Prec@1 73.828 (73.554)	Prec@5 95.703 (97.697)
2025-05-20 11:30:35 - INFO - TRAINING - Epoch: [6][170/196]	Time 0.140 (0.146)	Data 0.000 (0.011)	Loss 0.8627 (0.9126)	Prec@1 77.734 (73.586)	Prec@5 98.047 (97.693)
2025-05-20 11:30:36 - INFO - TRAINING - Epoch: [6][180/196]	Time 0.131 (0.146)	Data 0.000 (0.011)	Loss 0.8810 (0.9121)	Prec@1 78.125 (73.645)	Prec@5 98.047 (97.695)
2025-05-20 11:30:38 - INFO - TRAINING - Epoch: [6][190/196]	Time 0.131 (0.145)	Data 0.000 (0.010)	Loss 0.9558 (0.9105)	Prec@1 70.703 (73.718)	Prec@5 96.484 (97.711)
2025-05-20 11:30:39 - INFO - EVALUATING - Epoch: [6][0/40]	Time 0.693 (0.693)	Data 0.624 (0.624)	Loss 0.8338 (0.8338)	Prec@1 76.172 (76.172)	Prec@5 97.656 (97.656)
2025-05-20 11:30:40 - INFO - EVALUATING - Epoch: [6][10/40]	Time 0.076 (0.139)	Data 0.002 (0.066)	Loss 0.8361 (0.8618)	Prec@1 73.828 (75.249)	Prec@5 98.438 (97.940)
2025-05-20 11:30:41 - INFO - EVALUATING - Epoch: [6][20/40]	Time 0.070 (0.111)	Data 0.000 (0.036)	Loss 0.8350 (0.8546)	Prec@1 76.562 (75.930)	Prec@5 98.047 (97.675)
2025-05-20 11:30:41 - INFO - EVALUATING - Epoch: [6][30/40]	Time 0.070 (0.099)	Data 0.000 (0.025)	Loss 0.8739 (0.8575)	Prec@1 73.828 (75.643)	Prec@5 97.656 (97.770)
2025-05-20 11:30:42 - INFO - 
 Epoch: 7	Training Loss 0.9095 	Training Prec@1 73.740 	Training Prec@5 97.720 	Validation Loss 0.8574 	Validation Prec@1 75.550 	Validation Prec@5 97.800 

2025-05-20 11:30:42 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:30:42 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:30:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:30:43 - INFO - TRAINING - Epoch: [7][0/196]	Time 0.726 (0.726)	Data 0.605 (0.605)	Loss 0.9096 (0.9096)	Prec@1 73.047 (73.047)	Prec@5 98.047 (98.047)
2025-05-20 11:30:45 - INFO - TRAINING - Epoch: [7][10/196]	Time 0.140 (0.218)	Data 0.000 (0.084)	Loss 0.8709 (0.9228)	Prec@1 74.609 (73.295)	Prec@5 98.828 (97.656)
2025-05-20 11:30:46 - INFO - TRAINING - Epoch: [7][20/196]	Time 0.132 (0.179)	Data 0.000 (0.047)	Loss 0.8551 (0.9057)	Prec@1 76.172 (73.921)	Prec@5 98.828 (97.805)
2025-05-20 11:30:47 - INFO - TRAINING - Epoch: [7][30/196]	Time 0.132 (0.165)	Data 0.000 (0.032)	Loss 0.9777 (0.9129)	Prec@1 70.703 (73.475)	Prec@5 95.312 (97.669)
2025-05-20 11:30:49 - INFO - TRAINING - Epoch: [7][40/196]	Time 0.144 (0.158)	Data 0.007 (0.025)	Loss 0.8272 (0.9015)	Prec@1 74.609 (73.771)	Prec@5 98.438 (97.704)
2025-05-20 11:30:50 - INFO - TRAINING - Epoch: [7][50/196]	Time 0.142 (0.155)	Data 0.014 (0.022)	Loss 0.8023 (0.8972)	Prec@1 78.516 (73.874)	Prec@5 97.656 (97.786)
2025-05-20 11:30:52 - INFO - TRAINING - Epoch: [7][60/196]	Time 0.133 (0.154)	Data 0.010 (0.020)	Loss 0.7903 (0.8902)	Prec@1 76.953 (74.200)	Prec@5 99.219 (97.816)
2025-05-20 11:30:53 - INFO - TRAINING - Epoch: [7][70/196]	Time 0.133 (0.151)	Data 0.010 (0.018)	Loss 0.8268 (0.8875)	Prec@1 77.344 (74.301)	Prec@5 98.047 (97.865)
2025-05-20 11:30:54 - INFO - TRAINING - Epoch: [7][80/196]	Time 0.134 (0.149)	Data 0.000 (0.015)	Loss 0.9074 (0.8851)	Prec@1 73.438 (74.397)	Prec@5 98.047 (97.844)
2025-05-20 11:30:56 - INFO - TRAINING - Epoch: [7][90/196]	Time 0.133 (0.147)	Data 0.000 (0.014)	Loss 0.8547 (0.8830)	Prec@1 76.172 (74.528)	Prec@5 97.656 (97.849)
2025-05-20 11:30:57 - INFO - TRAINING - Epoch: [7][100/196]	Time 0.134 (0.146)	Data 0.000 (0.013)	Loss 0.9156 (0.8838)	Prec@1 72.266 (74.505)	Prec@5 98.438 (97.900)
2025-05-20 11:30:58 - INFO - TRAINING - Epoch: [7][110/196]	Time 0.131 (0.145)	Data 0.004 (0.012)	Loss 0.9493 (0.8857)	Prec@1 71.875 (74.444)	Prec@5 97.266 (97.899)
2025-05-20 11:31:00 - INFO - TRAINING - Epoch: [7][120/196]	Time 0.135 (0.144)	Data 0.000 (0.011)	Loss 0.7988 (0.8837)	Prec@1 78.125 (74.567)	Prec@5 97.656 (97.940)
2025-05-20 11:31:01 - INFO - TRAINING - Epoch: [7][130/196]	Time 0.132 (0.143)	Data 0.000 (0.010)	Loss 0.9123 (0.8840)	Prec@1 73.828 (74.612)	Prec@5 96.875 (97.916)
2025-05-20 11:31:02 - INFO - TRAINING - Epoch: [7][140/196]	Time 0.148 (0.143)	Data 0.005 (0.010)	Loss 0.7954 (0.8812)	Prec@1 79.688 (74.748)	Prec@5 99.219 (97.955)
2025-05-20 11:31:04 - INFO - TRAINING - Epoch: [7][150/196]	Time 0.130 (0.143)	Data 0.007 (0.010)	Loss 0.8853 (0.8809)	Prec@1 75.391 (74.770)	Prec@5 98.828 (97.962)
2025-05-20 11:31:05 - INFO - TRAINING - Epoch: [7][160/196]	Time 0.135 (0.143)	Data 0.000 (0.010)	Loss 0.9379 (0.8811)	Prec@1 71.875 (74.765)	Prec@5 98.047 (97.967)
2025-05-20 11:31:07 - INFO - TRAINING - Epoch: [7][170/196]	Time 0.134 (0.142)	Data 0.000 (0.010)	Loss 0.8439 (0.8779)	Prec@1 75.000 (74.927)	Prec@5 98.828 (98.010)
2025-05-20 11:31:08 - INFO - TRAINING - Epoch: [7][180/196]	Time 0.133 (0.142)	Data 0.000 (0.009)	Loss 0.8404 (0.8758)	Prec@1 77.734 (75.037)	Prec@5 97.656 (97.999)
2025-05-20 11:31:09 - INFO - TRAINING - Epoch: [7][190/196]	Time 0.133 (0.142)	Data 0.000 (0.009)	Loss 0.8828 (0.8748)	Prec@1 74.609 (75.080)	Prec@5 96.094 (97.994)
2025-05-20 11:31:11 - INFO - EVALUATING - Epoch: [7][0/40]	Time 0.694 (0.694)	Data 0.617 (0.617)	Loss 0.8891 (0.8891)	Prec@1 76.172 (76.172)	Prec@5 98.047 (98.047)
2025-05-20 11:31:12 - INFO - EVALUATING - Epoch: [7][10/40]	Time 0.084 (0.134)	Data 0.000 (0.059)	Loss 0.8370 (0.8829)	Prec@1 73.828 (74.325)	Prec@5 98.047 (97.337)
2025-05-20 11:31:12 - INFO - EVALUATING - Epoch: [7][20/40]	Time 0.090 (0.107)	Data 0.006 (0.033)	Loss 0.9067 (0.8850)	Prec@1 73.047 (74.423)	Prec@5 98.438 (97.340)
2025-05-20 11:31:13 - INFO - EVALUATING - Epoch: [7][30/40]	Time 0.070 (0.096)	Data 0.000 (0.023)	Loss 0.9778 (0.8994)	Prec@1 69.922 (73.942)	Prec@5 96.875 (97.392)
2025-05-20 11:31:14 - INFO - 
 Epoch: 8	Training Loss 0.8745 	Training Prec@1 75.098 	Training Prec@5 98.004 	Validation Loss 0.8974 	Validation Prec@1 73.840 	Validation Prec@5 97.420 

2025-05-20 11:31:14 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:31:14 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:31:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:31:15 - INFO - TRAINING - Epoch: [8][0/196]	Time 1.019 (1.019)	Data 0.859 (0.859)	Loss 0.8425 (0.8425)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
2025-05-20 11:31:16 - INFO - TRAINING - Epoch: [8][10/196]	Time 0.192 (0.239)	Data 0.019 (0.095)	Loss 0.8473 (0.9013)	Prec@1 77.734 (74.183)	Prec@5 98.047 (97.550)
2025-05-20 11:31:18 - INFO - TRAINING - Epoch: [8][20/196]	Time 0.143 (0.200)	Data 0.000 (0.052)	Loss 0.8902 (0.8953)	Prec@1 77.344 (74.349)	Prec@5 98.047 (97.749)
2025-05-20 11:31:19 - INFO - TRAINING - Epoch: [8][30/196]	Time 0.143 (0.182)	Data 0.006 (0.037)	Loss 0.8943 (0.8860)	Prec@1 74.609 (75.076)	Prec@5 98.438 (97.631)
2025-05-20 11:31:21 - INFO - TRAINING - Epoch: [8][40/196]	Time 0.133 (0.171)	Data 0.000 (0.029)	Loss 0.8069 (0.8789)	Prec@1 78.906 (75.286)	Prec@5 98.438 (97.723)
2025-05-20 11:31:22 - INFO - TRAINING - Epoch: [8][50/196]	Time 0.133 (0.163)	Data 0.010 (0.023)	Loss 0.7568 (0.8724)	Prec@1 83.203 (75.597)	Prec@5 99.609 (97.825)
2025-05-20 11:31:23 - INFO - TRAINING - Epoch: [8][60/196]	Time 0.131 (0.159)	Data 0.000 (0.020)	Loss 0.7971 (0.8679)	Prec@1 80.078 (75.864)	Prec@5 98.438 (97.874)
2025-05-20 11:31:25 - INFO - TRAINING - Epoch: [8][70/196]	Time 0.145 (0.155)	Data 0.009 (0.017)	Loss 0.8330 (0.8682)	Prec@1 76.953 (75.842)	Prec@5 98.828 (97.915)
2025-05-20 11:31:26 - INFO - TRAINING - Epoch: [8][80/196]	Time 0.134 (0.152)	Data 0.000 (0.015)	Loss 0.7869 (0.8625)	Prec@1 79.688 (76.071)	Prec@5 97.656 (97.950)
2025-05-20 11:31:28 - INFO - TRAINING - Epoch: [8][90/196]	Time 0.134 (0.150)	Data 0.000 (0.014)	Loss 0.7937 (0.8597)	Prec@1 78.516 (76.150)	Prec@5 98.828 (97.974)
2025-05-20 11:31:29 - INFO - TRAINING - Epoch: [8][100/196]	Time 0.151 (0.150)	Data 0.000 (0.013)	Loss 0.8793 (0.8582)	Prec@1 73.438 (76.203)	Prec@5 98.047 (98.004)
2025-05-20 11:31:30 - INFO - TRAINING - Epoch: [8][110/196]	Time 0.155 (0.149)	Data 0.000 (0.013)	Loss 0.7989 (0.8564)	Prec@1 81.250 (76.242)	Prec@5 99.609 (98.036)
2025-05-20 11:31:32 - INFO - TRAINING - Epoch: [8][120/196]	Time 0.139 (0.149)	Data 0.007 (0.013)	Loss 0.8528 (0.8556)	Prec@1 76.953 (76.224)	Prec@5 96.875 (98.050)
2025-05-20 11:31:33 - INFO - TRAINING - Epoch: [8][130/196]	Time 0.132 (0.148)	Data 0.000 (0.012)	Loss 0.8071 (0.8533)	Prec@1 77.734 (76.342)	Prec@5 98.828 (98.056)
2025-05-20 11:31:35 - INFO - TRAINING - Epoch: [8][140/196]	Time 0.134 (0.147)	Data 0.012 (0.011)	Loss 0.8114 (0.8529)	Prec@1 76.172 (76.405)	Prec@5 99.219 (98.080)
2025-05-20 11:31:36 - INFO - TRAINING - Epoch: [8][150/196]	Time 0.131 (0.146)	Data 0.000 (0.011)	Loss 0.8196 (0.8525)	Prec@1 79.297 (76.392)	Prec@5 98.438 (98.117)
2025-05-20 11:31:37 - INFO - TRAINING - Epoch: [8][160/196]	Time 0.135 (0.145)	Data 0.000 (0.010)	Loss 0.8237 (0.8508)	Prec@1 76.562 (76.400)	Prec@5 98.828 (98.117)
2025-05-20 11:31:39 - INFO - TRAINING - Epoch: [8][170/196]	Time 0.135 (0.145)	Data 0.000 (0.009)	Loss 0.8936 (0.8510)	Prec@1 73.438 (76.382)	Prec@5 98.828 (98.127)
2025-05-20 11:31:40 - INFO - TRAINING - Epoch: [8][180/196]	Time 0.132 (0.144)	Data 0.000 (0.009)	Loss 0.8535 (0.8496)	Prec@1 74.609 (76.442)	Prec@5 98.047 (98.129)
2025-05-20 11:31:41 - INFO - TRAINING - Epoch: [8][190/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.8405 (0.8493)	Prec@1 73.828 (76.376)	Prec@5 98.438 (98.145)
2025-05-20 11:31:43 - INFO - EVALUATING - Epoch: [8][0/40]	Time 1.380 (1.380)	Data 1.295 (1.295)	Loss 0.8109 (0.8109)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
2025-05-20 11:31:44 - INFO - EVALUATING - Epoch: [8][10/40]	Time 0.077 (0.202)	Data 0.000 (0.122)	Loss 0.7551 (0.8223)	Prec@1 83.203 (77.024)	Prec@5 97.266 (97.834)
2025-05-20 11:31:45 - INFO - EVALUATING - Epoch: [8][20/40]	Time 0.071 (0.142)	Data 0.000 (0.065)	Loss 0.7462 (0.8127)	Prec@1 80.469 (77.679)	Prec@5 99.219 (97.898)
2025-05-20 11:31:46 - INFO - EVALUATING - Epoch: [8][30/40]	Time 0.070 (0.120)	Data 0.000 (0.045)	Loss 0.8581 (0.8173)	Prec@1 74.609 (77.382)	Prec@5 98.828 (98.160)
2025-05-20 11:31:47 - INFO - 
 Epoch: 9	Training Loss 0.8499 	Training Prec@1 76.372 	Training Prec@5 98.126 	Validation Loss 0.8153 	Validation Prec@1 77.550 	Validation Prec@5 98.220 

2025-05-20 11:31:47 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:31:47 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:31:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:31:47 - INFO - TRAINING - Epoch: [9][0/196]	Time 0.916 (0.916)	Data 0.814 (0.814)	Loss 0.8084 (0.8084)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
2025-05-20 11:31:49 - INFO - TRAINING - Epoch: [9][10/196]	Time 0.155 (0.212)	Data 0.000 (0.077)	Loss 0.8427 (0.8227)	Prec@1 77.734 (78.374)	Prec@5 97.656 (98.260)
2025-05-20 11:31:50 - INFO - TRAINING - Epoch: [9][20/196]	Time 0.138 (0.177)	Data 0.007 (0.043)	Loss 0.8704 (0.8336)	Prec@1 76.562 (77.548)	Prec@5 98.438 (98.289)
2025-05-20 11:31:52 - INFO - TRAINING - Epoch: [9][30/196]	Time 0.134 (0.163)	Data 0.003 (0.030)	Loss 0.8702 (0.8413)	Prec@1 76.172 (76.689)	Prec@5 97.266 (98.236)
2025-05-20 11:31:53 - INFO - TRAINING - Epoch: [9][40/196]	Time 0.134 (0.156)	Data 0.007 (0.023)	Loss 0.7406 (0.8321)	Prec@1 81.250 (77.010)	Prec@5 98.438 (98.266)
2025-05-20 11:31:54 - INFO - TRAINING - Epoch: [9][50/196]	Time 0.140 (0.152)	Data 0.000 (0.019)	Loss 0.7528 (0.8250)	Prec@1 82.812 (77.466)	Prec@5 98.438 (98.353)
2025-05-20 11:31:56 - INFO - TRAINING - Epoch: [9][60/196]	Time 0.137 (0.150)	Data 0.000 (0.016)	Loss 0.8663 (0.8277)	Prec@1 76.172 (77.344)	Prec@5 98.828 (98.335)
2025-05-20 11:31:57 - INFO - TRAINING - Epoch: [9][70/196]	Time 0.135 (0.150)	Data 0.016 (0.015)	Loss 0.7933 (0.8290)	Prec@1 78.516 (77.360)	Prec@5 97.656 (98.311)
2025-05-20 11:31:59 - INFO - TRAINING - Epoch: [9][80/196]	Time 0.133 (0.148)	Data 0.000 (0.014)	Loss 0.8163 (0.8297)	Prec@1 78.125 (77.358)	Prec@5 99.219 (98.312)
2025-05-20 11:32:00 - INFO - TRAINING - Epoch: [9][90/196]	Time 0.138 (0.146)	Data 0.000 (0.012)	Loss 0.8705 (0.8312)	Prec@1 73.438 (77.275)	Prec@5 99.219 (98.304)
2025-05-20 11:32:01 - INFO - TRAINING - Epoch: [9][100/196]	Time 0.134 (0.145)	Data 0.000 (0.012)	Loss 0.7863 (0.8273)	Prec@1 76.562 (77.437)	Prec@5 98.047 (98.318)
2025-05-20 11:32:03 - INFO - TRAINING - Epoch: [9][110/196]	Time 0.133 (0.144)	Data 0.000 (0.011)	Loss 0.7910 (0.8271)	Prec@1 77.734 (77.397)	Prec@5 98.438 (98.328)
2025-05-20 11:32:04 - INFO - TRAINING - Epoch: [9][120/196]	Time 0.138 (0.143)	Data 0.000 (0.010)	Loss 0.8380 (0.8266)	Prec@1 78.125 (77.434)	Prec@5 97.656 (98.315)
2025-05-20 11:32:05 - INFO - TRAINING - Epoch: [9][130/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.8362 (0.8276)	Prec@1 78.906 (77.415)	Prec@5 99.609 (98.321)
2025-05-20 11:32:07 - INFO - TRAINING - Epoch: [9][140/196]	Time 0.132 (0.142)	Data 0.003 (0.009)	Loss 0.8572 (0.8292)	Prec@1 75.391 (77.352)	Prec@5 98.438 (98.335)
2025-05-20 11:32:08 - INFO - TRAINING - Epoch: [9][150/196]	Time 0.153 (0.142)	Data 0.000 (0.008)	Loss 0.8187 (0.8293)	Prec@1 79.688 (77.318)	Prec@5 97.266 (98.308)
2025-05-20 11:32:09 - INFO - TRAINING - Epoch: [9][160/196]	Time 0.138 (0.142)	Data 0.000 (0.008)	Loss 0.8217 (0.8281)	Prec@1 76.562 (77.395)	Prec@5 98.047 (98.309)
2025-05-20 11:32:11 - INFO - TRAINING - Epoch: [9][170/196]	Time 0.138 (0.142)	Data 0.010 (0.008)	Loss 0.7752 (0.8265)	Prec@1 78.906 (77.451)	Prec@5 99.609 (98.316)
2025-05-20 11:32:12 - INFO - TRAINING - Epoch: [9][180/196]	Time 0.133 (0.142)	Data 0.000 (0.008)	Loss 0.7198 (0.8255)	Prec@1 82.031 (77.475)	Prec@5 98.828 (98.304)
2025-05-20 11:32:14 - INFO - TRAINING - Epoch: [9][190/196]	Time 0.135 (0.141)	Data 0.000 (0.007)	Loss 0.7401 (0.8248)	Prec@1 82.812 (77.495)	Prec@5 98.828 (98.290)
2025-05-20 11:32:15 - INFO - EVALUATING - Epoch: [9][0/40]	Time 0.684 (0.684)	Data 0.612 (0.612)	Loss 0.8747 (0.8747)	Prec@1 78.125 (78.125)	Prec@5 96.875 (96.875)
2025-05-20 11:32:16 - INFO - EVALUATING - Epoch: [9][10/40]	Time 0.069 (0.148)	Data 0.000 (0.070)	Loss 0.7322 (0.8446)	Prec@1 82.812 (76.776)	Prec@5 98.047 (98.011)
2025-05-20 11:32:17 - INFO - EVALUATING - Epoch: [9][20/40]	Time 0.081 (0.117)	Data 0.003 (0.039)	Loss 0.8399 (0.8378)	Prec@1 75.000 (77.214)	Prec@5 98.438 (97.917)
2025-05-20 11:32:17 - INFO - EVALUATING - Epoch: [9][30/40]	Time 0.070 (0.102)	Data 0.000 (0.027)	Loss 0.8388 (0.8381)	Prec@1 77.734 (77.004)	Prec@5 97.656 (98.148)
2025-05-20 11:32:18 - INFO - 
 Epoch: 10	Training Loss 0.8253 	Training Prec@1 77.486 	Training Prec@5 98.282 	Validation Loss 0.8367 	Validation Prec@1 77.010 	Validation Prec@5 98.190 

2025-05-20 11:32:18 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:32:18 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:32:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:32:19 - INFO - TRAINING - Epoch: [10][0/196]	Time 0.762 (0.762)	Data 0.642 (0.642)	Loss 0.8288 (0.8288)	Prec@1 77.734 (77.734)	Prec@5 98.438 (98.438)
2025-05-20 11:32:21 - INFO - TRAINING - Epoch: [10][10/196]	Time 0.148 (0.215)	Data 0.000 (0.082)	Loss 0.8039 (0.8069)	Prec@1 77.734 (77.486)	Prec@5 98.828 (98.331)
2025-05-20 11:32:22 - INFO - TRAINING - Epoch: [10][20/196]	Time 0.152 (0.186)	Data 0.003 (0.046)	Loss 0.7490 (0.8124)	Prec@1 81.250 (77.641)	Prec@5 98.047 (98.326)
2025-05-20 11:32:24 - INFO - TRAINING - Epoch: [10][30/196]	Time 0.145 (0.174)	Data 0.005 (0.034)	Loss 0.8395 (0.8146)	Prec@1 77.344 (77.697)	Prec@5 99.219 (98.412)
2025-05-20 11:32:25 - INFO - TRAINING - Epoch: [10][40/196]	Time 0.133 (0.166)	Data 0.000 (0.027)	Loss 0.8466 (0.8148)	Prec@1 76.172 (77.763)	Prec@5 97.656 (98.361)
2025-05-20 11:32:26 - INFO - TRAINING - Epoch: [10][50/196]	Time 0.144 (0.160)	Data 0.000 (0.022)	Loss 0.7040 (0.8056)	Prec@1 83.203 (78.339)	Prec@5 98.438 (98.460)
2025-05-20 11:32:28 - INFO - TRAINING - Epoch: [10][60/196]	Time 0.152 (0.157)	Data 0.000 (0.019)	Loss 0.8045 (0.8039)	Prec@1 79.297 (78.356)	Prec@5 96.094 (98.393)
2025-05-20 11:32:29 - INFO - TRAINING - Epoch: [10][70/196]	Time 0.130 (0.156)	Data 0.004 (0.018)	Loss 0.8067 (0.8015)	Prec@1 78.516 (78.477)	Prec@5 97.656 (98.371)
2025-05-20 11:32:31 - INFO - TRAINING - Epoch: [10][80/196]	Time 0.137 (0.153)	Data 0.007 (0.016)	Loss 0.7608 (0.8005)	Prec@1 81.641 (78.607)	Prec@5 98.828 (98.341)
2025-05-20 11:32:32 - INFO - TRAINING - Epoch: [10][90/196]	Time 0.132 (0.152)	Data 0.008 (0.014)	Loss 0.7760 (0.8058)	Prec@1 78.906 (78.301)	Prec@5 98.828 (98.309)
2025-05-20 11:32:33 - INFO - TRAINING - Epoch: [10][100/196]	Time 0.134 (0.150)	Data 0.000 (0.013)	Loss 0.8401 (0.8058)	Prec@1 80.078 (78.307)	Prec@5 96.875 (98.302)
2025-05-20 11:32:35 - INFO - TRAINING - Epoch: [10][110/196]	Time 0.141 (0.149)	Data 0.000 (0.012)	Loss 0.8108 (0.8057)	Prec@1 79.688 (78.266)	Prec@5 98.828 (98.314)
2025-05-20 11:32:36 - INFO - TRAINING - Epoch: [10][120/196]	Time 0.152 (0.149)	Data 0.008 (0.012)	Loss 0.8204 (0.8063)	Prec@1 77.734 (78.232)	Prec@5 97.656 (98.318)
2025-05-20 11:32:38 - INFO - TRAINING - Epoch: [10][130/196]	Time 0.134 (0.148)	Data 0.007 (0.011)	Loss 0.8526 (0.8060)	Prec@1 75.781 (78.268)	Prec@5 98.438 (98.285)
2025-05-20 11:32:39 - INFO - TRAINING - Epoch: [10][140/196]	Time 0.135 (0.147)	Data 0.000 (0.010)	Loss 0.7822 (0.8058)	Prec@1 80.078 (78.280)	Prec@5 98.047 (98.280)
2025-05-20 11:32:40 - INFO - TRAINING - Epoch: [10][150/196]	Time 0.134 (0.146)	Data 0.000 (0.010)	Loss 0.8446 (0.8058)	Prec@1 74.609 (78.252)	Prec@5 98.047 (98.295)
2025-05-20 11:32:42 - INFO - TRAINING - Epoch: [10][160/196]	Time 0.133 (0.145)	Data 0.006 (0.009)	Loss 0.8477 (0.8062)	Prec@1 76.953 (78.244)	Prec@5 98.828 (98.282)
2025-05-20 11:32:43 - INFO - TRAINING - Epoch: [10][170/196]	Time 0.133 (0.145)	Data 0.004 (0.009)	Loss 0.8971 (0.8080)	Prec@1 74.609 (78.143)	Prec@5 96.484 (98.264)
2025-05-20 11:32:44 - INFO - TRAINING - Epoch: [10][180/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.7918 (0.8074)	Prec@1 78.906 (78.179)	Prec@5 97.266 (98.258)
2025-05-20 11:32:46 - INFO - TRAINING - Epoch: [10][190/196]	Time 0.132 (0.144)	Data 0.000 (0.008)	Loss 0.7826 (0.8072)	Prec@1 79.688 (78.199)	Prec@5 98.047 (98.282)
2025-05-20 11:32:47 - INFO - EVALUATING - Epoch: [10][0/40]	Time 0.845 (0.845)	Data 0.755 (0.755)	Loss 0.8254 (0.8254)	Prec@1 76.172 (76.172)	Prec@5 98.438 (98.438)
2025-05-20 11:32:48 - INFO - EVALUATING - Epoch: [10][10/40]	Time 0.071 (0.184)	Data 0.000 (0.104)	Loss 0.7575 (0.7991)	Prec@1 77.734 (77.805)	Prec@5 99.219 (98.260)
2025-05-20 11:32:50 - INFO - EVALUATING - Epoch: [10][20/40]	Time 0.086 (0.148)	Data 0.003 (0.068)	Loss 0.7615 (0.7919)	Prec@1 79.688 (78.144)	Prec@5 98.047 (98.140)
2025-05-20 11:32:50 - INFO - EVALUATING - Epoch: [10][30/40]	Time 0.069 (0.129)	Data 0.000 (0.051)	Loss 0.7914 (0.7966)	Prec@1 79.297 (78.049)	Prec@5 96.875 (98.148)
2025-05-20 11:32:51 - INFO - 
 Epoch: 11	Training Loss 0.8085 	Training Prec@1 78.156 	Training Prec@5 98.288 	Validation Loss 0.7974 	Validation Prec@1 77.940 	Validation Prec@5 98.220 

2025-05-20 11:32:51 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:32:51 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:32:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:32:52 - INFO - TRAINING - Epoch: [11][0/196]	Time 0.901 (0.901)	Data 0.780 (0.780)	Loss 0.8877 (0.8877)	Prec@1 75.781 (75.781)	Prec@5 98.828 (98.828)
2025-05-20 11:32:54 - INFO - TRAINING - Epoch: [11][10/196]	Time 0.147 (0.217)	Data 0.003 (0.085)	Loss 0.8324 (0.8102)	Prec@1 77.734 (78.729)	Prec@5 97.266 (98.402)
2025-05-20 11:32:55 - INFO - TRAINING - Epoch: [11][20/196]	Time 0.132 (0.180)	Data 0.001 (0.047)	Loss 0.7694 (0.8011)	Prec@1 80.859 (78.664)	Prec@5 98.438 (98.438)
2025-05-20 11:32:56 - INFO - TRAINING - Epoch: [11][30/196]	Time 0.133 (0.165)	Data 0.000 (0.033)	Loss 0.7762 (0.7886)	Prec@1 79.688 (79.234)	Prec@5 99.609 (98.614)
2025-05-20 11:32:58 - INFO - TRAINING - Epoch: [11][40/196]	Time 0.132 (0.157)	Data 0.001 (0.025)	Loss 0.7740 (0.7964)	Prec@1 79.297 (78.773)	Prec@5 98.828 (98.514)
2025-05-20 11:32:59 - INFO - TRAINING - Epoch: [11][50/196]	Time 0.133 (0.153)	Data 0.000 (0.021)	Loss 0.7284 (0.7948)	Prec@1 81.641 (78.822)	Prec@5 98.828 (98.514)
2025-05-20 11:33:00 - INFO - TRAINING - Epoch: [11][60/196]	Time 0.125 (0.150)	Data 0.000 (0.018)	Loss 0.7982 (0.7969)	Prec@1 77.734 (78.740)	Prec@5 98.828 (98.457)
2025-05-20 11:33:02 - INFO - TRAINING - Epoch: [11][70/196]	Time 0.157 (0.150)	Data 0.018 (0.017)	Loss 0.7896 (0.7913)	Prec@1 82.031 (79.044)	Prec@5 99.219 (98.476)
2025-05-20 11:33:03 - INFO - TRAINING - Epoch: [11][80/196]	Time 0.171 (0.150)	Data 0.000 (0.016)	Loss 0.8109 (0.7884)	Prec@1 76.953 (79.162)	Prec@5 99.219 (98.510)
2025-05-20 11:33:05 - INFO - TRAINING - Epoch: [11][90/196]	Time 0.136 (0.149)	Data 0.000 (0.014)	Loss 0.8459 (0.7879)	Prec@1 74.609 (79.168)	Prec@5 98.438 (98.468)
2025-05-20 11:33:06 - INFO - TRAINING - Epoch: [11][100/196]	Time 0.134 (0.147)	Data 0.000 (0.013)	Loss 0.8295 (0.7890)	Prec@1 77.344 (79.115)	Prec@5 97.656 (98.465)
2025-05-20 11:33:07 - INFO - TRAINING - Epoch: [11][110/196]	Time 0.133 (0.146)	Data 0.007 (0.012)	Loss 0.7050 (0.7909)	Prec@1 82.422 (79.008)	Prec@5 98.438 (98.469)
2025-05-20 11:33:09 - INFO - TRAINING - Epoch: [11][120/196]	Time 0.135 (0.145)	Data 0.007 (0.012)	Loss 0.7539 (0.7908)	Prec@1 80.078 (78.977)	Prec@5 99.219 (98.509)
2025-05-20 11:33:10 - INFO - TRAINING - Epoch: [11][130/196]	Time 0.134 (0.144)	Data 0.000 (0.011)	Loss 0.7979 (0.7906)	Prec@1 78.516 (78.978)	Prec@5 98.438 (98.512)
2025-05-20 11:33:12 - INFO - TRAINING - Epoch: [11][140/196]	Time 0.134 (0.144)	Data 0.000 (0.010)	Loss 0.7421 (0.7904)	Prec@1 81.250 (79.020)	Prec@5 98.828 (98.487)
2025-05-20 11:33:13 - INFO - TRAINING - Epoch: [11][150/196]	Time 0.134 (0.143)	Data 0.007 (0.010)	Loss 0.7311 (0.7909)	Prec@1 82.031 (78.935)	Prec@5 98.438 (98.492)
2025-05-20 11:33:14 - INFO - TRAINING - Epoch: [11][160/196]	Time 0.146 (0.143)	Data 0.005 (0.010)	Loss 0.7928 (0.7913)	Prec@1 76.953 (78.928)	Prec@5 98.828 (98.484)
2025-05-20 11:33:16 - INFO - TRAINING - Epoch: [11][170/196]	Time 0.155 (0.143)	Data 0.017 (0.009)	Loss 0.7395 (0.7917)	Prec@1 83.984 (78.877)	Prec@5 98.828 (98.485)
2025-05-20 11:33:17 - INFO - TRAINING - Epoch: [11][180/196]	Time 0.135 (0.143)	Data 0.000 (0.009)	Loss 0.8810 (0.7914)	Prec@1 73.828 (78.891)	Prec@5 96.484 (98.470)
2025-05-20 11:33:18 - INFO - TRAINING - Epoch: [11][190/196]	Time 0.134 (0.142)	Data 0.000 (0.009)	Loss 0.8571 (0.7910)	Prec@1 76.172 (78.882)	Prec@5 98.438 (98.474)
2025-05-20 11:33:20 - INFO - EVALUATING - Epoch: [11][0/40]	Time 0.914 (0.914)	Data 0.846 (0.846)	Loss 0.7833 (0.7833)	Prec@1 80.859 (80.859)	Prec@5 97.656 (97.656)
2025-05-20 11:33:21 - INFO - EVALUATING - Epoch: [11][10/40]	Time 0.068 (0.153)	Data 0.000 (0.079)	Loss 0.7501 (0.7727)	Prec@1 81.641 (78.871)	Prec@5 96.875 (98.153)
2025-05-20 11:33:22 - INFO - EVALUATING - Epoch: [11][20/40]	Time 0.076 (0.116)	Data 0.005 (0.043)	Loss 0.7536 (0.7695)	Prec@1 77.734 (79.222)	Prec@5 99.219 (98.196)
2025-05-20 11:33:22 - INFO - EVALUATING - Epoch: [11][30/40]	Time 0.070 (0.103)	Data 0.000 (0.030)	Loss 0.8192 (0.7709)	Prec@1 76.172 (79.209)	Prec@5 97.656 (98.349)
2025-05-20 11:33:23 - INFO - 
 Epoch: 12	Training Loss 0.7914 	Training Prec@1 78.864 	Training Prec@5 98.470 	Validation Loss 0.7709 	Validation Prec@1 79.200 	Validation Prec@5 98.300 

2025-05-20 11:33:23 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:33:23 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:33:23 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:33:24 - INFO - TRAINING - Epoch: [12][0/196]	Time 1.002 (1.002)	Data 0.857 (0.857)	Loss 0.7897 (0.7897)	Prec@1 78.906 (78.906)	Prec@5 98.047 (98.047)
2025-05-20 11:33:26 - INFO - TRAINING - Epoch: [12][10/196]	Time 0.137 (0.214)	Data 0.004 (0.085)	Loss 0.8162 (0.8063)	Prec@1 78.125 (79.084)	Prec@5 96.875 (98.011)
2025-05-20 11:33:27 - INFO - TRAINING - Epoch: [12][20/196]	Time 0.143 (0.179)	Data 0.000 (0.045)	Loss 0.6796 (0.7937)	Prec@1 83.594 (79.650)	Prec@5 98.828 (98.177)
2025-05-20 11:33:28 - INFO - TRAINING - Epoch: [12][30/196]	Time 0.146 (0.167)	Data 0.005 (0.032)	Loss 0.7327 (0.7888)	Prec@1 81.250 (79.637)	Prec@5 99.219 (98.223)
2025-05-20 11:33:30 - INFO - TRAINING - Epoch: [12][40/196]	Time 0.150 (0.164)	Data 0.015 (0.026)	Loss 0.6927 (0.7800)	Prec@1 85.938 (79.859)	Prec@5 98.438 (98.438)
2025-05-20 11:33:31 - INFO - TRAINING - Epoch: [12][50/196]	Time 0.135 (0.159)	Data 0.000 (0.021)	Loss 0.7575 (0.7772)	Prec@1 82.031 (79.879)	Prec@5 97.656 (98.430)
2025-05-20 11:33:33 - INFO - TRAINING - Epoch: [12][60/196]	Time 0.134 (0.155)	Data 0.000 (0.018)	Loss 0.7236 (0.7755)	Prec@1 80.078 (79.809)	Prec@5 100.000 (98.489)
2025-05-20 11:33:34 - INFO - TRAINING - Epoch: [12][70/196]	Time 0.133 (0.152)	Data 0.000 (0.016)	Loss 0.7813 (0.7777)	Prec@1 80.859 (79.671)	Prec@5 99.219 (98.482)
2025-05-20 11:33:35 - INFO - TRAINING - Epoch: [12][80/196]	Time 0.134 (0.150)	Data 0.000 (0.015)	Loss 0.7666 (0.7794)	Prec@1 80.078 (79.533)	Prec@5 99.219 (98.515)
2025-05-20 11:33:37 - INFO - TRAINING - Epoch: [12][90/196]	Time 0.134 (0.148)	Data 0.000 (0.013)	Loss 0.8445 (0.7802)	Prec@1 77.344 (79.503)	Prec@5 98.438 (98.506)
2025-05-20 11:33:38 - INFO - TRAINING - Epoch: [12][100/196]	Time 0.133 (0.147)	Data 0.000 (0.012)	Loss 0.7211 (0.7798)	Prec@1 81.250 (79.521)	Prec@5 98.438 (98.511)
2025-05-20 11:33:39 - INFO - TRAINING - Epoch: [12][110/196]	Time 0.134 (0.146)	Data 0.000 (0.011)	Loss 0.7291 (0.7794)	Prec@1 81.641 (79.529)	Prec@5 98.828 (98.508)
2025-05-20 11:33:41 - INFO - TRAINING - Epoch: [12][120/196]	Time 0.152 (0.145)	Data 0.000 (0.011)	Loss 0.8816 (0.7820)	Prec@1 71.094 (79.368)	Prec@5 98.047 (98.476)
2025-05-20 11:33:42 - INFO - TRAINING - Epoch: [12][130/196]	Time 0.144 (0.145)	Data 0.011 (0.011)	Loss 0.8317 (0.7819)	Prec@1 76.172 (79.374)	Prec@5 98.828 (98.497)
2025-05-20 11:33:44 - INFO - TRAINING - Epoch: [12][140/196]	Time 0.143 (0.145)	Data 0.015 (0.010)	Loss 0.7521 (0.7792)	Prec@1 78.125 (79.458)	Prec@5 98.438 (98.493)
2025-05-20 11:33:45 - INFO - TRAINING - Epoch: [12][150/196]	Time 0.137 (0.144)	Data 0.000 (0.010)	Loss 0.7211 (0.7777)	Prec@1 83.203 (79.532)	Prec@5 100.000 (98.497)
2025-05-20 11:33:46 - INFO - TRAINING - Epoch: [12][160/196]	Time 0.134 (0.144)	Data 0.000 (0.009)	Loss 0.7716 (0.7776)	Prec@1 80.078 (79.506)	Prec@5 98.828 (98.493)
2025-05-20 11:33:48 - INFO - TRAINING - Epoch: [12][170/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.7862 (0.7768)	Prec@1 77.734 (79.534)	Prec@5 98.438 (98.522)
2025-05-20 11:33:49 - INFO - TRAINING - Epoch: [12][180/196]	Time 0.133 (0.142)	Data 0.000 (0.008)	Loss 0.7987 (0.7761)	Prec@1 77.734 (79.573)	Prec@5 97.266 (98.537)
2025-05-20 11:33:50 - INFO - TRAINING - Epoch: [12][190/196]	Time 0.133 (0.142)	Data 0.000 (0.008)	Loss 0.8026 (0.7752)	Prec@1 77.734 (79.622)	Prec@5 98.438 (98.532)
2025-05-20 11:33:51 - INFO - EVALUATING - Epoch: [12][0/40]	Time 0.393 (0.393)	Data 0.324 (0.324)	Loss 0.7892 (0.7892)	Prec@1 78.516 (78.516)	Prec@5 97.656 (97.656)
2025-05-20 11:33:53 - INFO - EVALUATING - Epoch: [12][10/40]	Time 0.089 (0.139)	Data 0.009 (0.067)	Loss 0.6915 (0.7745)	Prec@1 82.812 (79.688)	Prec@5 98.828 (98.011)
2025-05-20 11:33:53 - INFO - EVALUATING - Epoch: [12][20/40]	Time 0.072 (0.110)	Data 0.003 (0.036)	Loss 0.7311 (0.7635)	Prec@1 83.203 (80.041)	Prec@5 98.438 (97.935)
2025-05-20 11:33:54 - INFO - EVALUATING - Epoch: [12][30/40]	Time 0.069 (0.099)	Data 0.000 (0.025)	Loss 0.7642 (0.7690)	Prec@1 78.125 (79.675)	Prec@5 98.438 (98.148)
2025-05-20 11:33:55 - INFO - 
 Epoch: 13	Training Loss 0.7744 	Training Prec@1 79.656 	Training Prec@5 98.538 	Validation Loss 0.7666 	Validation Prec@1 79.780 	Validation Prec@5 98.270 

2025-05-20 11:33:55 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:33:55 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:33:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:33:57 - INFO - TRAINING - Epoch: [13][0/196]	Time 1.412 (1.412)	Data 1.271 (1.271)	Loss 0.7986 (0.7986)	Prec@1 80.469 (80.469)	Prec@5 98.047 (98.047)
2025-05-20 11:33:58 - INFO - TRAINING - Epoch: [13][10/196]	Time 0.137 (0.260)	Data 0.018 (0.122)	Loss 0.7218 (0.8058)	Prec@1 80.078 (78.054)	Prec@5 98.438 (98.580)
2025-05-20 11:33:59 - INFO - TRAINING - Epoch: [13][20/196]	Time 0.133 (0.201)	Data 0.000 (0.065)	Loss 0.7717 (0.7903)	Prec@1 78.516 (79.055)	Prec@5 99.219 (98.586)
2025-05-20 11:34:01 - INFO - TRAINING - Epoch: [13][30/196]	Time 0.134 (0.179)	Data 0.000 (0.044)	Loss 0.7141 (0.7750)	Prec@1 82.812 (79.776)	Prec@5 99.219 (98.753)
2025-05-20 11:34:02 - INFO - TRAINING - Epoch: [13][40/196]	Time 0.133 (0.168)	Data 0.000 (0.034)	Loss 0.6675 (0.7694)	Prec@1 85.156 (79.973)	Prec@5 98.828 (98.723)
2025-05-20 11:34:03 - INFO - TRAINING - Epoch: [13][50/196]	Time 0.130 (0.162)	Data 0.000 (0.028)	Loss 0.7093 (0.7658)	Prec@1 82.422 (80.070)	Prec@5 99.219 (98.706)
2025-05-20 11:34:05 - INFO - TRAINING - Epoch: [13][60/196]	Time 0.130 (0.158)	Data 0.000 (0.024)	Loss 0.7031 (0.7615)	Prec@1 85.547 (80.341)	Prec@5 99.219 (98.655)
2025-05-20 11:34:06 - INFO - TRAINING - Epoch: [13][70/196]	Time 0.152 (0.155)	Data 0.000 (0.021)	Loss 0.7336 (0.7623)	Prec@1 81.250 (80.298)	Prec@5 98.438 (98.608)
2025-05-20 11:34:08 - INFO - TRAINING - Epoch: [13][80/196]	Time 0.144 (0.153)	Data 0.000 (0.019)	Loss 0.7617 (0.7623)	Prec@1 80.078 (80.324)	Prec@5 98.438 (98.621)
2025-05-20 11:34:09 - INFO - TRAINING - Epoch: [13][90/196]	Time 0.135 (0.152)	Data 0.025 (0.018)	Loss 0.7664 (0.7613)	Prec@1 79.688 (80.306)	Prec@5 98.438 (98.631)
2025-05-20 11:34:10 - INFO - TRAINING - Epoch: [13][100/196]	Time 0.148 (0.151)	Data 0.007 (0.017)	Loss 0.7801 (0.7600)	Prec@1 77.344 (80.314)	Prec@5 97.266 (98.635)
2025-05-20 11:34:12 - INFO - TRAINING - Epoch: [13][110/196]	Time 0.135 (0.149)	Data 0.000 (0.016)	Loss 0.7629 (0.7590)	Prec@1 80.469 (80.360)	Prec@5 98.828 (98.687)
2025-05-20 11:34:13 - INFO - TRAINING - Epoch: [13][120/196]	Time 0.134 (0.148)	Data 0.000 (0.014)	Loss 0.7562 (0.7576)	Prec@1 77.734 (80.420)	Prec@5 98.828 (98.683)
2025-05-20 11:34:14 - INFO - TRAINING - Epoch: [13][130/196]	Time 0.135 (0.147)	Data 0.000 (0.013)	Loss 0.7212 (0.7559)	Prec@1 82.422 (80.505)	Prec@5 99.219 (98.697)
2025-05-20 11:34:16 - INFO - TRAINING - Epoch: [13][140/196]	Time 0.122 (0.146)	Data 0.000 (0.012)	Loss 0.8053 (0.7575)	Prec@1 79.297 (80.424)	Prec@5 97.266 (98.643)
2025-05-20 11:34:17 - INFO - TRAINING - Epoch: [13][150/196]	Time 0.134 (0.145)	Data 0.000 (0.012)	Loss 0.7824 (0.7567)	Prec@1 78.906 (80.466)	Prec@5 99.609 (98.639)
2025-05-20 11:34:18 - INFO - TRAINING - Epoch: [13][160/196]	Time 0.131 (0.145)	Data 0.000 (0.011)	Loss 0.7030 (0.7565)	Prec@1 83.203 (80.461)	Prec@5 98.438 (98.649)
2025-05-20 11:34:20 - INFO - TRAINING - Epoch: [13][170/196]	Time 0.155 (0.144)	Data 0.000 (0.011)	Loss 0.7571 (0.7573)	Prec@1 81.641 (80.437)	Prec@5 97.656 (98.616)
2025-05-20 11:34:21 - INFO - TRAINING - Epoch: [13][180/196]	Time 0.155 (0.144)	Data 0.000 (0.011)	Loss 0.7846 (0.7575)	Prec@1 80.078 (80.417)	Prec@5 97.266 (98.595)
2025-05-20 11:34:23 - INFO - TRAINING - Epoch: [13][190/196]	Time 0.132 (0.143)	Data 0.000 (0.010)	Loss 0.7502 (0.7570)	Prec@1 80.859 (80.434)	Prec@5 99.219 (98.607)
2025-05-20 11:34:24 - INFO - EVALUATING - Epoch: [13][0/40]	Time 0.761 (0.761)	Data 0.690 (0.690)	Loss 0.7604 (0.7604)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)
2025-05-20 11:34:25 - INFO - EVALUATING - Epoch: [13][10/40]	Time 0.072 (0.140)	Data 0.003 (0.066)	Loss 0.7170 (0.7746)	Prec@1 79.297 (79.155)	Prec@5 98.828 (98.082)
2025-05-20 11:34:26 - INFO - EVALUATING - Epoch: [13][20/40]	Time 0.080 (0.110)	Data 0.000 (0.037)	Loss 0.7469 (0.7713)	Prec@1 80.469 (79.669)	Prec@5 98.438 (97.898)
2025-05-20 11:34:26 - INFO - EVALUATING - Epoch: [13][30/40]	Time 0.070 (0.098)	Data 0.000 (0.025)	Loss 0.8043 (0.7750)	Prec@1 77.344 (79.612)	Prec@5 98.828 (98.110)
2025-05-20 11:34:27 - INFO - 
 Epoch: 14	Training Loss 0.7571 	Training Prec@1 80.430 	Training Prec@5 98.600 	Validation Loss 0.7740 	Validation Prec@1 79.640 	Validation Prec@5 98.180 

2025-05-20 11:34:27 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:34:27 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:34:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:34:28 - INFO - TRAINING - Epoch: [14][0/196]	Time 0.911 (0.911)	Data 0.811 (0.811)	Loss 0.6731 (0.6731)	Prec@1 82.031 (82.031)	Prec@5 99.609 (99.609)
2025-05-20 11:34:30 - INFO - TRAINING - Epoch: [14][10/196]	Time 0.140 (0.216)	Data 0.000 (0.087)	Loss 0.6765 (0.7372)	Prec@1 85.547 (81.676)	Prec@5 98.828 (98.828)
2025-05-20 11:34:31 - INFO - TRAINING - Epoch: [14][20/196]	Time 0.135 (0.179)	Data 0.000 (0.048)	Loss 0.7200 (0.7507)	Prec@1 82.422 (80.618)	Prec@5 98.828 (98.717)
2025-05-20 11:34:32 - INFO - TRAINING - Epoch: [14][30/196]	Time 0.133 (0.164)	Data 0.000 (0.034)	Loss 0.8004 (0.7501)	Prec@1 77.734 (80.494)	Prec@5 98.828 (98.778)
2025-05-20 11:34:34 - INFO - TRAINING - Epoch: [14][40/196]	Time 0.138 (0.160)	Data 0.012 (0.026)	Loss 0.7129 (0.7478)	Prec@1 80.469 (80.621)	Prec@5 99.219 (98.704)
2025-05-20 11:34:35 - INFO - TRAINING - Epoch: [14][50/196]	Time 0.132 (0.158)	Data 0.001 (0.022)	Loss 0.7536 (0.7424)	Prec@1 81.250 (80.898)	Prec@5 98.438 (98.667)
2025-05-20 11:34:37 - INFO - TRAINING - Epoch: [14][60/196]	Time 0.131 (0.157)	Data 0.000 (0.019)	Loss 0.7824 (0.7445)	Prec@1 79.297 (80.827)	Prec@5 99.219 (98.732)
2025-05-20 11:34:38 - INFO - TRAINING - Epoch: [14][70/196]	Time 0.136 (0.154)	Data 0.000 (0.017)	Loss 0.7039 (0.7391)	Prec@1 84.766 (81.217)	Prec@5 97.266 (98.757)
2025-05-20 11:34:39 - INFO - TRAINING - Epoch: [14][80/196]	Time 0.134 (0.151)	Data 0.000 (0.015)	Loss 0.7507 (0.7396)	Prec@1 81.250 (81.231)	Prec@5 98.438 (98.746)
2025-05-20 11:34:41 - INFO - TRAINING - Epoch: [14][90/196]	Time 0.134 (0.149)	Data 0.001 (0.014)	Loss 0.6781 (0.7420)	Prec@1 85.547 (81.143)	Prec@5 98.438 (98.704)
2025-05-20 11:34:42 - INFO - TRAINING - Epoch: [14][100/196]	Time 0.134 (0.148)	Data 0.002 (0.013)	Loss 0.7564 (0.7428)	Prec@1 80.469 (81.107)	Prec@5 98.438 (98.724)
2025-05-20 11:34:43 - INFO - TRAINING - Epoch: [14][110/196]	Time 0.133 (0.146)	Data 0.006 (0.012)	Loss 0.6734 (0.7416)	Prec@1 84.766 (81.194)	Prec@5 97.656 (98.694)
2025-05-20 11:34:45 - INFO - TRAINING - Epoch: [14][120/196]	Time 0.134 (0.145)	Data 0.000 (0.011)	Loss 0.8223 (0.7434)	Prec@1 76.953 (81.137)	Prec@5 98.047 (98.689)
2025-05-20 11:34:46 - INFO - TRAINING - Epoch: [14][130/196]	Time 0.133 (0.145)	Data 0.000 (0.011)	Loss 0.8136 (0.7442)	Prec@1 78.516 (81.095)	Prec@5 97.656 (98.667)
2025-05-20 11:34:48 - INFO - TRAINING - Epoch: [14][140/196]	Time 0.153 (0.145)	Data 0.003 (0.010)	Loss 0.7403 (0.7443)	Prec@1 82.031 (81.053)	Prec@5 98.828 (98.645)
2025-05-20 11:34:49 - INFO - TRAINING - Epoch: [14][150/196]	Time 0.149 (0.145)	Data 0.000 (0.010)	Loss 0.7077 (0.7445)	Prec@1 81.250 (81.002)	Prec@5 99.609 (98.668)
2025-05-20 11:34:50 - INFO - TRAINING - Epoch: [14][160/196]	Time 0.133 (0.144)	Data 0.007 (0.010)	Loss 0.7624 (0.7440)	Prec@1 78.906 (81.027)	Prec@5 98.828 (98.675)
2025-05-20 11:34:52 - INFO - TRAINING - Epoch: [14][170/196]	Time 0.134 (0.144)	Data 0.000 (0.009)	Loss 0.7222 (0.7454)	Prec@1 82.812 (80.971)	Prec@5 99.219 (98.666)
2025-05-20 11:34:53 - INFO - TRAINING - Epoch: [14][180/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.7063 (0.7441)	Prec@1 82.422 (81.071)	Prec@5 99.609 (98.671)
2025-05-20 11:34:54 - INFO - TRAINING - Epoch: [14][190/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.6929 (0.7431)	Prec@1 82.812 (81.084)	Prec@5 99.219 (98.665)
2025-05-20 11:34:56 - INFO - EVALUATING - Epoch: [14][0/40]	Time 0.744 (0.744)	Data 0.672 (0.672)	Loss 0.8169 (0.8169)	Prec@1 78.906 (78.906)	Prec@5 96.875 (96.875)
2025-05-20 11:34:57 - INFO - EVALUATING - Epoch: [14][10/40]	Time 0.078 (0.138)	Data 0.000 (0.066)	Loss 0.7070 (0.7948)	Prec@1 82.031 (78.374)	Prec@5 98.828 (97.763)
2025-05-20 11:34:57 - INFO - EVALUATING - Epoch: [14][20/40]	Time 0.080 (0.109)	Data 0.005 (0.036)	Loss 0.8099 (0.7980)	Prec@1 77.734 (78.330)	Prec@5 98.438 (97.638)
2025-05-20 11:34:58 - INFO - EVALUATING - Epoch: [14][30/40]	Time 0.070 (0.098)	Data 0.000 (0.025)	Loss 0.9072 (0.8036)	Prec@1 72.266 (78.201)	Prec@5 98.438 (97.883)
2025-05-20 11:34:59 - INFO - 
 Epoch: 15	Training Loss 0.7436 	Training Prec@1 81.092 	Training Prec@5 98.666 	Validation Loss 0.8019 	Validation Prec@1 78.150 	Validation Prec@5 97.910 

2025-05-20 11:34:59 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:34:59 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:34:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:35:00 - INFO - TRAINING - Epoch: [15][0/196]	Time 1.392 (1.392)	Data 1.160 (1.160)	Loss 0.7087 (0.7087)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
2025-05-20 11:35:02 - INFO - TRAINING - Epoch: [15][10/196]	Time 0.154 (0.259)	Data 0.005 (0.110)	Loss 0.7875 (0.7411)	Prec@1 78.516 (81.605)	Prec@5 98.438 (98.544)
2025-05-20 11:35:03 - INFO - TRAINING - Epoch: [15][20/196]	Time 0.151 (0.211)	Data 0.003 (0.060)	Loss 0.7594 (0.7396)	Prec@1 80.859 (81.622)	Prec@5 98.438 (98.475)
2025-05-20 11:35:05 - INFO - TRAINING - Epoch: [15][30/196]	Time 0.132 (0.188)	Data 0.007 (0.042)	Loss 0.7075 (0.7347)	Prec@1 82.031 (81.666)	Prec@5 99.219 (98.513)
2025-05-20 11:35:06 - INFO - TRAINING - Epoch: [15][40/196]	Time 0.133 (0.175)	Data 0.009 (0.033)	Loss 0.6746 (0.7361)	Prec@1 85.547 (81.469)	Prec@5 100.000 (98.552)
2025-05-20 11:35:07 - INFO - TRAINING - Epoch: [15][50/196]	Time 0.133 (0.167)	Data 0.000 (0.027)	Loss 0.7477 (0.7369)	Prec@1 81.641 (81.373)	Prec@5 97.656 (98.667)
2025-05-20 11:35:09 - INFO - TRAINING - Epoch: [15][60/196]	Time 0.135 (0.162)	Data 0.000 (0.023)	Loss 0.7586 (0.7339)	Prec@1 78.906 (81.500)	Prec@5 98.438 (98.726)
2025-05-20 11:35:10 - INFO - TRAINING - Epoch: [15][70/196]	Time 0.133 (0.158)	Data 0.000 (0.020)	Loss 0.7002 (0.7347)	Prec@1 84.375 (81.470)	Prec@5 100.000 (98.751)
2025-05-20 11:35:12 - INFO - TRAINING - Epoch: [15][80/196]	Time 0.133 (0.155)	Data 0.006 (0.018)	Loss 0.7594 (0.7361)	Prec@1 81.641 (81.366)	Prec@5 98.828 (98.770)
2025-05-20 11:35:13 - INFO - TRAINING - Epoch: [15][90/196]	Time 0.137 (0.153)	Data 0.000 (0.016)	Loss 0.7723 (0.7347)	Prec@1 81.641 (81.413)	Prec@5 98.438 (98.768)
2025-05-20 11:35:14 - INFO - TRAINING - Epoch: [15][100/196]	Time 0.155 (0.152)	Data 0.012 (0.015)	Loss 0.7725 (0.7335)	Prec@1 82.422 (81.509)	Prec@5 98.047 (98.755)
2025-05-20 11:35:16 - INFO - TRAINING - Epoch: [15][110/196]	Time 0.149 (0.151)	Data 0.005 (0.014)	Loss 0.6569 (0.7326)	Prec@1 85.547 (81.556)	Prec@5 98.828 (98.733)
2025-05-20 11:35:17 - INFO - TRAINING - Epoch: [15][120/196]	Time 0.133 (0.150)	Data 0.003 (0.013)	Loss 0.6918 (0.7329)	Prec@1 83.203 (81.595)	Prec@5 99.609 (98.731)
2025-05-20 11:35:18 - INFO - TRAINING - Epoch: [15][130/196]	Time 0.134 (0.149)	Data 0.000 (0.013)	Loss 0.7151 (0.7334)	Prec@1 80.859 (81.521)	Prec@5 99.609 (98.739)
2025-05-20 11:35:20 - INFO - TRAINING - Epoch: [15][140/196]	Time 0.133 (0.148)	Data 0.000 (0.012)	Loss 0.7685 (0.7337)	Prec@1 80.078 (81.527)	Prec@5 97.656 (98.720)
2025-05-20 11:35:21 - INFO - TRAINING - Epoch: [15][150/196]	Time 0.135 (0.147)	Data 0.000 (0.011)	Loss 0.7737 (0.7338)	Prec@1 79.297 (81.540)	Prec@5 97.266 (98.712)
2025-05-20 11:35:22 - INFO - TRAINING - Epoch: [15][160/196]	Time 0.133 (0.146)	Data 0.000 (0.011)	Loss 0.7583 (0.7332)	Prec@1 79.297 (81.561)	Prec@5 98.438 (98.704)
2025-05-20 11:35:24 - INFO - TRAINING - Epoch: [15][170/196]	Time 0.134 (0.145)	Data 0.000 (0.010)	Loss 0.7654 (0.7337)	Prec@1 80.078 (81.513)	Prec@5 99.219 (98.721)
2025-05-20 11:35:25 - INFO - TRAINING - Epoch: [15][180/196]	Time 0.135 (0.145)	Data 0.000 (0.009)	Loss 0.6779 (0.7334)	Prec@1 84.766 (81.507)	Prec@5 98.828 (98.735)
2025-05-20 11:35:26 - INFO - TRAINING - Epoch: [15][190/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.7477 (0.7327)	Prec@1 78.516 (81.512)	Prec@5 99.219 (98.734)
2025-05-20 11:35:29 - INFO - EVALUATING - Epoch: [15][0/40]	Time 1.250 (1.250)	Data 1.171 (1.171)	Loss 0.7316 (0.7316)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
2025-05-20 11:35:29 - INFO - EVALUATING - Epoch: [15][10/40]	Time 0.069 (0.183)	Data 0.000 (0.110)	Loss 0.6574 (0.7349)	Prec@1 85.156 (81.214)	Prec@5 98.047 (98.331)
2025-05-20 11:35:30 - INFO - EVALUATING - Epoch: [15][20/40]	Time 0.071 (0.134)	Data 0.003 (0.059)	Loss 0.7024 (0.7268)	Prec@1 83.203 (81.417)	Prec@5 98.438 (98.326)
2025-05-20 11:35:31 - INFO - EVALUATING - Epoch: [15][30/40]	Time 0.070 (0.114)	Data 0.000 (0.041)	Loss 0.7545 (0.7265)	Prec@1 77.734 (81.414)	Prec@5 99.219 (98.463)
2025-05-20 11:35:32 - INFO - 
 Epoch: 16	Training Loss 0.7328 	Training Prec@1 81.500 	Training Prec@5 98.720 	Validation Loss 0.7258 	Validation Prec@1 81.520 	Validation Prec@5 98.500 

2025-05-20 11:35:32 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:35:32 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:35:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:35:33 - INFO - TRAINING - Epoch: [16][0/196]	Time 0.998 (0.998)	Data 0.903 (0.903)	Loss 0.6525 (0.6525)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
2025-05-20 11:35:34 - INFO - TRAINING - Epoch: [16][10/196]	Time 0.142 (0.223)	Data 0.000 (0.088)	Loss 0.7223 (0.7088)	Prec@1 82.422 (82.528)	Prec@5 98.438 (99.148)
2025-05-20 11:35:36 - INFO - TRAINING - Epoch: [16][20/196]	Time 0.132 (0.182)	Data 0.009 (0.047)	Loss 0.6853 (0.7022)	Prec@1 84.375 (82.868)	Prec@5 98.047 (99.070)
2025-05-20 11:35:37 - INFO - TRAINING - Epoch: [16][30/196]	Time 0.133 (0.167)	Data 0.003 (0.033)	Loss 0.6689 (0.7039)	Prec@1 83.594 (82.787)	Prec@5 99.609 (99.005)
2025-05-20 11:35:38 - INFO - TRAINING - Epoch: [16][40/196]	Time 0.139 (0.159)	Data 0.007 (0.026)	Loss 0.6915 (0.7096)	Prec@1 82.812 (82.698)	Prec@5 99.219 (98.962)
2025-05-20 11:35:40 - INFO - TRAINING - Epoch: [16][50/196]	Time 0.144 (0.156)	Data 0.008 (0.022)	Loss 0.7181 (0.7105)	Prec@1 83.203 (82.575)	Prec@5 99.609 (98.981)
2025-05-20 11:35:41 - INFO - TRAINING - Epoch: [16][60/196]	Time 0.138 (0.154)	Data 0.000 (0.020)	Loss 0.7821 (0.7118)	Prec@1 78.906 (82.441)	Prec@5 99.609 (98.937)
2025-05-20 11:35:42 - INFO - TRAINING - Epoch: [16][70/196]	Time 0.134 (0.152)	Data 0.006 (0.018)	Loss 0.6857 (0.7126)	Prec@1 82.422 (82.400)	Prec@5 100.000 (98.933)
2025-05-20 11:35:44 - INFO - TRAINING - Epoch: [16][80/196]	Time 0.141 (0.150)	Data 0.000 (0.016)	Loss 0.6691 (0.7142)	Prec@1 83.984 (82.200)	Prec@5 99.219 (98.929)
2025-05-20 11:35:45 - INFO - TRAINING - Epoch: [16][90/196]	Time 0.135 (0.148)	Data 0.010 (0.014)	Loss 0.6959 (0.7160)	Prec@1 82.031 (82.091)	Prec@5 98.438 (98.927)
2025-05-20 11:35:46 - INFO - TRAINING - Epoch: [16][100/196]	Time 0.134 (0.147)	Data 0.000 (0.013)	Loss 0.6707 (0.7153)	Prec@1 83.984 (82.221)	Prec@5 99.219 (98.909)
2025-05-20 11:35:48 - INFO - TRAINING - Epoch: [16][110/196]	Time 0.134 (0.145)	Data 0.007 (0.012)	Loss 0.7353 (0.7151)	Prec@1 82.812 (82.207)	Prec@5 98.828 (98.906)
2025-05-20 11:35:49 - INFO - TRAINING - Epoch: [16][120/196]	Time 0.134 (0.145)	Data 0.000 (0.012)	Loss 0.7550 (0.7156)	Prec@1 80.078 (82.154)	Prec@5 99.219 (98.883)
2025-05-20 11:35:51 - INFO - TRAINING - Epoch: [16][130/196]	Time 0.134 (0.144)	Data 0.011 (0.011)	Loss 0.6963 (0.7174)	Prec@1 84.375 (82.145)	Prec@5 99.219 (98.852)
2025-05-20 11:35:52 - INFO - TRAINING - Epoch: [16][140/196]	Time 0.145 (0.143)	Data 0.003 (0.010)	Loss 0.7608 (0.7186)	Prec@1 80.078 (82.114)	Prec@5 99.609 (98.853)
2025-05-20 11:35:53 - INFO - TRAINING - Epoch: [16][150/196]	Time 0.146 (0.143)	Data 0.000 (0.010)	Loss 0.7225 (0.7195)	Prec@1 80.469 (82.075)	Prec@5 98.438 (98.846)
2025-05-20 11:35:55 - INFO - TRAINING - Epoch: [16][160/196]	Time 0.141 (0.143)	Data 0.000 (0.010)	Loss 0.7899 (0.7210)	Prec@1 78.516 (81.980)	Prec@5 99.219 (98.862)
2025-05-20 11:35:56 - INFO - TRAINING - Epoch: [16][170/196]	Time 0.134 (0.143)	Data 0.006 (0.009)	Loss 0.6587 (0.7199)	Prec@1 85.547 (81.995)	Prec@5 99.219 (98.883)
2025-05-20 11:35:57 - INFO - TRAINING - Epoch: [16][180/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.7811 (0.7196)	Prec@1 79.297 (82.001)	Prec@5 97.656 (98.871)
2025-05-20 11:35:59 - INFO - TRAINING - Epoch: [16][190/196]	Time 0.130 (0.142)	Data 0.000 (0.009)	Loss 0.6830 (0.7198)	Prec@1 83.203 (82.019)	Prec@5 99.219 (98.855)
2025-05-20 11:36:00 - INFO - EVALUATING - Epoch: [16][0/40]	Time 0.698 (0.698)	Data 0.629 (0.629)	Loss 0.7144 (0.7144)	Prec@1 81.641 (81.641)	Prec@5 98.438 (98.438)
2025-05-20 11:36:01 - INFO - EVALUATING - Epoch: [16][10/40]	Time 0.081 (0.136)	Data 0.000 (0.062)	Loss 0.7168 (0.7525)	Prec@1 80.469 (80.433)	Prec@5 99.219 (98.473)
2025-05-20 11:36:02 - INFO - EVALUATING - Epoch: [16][20/40]	Time 0.072 (0.108)	Data 0.000 (0.034)	Loss 0.7284 (0.7491)	Prec@1 82.422 (80.692)	Prec@5 99.219 (98.382)
2025-05-20 11:36:03 - INFO - EVALUATING - Epoch: [16][30/40]	Time 0.069 (0.097)	Data 0.000 (0.023)	Loss 0.7733 (0.7464)	Prec@1 77.734 (80.784)	Prec@5 98.438 (98.400)
2025-05-20 11:36:03 - INFO - 
 Epoch: 17	Training Loss 0.7200 	Training Prec@1 82.002 	Training Prec@5 98.862 	Validation Loss 0.7474 	Validation Prec@1 80.830 	Validation Prec@5 98.370 

2025-05-20 11:36:03 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:36:03 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:36:03 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:36:04 - INFO - TRAINING - Epoch: [17][0/196]	Time 0.953 (0.953)	Data 0.827 (0.827)	Loss 0.7601 (0.7601)	Prec@1 80.469 (80.469)	Prec@5 98.047 (98.047)
2025-05-20 11:36:06 - INFO - TRAINING - Epoch: [17][10/196]	Time 0.131 (0.221)	Data 0.011 (0.080)	Loss 0.7311 (0.7101)	Prec@1 80.469 (82.670)	Prec@5 99.219 (98.757)
2025-05-20 11:36:07 - INFO - TRAINING - Epoch: [17][20/196]	Time 0.160 (0.192)	Data 0.000 (0.046)	Loss 0.7428 (0.7135)	Prec@1 81.250 (82.366)	Prec@5 99.219 (98.921)
2025-05-20 11:36:09 - INFO - TRAINING - Epoch: [17][30/196]	Time 0.143 (0.182)	Data 0.015 (0.033)	Loss 0.8283 (0.7216)	Prec@1 78.125 (82.157)	Prec@5 97.656 (98.702)
2025-05-20 11:36:10 - INFO - TRAINING - Epoch: [17][40/196]	Time 0.137 (0.171)	Data 0.000 (0.026)	Loss 0.6972 (0.7182)	Prec@1 83.203 (82.355)	Prec@5 98.047 (98.676)
2025-05-20 11:36:12 - INFO - TRAINING - Epoch: [17][50/196]	Time 0.135 (0.164)	Data 0.000 (0.022)	Loss 0.7001 (0.7199)	Prec@1 83.594 (82.169)	Prec@5 98.828 (98.644)
2025-05-20 11:36:13 - INFO - TRAINING - Epoch: [17][60/196]	Time 0.133 (0.159)	Data 0.000 (0.018)	Loss 0.7423 (0.7165)	Prec@1 80.859 (82.332)	Prec@5 97.656 (98.732)
2025-05-20 11:36:14 - INFO - TRAINING - Epoch: [17][70/196]	Time 0.138 (0.156)	Data 0.000 (0.016)	Loss 0.7002 (0.7126)	Prec@1 82.812 (82.449)	Prec@5 98.828 (98.746)
2025-05-20 11:36:16 - INFO - TRAINING - Epoch: [17][80/196]	Time 0.136 (0.153)	Data 0.000 (0.014)	Loss 0.7839 (0.7126)	Prec@1 77.344 (82.422)	Prec@5 98.438 (98.761)
2025-05-20 11:36:17 - INFO - TRAINING - Epoch: [17][90/196]	Time 0.134 (0.151)	Data 0.000 (0.013)	Loss 0.7289 (0.7105)	Prec@1 80.859 (82.576)	Prec@5 99.219 (98.738)
2025-05-20 11:36:18 - INFO - TRAINING - Epoch: [17][100/196]	Time 0.140 (0.149)	Data 0.000 (0.012)	Loss 0.7181 (0.7123)	Prec@1 83.203 (82.464)	Prec@5 98.047 (98.724)
2025-05-20 11:36:20 - INFO - TRAINING - Epoch: [17][110/196]	Time 0.158 (0.149)	Data 0.015 (0.011)	Loss 0.6909 (0.7125)	Prec@1 82.812 (82.443)	Prec@5 99.609 (98.747)
2025-05-20 11:36:21 - INFO - TRAINING - Epoch: [17][120/196]	Time 0.147 (0.148)	Data 0.005 (0.011)	Loss 0.7671 (0.7130)	Prec@1 78.516 (82.412)	Prec@5 100.000 (98.744)
2025-05-20 11:36:23 - INFO - TRAINING - Epoch: [17][130/196]	Time 0.140 (0.148)	Data 0.000 (0.011)	Loss 0.7558 (0.7133)	Prec@1 81.641 (82.386)	Prec@5 99.219 (98.742)
2025-05-20 11:36:24 - INFO - TRAINING - Epoch: [17][140/196]	Time 0.134 (0.147)	Data 0.003 (0.010)	Loss 0.6469 (0.7125)	Prec@1 85.938 (82.391)	Prec@5 99.609 (98.762)
2025-05-20 11:36:25 - INFO - TRAINING - Epoch: [17][150/196]	Time 0.133 (0.146)	Data 0.000 (0.010)	Loss 0.7046 (0.7129)	Prec@1 83.984 (82.380)	Prec@5 99.609 (98.771)
2025-05-20 11:36:27 - INFO - TRAINING - Epoch: [17][160/196]	Time 0.134 (0.145)	Data 0.007 (0.009)	Loss 0.7605 (0.7128)	Prec@1 78.906 (82.405)	Prec@5 99.609 (98.775)
2025-05-20 11:36:28 - INFO - TRAINING - Epoch: [17][170/196]	Time 0.133 (0.144)	Data 0.008 (0.009)	Loss 0.6630 (0.7124)	Prec@1 84.375 (82.445)	Prec@5 99.219 (98.776)
2025-05-20 11:36:29 - INFO - TRAINING - Epoch: [17][180/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.7749 (0.7121)	Prec@1 80.078 (82.459)	Prec@5 96.875 (98.772)
2025-05-20 11:36:31 - INFO - TRAINING - Epoch: [17][190/196]	Time 0.130 (0.143)	Data 0.000 (0.008)	Loss 0.7070 (0.7115)	Prec@1 80.469 (82.471)	Prec@5 98.828 (98.787)
2025-05-20 11:36:33 - INFO - EVALUATING - Epoch: [17][0/40]	Time 1.205 (1.205)	Data 1.120 (1.120)	Loss 0.7066 (0.7066)	Prec@1 82.422 (82.422)	Prec@5 98.047 (98.047)
2025-05-20 11:36:34 - INFO - EVALUATING - Epoch: [17][10/40]	Time 0.089 (0.197)	Data 0.005 (0.118)	Loss 0.7189 (0.7340)	Prec@1 81.250 (81.357)	Prec@5 98.047 (97.905)
2025-05-20 11:36:35 - INFO - EVALUATING - Epoch: [17][20/40]	Time 0.073 (0.148)	Data 0.006 (0.069)	Loss 0.7004 (0.7265)	Prec@1 81.641 (81.678)	Prec@5 98.828 (98.121)
2025-05-20 11:36:35 - INFO - EVALUATING - Epoch: [17][30/40]	Time 0.077 (0.126)	Data 0.000 (0.048)	Loss 0.8120 (0.7295)	Prec@1 80.469 (81.552)	Prec@5 97.656 (98.211)
2025-05-20 11:36:36 - INFO - 
 Epoch: 18	Training Loss 0.7118 	Training Prec@1 82.474 	Training Prec@5 98.776 	Validation Loss 0.7279 	Validation Prec@1 81.560 	Validation Prec@5 98.360 

2025-05-20 11:36:36 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:36:36 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:36:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:36:37 - INFO - TRAINING - Epoch: [18][0/196]	Time 1.044 (1.044)	Data 0.941 (0.941)	Loss 0.6987 (0.6987)	Prec@1 81.641 (81.641)	Prec@5 99.219 (99.219)
2025-05-20 11:36:39 - INFO - TRAINING - Epoch: [18][10/196]	Time 0.135 (0.222)	Data 0.006 (0.090)	Loss 0.7740 (0.7064)	Prec@1 79.688 (82.351)	Prec@5 99.219 (99.148)
2025-05-20 11:36:40 - INFO - TRAINING - Epoch: [18][20/196]	Time 0.133 (0.183)	Data 0.005 (0.050)	Loss 0.6405 (0.7021)	Prec@1 86.328 (82.794)	Prec@5 99.609 (99.144)
2025-05-20 11:36:41 - INFO - TRAINING - Epoch: [18][30/196]	Time 0.134 (0.167)	Data 0.008 (0.035)	Loss 0.7235 (0.7075)	Prec@1 80.469 (82.371)	Prec@5 99.609 (99.042)
2025-05-20 11:36:43 - INFO - TRAINING - Epoch: [18][40/196]	Time 0.132 (0.159)	Data 0.000 (0.027)	Loss 0.7600 (0.7062)	Prec@1 79.688 (82.441)	Prec@5 98.828 (99.038)
2025-05-20 11:36:44 - INFO - TRAINING - Epoch: [18][50/196]	Time 0.132 (0.154)	Data 0.001 (0.022)	Loss 0.6553 (0.7003)	Prec@1 85.156 (82.629)	Prec@5 99.609 (99.096)
2025-05-20 11:36:45 - INFO - TRAINING - Epoch: [18][60/196]	Time 0.147 (0.152)	Data 0.003 (0.019)	Loss 0.6710 (0.6989)	Prec@1 83.984 (82.633)	Prec@5 100.000 (99.084)
2025-05-20 11:36:47 - INFO - TRAINING - Epoch: [18][70/196]	Time 0.155 (0.151)	Data 0.011 (0.016)	Loss 0.7119 (0.7030)	Prec@1 81.250 (82.471)	Prec@5 99.609 (99.076)
2025-05-20 11:36:48 - INFO - TRAINING - Epoch: [18][80/196]	Time 0.135 (0.150)	Data 0.000 (0.015)	Loss 0.7213 (0.7043)	Prec@1 83.594 (82.451)	Prec@5 98.828 (99.089)
2025-05-20 11:36:50 - INFO - TRAINING - Epoch: [18][90/196]	Time 0.132 (0.148)	Data 0.003 (0.014)	Loss 0.6970 (0.7036)	Prec@1 84.375 (82.542)	Prec@5 99.219 (99.111)
2025-05-20 11:36:51 - INFO - TRAINING - Epoch: [18][100/196]	Time 0.134 (0.147)	Data 0.008 (0.012)	Loss 0.7037 (0.7042)	Prec@1 84.766 (82.565)	Prec@5 99.219 (99.107)
2025-05-20 11:36:52 - INFO - TRAINING - Epoch: [18][110/196]	Time 0.134 (0.146)	Data 0.000 (0.011)	Loss 0.7160 (0.7050)	Prec@1 82.812 (82.598)	Prec@5 98.438 (99.064)
2025-05-20 11:36:54 - INFO - TRAINING - Epoch: [18][120/196]	Time 0.134 (0.145)	Data 0.000 (0.011)	Loss 0.7152 (0.7057)	Prec@1 80.859 (82.554)	Prec@5 98.828 (99.048)
2025-05-20 11:36:55 - INFO - TRAINING - Epoch: [18][130/196]	Time 0.134 (0.144)	Data 0.000 (0.010)	Loss 0.7127 (0.7044)	Prec@1 81.641 (82.622)	Prec@5 98.828 (99.028)
2025-05-20 11:36:56 - INFO - TRAINING - Epoch: [18][140/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.7138 (0.7044)	Prec@1 82.812 (82.655)	Prec@5 99.219 (99.005)
2025-05-20 11:36:58 - INFO - TRAINING - Epoch: [18][150/196]	Time 0.132 (0.142)	Data 0.000 (0.009)	Loss 0.7408 (0.7038)	Prec@1 78.906 (82.675)	Prec@5 98.047 (98.996)
2025-05-20 11:36:59 - INFO - TRAINING - Epoch: [18][160/196]	Time 0.147 (0.142)	Data 0.000 (0.009)	Loss 0.6364 (0.7047)	Prec@1 85.547 (82.633)	Prec@5 99.609 (98.986)
2025-05-20 11:37:01 - INFO - TRAINING - Epoch: [18][170/196]	Time 0.152 (0.143)	Data 0.000 (0.008)	Loss 0.7818 (0.7046)	Prec@1 78.906 (82.630)	Prec@5 98.438 (98.981)
2025-05-20 11:37:02 - INFO - TRAINING - Epoch: [18][180/196]	Time 0.130 (0.142)	Data 0.000 (0.008)	Loss 0.6320 (0.7036)	Prec@1 85.938 (82.679)	Prec@5 99.219 (98.975)
2025-05-20 11:37:03 - INFO - TRAINING - Epoch: [18][190/196]	Time 0.133 (0.142)	Data 0.000 (0.008)	Loss 0.6497 (0.7037)	Prec@1 84.375 (82.675)	Prec@5 99.609 (98.953)
2025-05-20 11:37:05 - INFO - EVALUATING - Epoch: [18][0/40]	Time 0.671 (0.671)	Data 0.595 (0.595)	Loss 0.7392 (0.7392)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
2025-05-20 11:37:06 - INFO - EVALUATING - Epoch: [18][10/40]	Time 0.073 (0.142)	Data 0.000 (0.070)	Loss 0.6555 (0.7581)	Prec@1 83.594 (80.256)	Prec@5 99.219 (98.757)
2025-05-20 11:37:06 - INFO - EVALUATING - Epoch: [18][20/40]	Time 0.080 (0.111)	Data 0.003 (0.038)	Loss 0.7361 (0.7502)	Prec@1 81.641 (80.599)	Prec@5 99.609 (98.419)
2025-05-20 11:37:07 - INFO - EVALUATING - Epoch: [18][30/40]	Time 0.070 (0.099)	Data 0.000 (0.026)	Loss 0.7839 (0.7526)	Prec@1 76.562 (80.456)	Prec@5 98.828 (98.501)
2025-05-20 11:37:08 - INFO - 
 Epoch: 19	Training Loss 0.7037 	Training Prec@1 82.658 	Training Prec@5 98.958 	Validation Loss 0.7468 	Validation Prec@1 80.680 	Validation Prec@5 98.570 

2025-05-20 11:37:08 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:37:08 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:37:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:37:09 - INFO - TRAINING - Epoch: [19][0/196]	Time 1.046 (1.046)	Data 0.903 (0.903)	Loss 0.7005 (0.7005)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
2025-05-20 11:37:10 - INFO - TRAINING - Epoch: [19][10/196]	Time 0.156 (0.227)	Data 0.000 (0.088)	Loss 0.7511 (0.6993)	Prec@1 80.859 (82.955)	Prec@5 98.047 (98.757)
2025-05-20 11:37:12 - INFO - TRAINING - Epoch: [19][20/196]	Time 0.157 (0.188)	Data 0.001 (0.048)	Loss 0.6335 (0.6989)	Prec@1 87.891 (83.185)	Prec@5 98.047 (98.791)
2025-05-20 11:37:13 - INFO - TRAINING - Epoch: [19][30/196]	Time 0.142 (0.173)	Data 0.007 (0.035)	Loss 0.6443 (0.6904)	Prec@1 85.547 (83.518)	Prec@5 99.219 (98.816)
2025-05-20 11:37:15 - INFO - TRAINING - Epoch: [19][40/196]	Time 0.133 (0.167)	Data 0.011 (0.029)	Loss 0.6562 (0.6978)	Prec@1 85.547 (83.165)	Prec@5 98.828 (98.752)
2025-05-20 11:37:16 - INFO - TRAINING - Epoch: [19][50/196]	Time 0.134 (0.161)	Data 0.007 (0.025)	Loss 0.7408 (0.6926)	Prec@1 80.469 (83.249)	Prec@5 98.828 (98.790)
2025-05-20 11:37:17 - INFO - TRAINING - Epoch: [19][60/196]	Time 0.124 (0.156)	Data 0.000 (0.021)	Loss 0.6787 (0.6944)	Prec@1 83.203 (83.229)	Prec@5 99.219 (98.758)
2025-05-20 11:37:19 - INFO - TRAINING - Epoch: [19][70/196]	Time 0.133 (0.153)	Data 0.000 (0.018)	Loss 0.6614 (0.6924)	Prec@1 85.938 (83.269)	Prec@5 99.219 (98.801)
2025-05-20 11:37:20 - INFO - TRAINING - Epoch: [19][80/196]	Time 0.132 (0.151)	Data 0.002 (0.016)	Loss 0.7434 (0.6926)	Prec@1 81.641 (83.208)	Prec@5 97.656 (98.799)
2025-05-20 11:37:21 - INFO - TRAINING - Epoch: [19][90/196]	Time 0.134 (0.149)	Data 0.003 (0.015)	Loss 0.6528 (0.6908)	Prec@1 85.938 (83.242)	Prec@5 100.000 (98.862)
2025-05-20 11:37:23 - INFO - TRAINING - Epoch: [19][100/196]	Time 0.133 (0.147)	Data 0.000 (0.013)	Loss 0.6752 (0.6883)	Prec@1 81.250 (83.350)	Prec@5 99.609 (98.882)
2025-05-20 11:37:24 - INFO - TRAINING - Epoch: [19][110/196]	Time 0.136 (0.146)	Data 0.000 (0.012)	Loss 0.7216 (0.6908)	Prec@1 82.031 (83.274)	Prec@5 97.656 (98.842)
2025-05-20 11:37:26 - INFO - TRAINING - Epoch: [19][120/196]	Time 0.151 (0.146)	Data 0.000 (0.011)	Loss 0.6600 (0.6899)	Prec@1 85.547 (83.306)	Prec@5 98.828 (98.841)
2025-05-20 11:37:27 - INFO - TRAINING - Epoch: [19][130/196]	Time 0.162 (0.146)	Data 0.003 (0.011)	Loss 0.6894 (0.6893)	Prec@1 82.031 (83.302)	Prec@5 99.219 (98.852)
2025-05-20 11:37:28 - INFO - TRAINING - Epoch: [19][140/196]	Time 0.128 (0.146)	Data 0.004 (0.010)	Loss 0.7161 (0.6891)	Prec@1 82.812 (83.322)	Prec@5 99.609 (98.864)
2025-05-20 11:37:30 - INFO - TRAINING - Epoch: [19][150/196]	Time 0.134 (0.145)	Data 0.007 (0.010)	Loss 0.6958 (0.6896)	Prec@1 83.984 (83.327)	Prec@5 99.219 (98.851)
2025-05-20 11:37:31 - INFO - TRAINING - Epoch: [19][160/196]	Time 0.138 (0.144)	Data 0.007 (0.009)	Loss 0.7052 (0.6902)	Prec@1 82.422 (83.295)	Prec@5 98.828 (98.857)
2025-05-20 11:37:33 - INFO - TRAINING - Epoch: [19][170/196]	Time 0.134 (0.144)	Data 0.012 (0.009)	Loss 0.7668 (0.6907)	Prec@1 80.078 (83.240)	Prec@5 98.047 (98.862)
2025-05-20 11:37:34 - INFO - TRAINING - Epoch: [19][180/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.6929 (0.6920)	Prec@1 82.812 (83.156)	Prec@5 99.219 (98.865)
2025-05-20 11:37:35 - INFO - TRAINING - Epoch: [19][190/196]	Time 0.133 (0.143)	Data 0.000 (0.008)	Loss 0.6956 (0.6937)	Prec@1 82.422 (83.064)	Prec@5 98.438 (98.883)
2025-05-20 11:37:37 - INFO - EVALUATING - Epoch: [19][0/40]	Time 0.761 (0.761)	Data 0.690 (0.690)	Loss 0.7380 (0.7380)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)
2025-05-20 11:37:37 - INFO - EVALUATING - Epoch: [19][10/40]	Time 0.085 (0.138)	Data 0.009 (0.065)	Loss 0.6844 (0.7359)	Prec@1 84.375 (80.930)	Prec@5 99.219 (98.651)
2025-05-20 11:37:38 - INFO - EVALUATING - Epoch: [19][20/40]	Time 0.081 (0.109)	Data 0.007 (0.036)	Loss 0.6839 (0.7376)	Prec@1 82.031 (81.045)	Prec@5 98.438 (98.400)
2025-05-20 11:37:39 - INFO - EVALUATING - Epoch: [19][30/40]	Time 0.071 (0.099)	Data 0.000 (0.025)	Loss 0.7680 (0.7375)	Prec@1 79.297 (81.036)	Prec@5 98.047 (98.538)
2025-05-20 11:37:40 - INFO - 
 Epoch: 20	Training Loss 0.6942 	Training Prec@1 83.068 	Training Prec@5 98.872 	Validation Loss 0.7377 	Validation Prec@1 81.090 	Validation Prec@5 98.670 

2025-05-20 11:37:40 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:37:40 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:37:40 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:37:42 - INFO - TRAINING - Epoch: [20][0/196]	Time 1.665 (1.665)	Data 1.516 (1.516)	Loss 0.6244 (0.6244)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
2025-05-20 11:37:43 - INFO - TRAINING - Epoch: [20][10/196]	Time 0.147 (0.283)	Data 0.005 (0.145)	Loss 0.7475 (0.6931)	Prec@1 80.859 (83.487)	Prec@5 99.219 (99.041)
2025-05-20 11:37:44 - INFO - TRAINING - Epoch: [20][20/196]	Time 0.134 (0.213)	Data 0.000 (0.077)	Loss 0.7309 (0.7008)	Prec@1 81.250 (82.812)	Prec@5 98.438 (98.958)
2025-05-20 11:37:46 - INFO - TRAINING - Epoch: [20][30/196]	Time 0.134 (0.188)	Data 0.000 (0.052)	Loss 0.6087 (0.6910)	Prec@1 87.891 (83.266)	Prec@5 99.609 (98.967)
2025-05-20 11:37:47 - INFO - TRAINING - Epoch: [20][40/196]	Time 0.135 (0.174)	Data 0.000 (0.040)	Loss 0.6706 (0.6820)	Prec@1 83.594 (83.651)	Prec@5 99.219 (99.066)
2025-05-20 11:37:48 - INFO - TRAINING - Epoch: [20][50/196]	Time 0.136 (0.166)	Data 0.000 (0.032)	Loss 0.6697 (0.6823)	Prec@1 82.422 (83.632)	Prec@5 99.219 (99.050)
2025-05-20 11:37:50 - INFO - TRAINING - Epoch: [20][60/196]	Time 0.134 (0.161)	Data 0.000 (0.027)	Loss 0.6346 (0.6866)	Prec@1 83.984 (83.338)	Prec@5 99.609 (99.071)
2025-05-20 11:37:51 - INFO - TRAINING - Epoch: [20][70/196]	Time 0.136 (0.157)	Data 0.000 (0.024)	Loss 0.6511 (0.6849)	Prec@1 84.766 (83.478)	Prec@5 99.609 (99.076)
2025-05-20 11:37:52 - INFO - TRAINING - Epoch: [20][80/196]	Time 0.133 (0.155)	Data 0.000 (0.021)	Loss 0.7192 (0.6850)	Prec@1 80.469 (83.449)	Prec@5 99.609 (99.050)
2025-05-20 11:37:54 - INFO - TRAINING - Epoch: [20][90/196]	Time 0.145 (0.154)	Data 0.035 (0.019)	Loss 0.6226 (0.6823)	Prec@1 86.719 (83.555)	Prec@5 98.828 (99.060)
2025-05-20 11:37:55 - INFO - TRAINING - Epoch: [20][100/196]	Time 0.133 (0.153)	Data 0.000 (0.018)	Loss 0.7113 (0.6826)	Prec@1 80.469 (83.559)	Prec@5 99.609 (99.041)
2025-05-20 11:37:57 - INFO - TRAINING - Epoch: [20][110/196]	Time 0.134 (0.151)	Data 0.000 (0.016)	Loss 0.6273 (0.6820)	Prec@1 84.766 (83.583)	Prec@5 98.828 (99.032)
2025-05-20 11:37:58 - INFO - TRAINING - Epoch: [20][120/196]	Time 0.132 (0.150)	Data 0.000 (0.015)	Loss 0.6210 (0.6803)	Prec@1 87.500 (83.691)	Prec@5 98.828 (99.041)
2025-05-20 11:37:59 - INFO - TRAINING - Epoch: [20][130/196]	Time 0.133 (0.148)	Data 0.000 (0.014)	Loss 0.6526 (0.6828)	Prec@1 85.547 (83.621)	Prec@5 98.828 (99.013)
2025-05-20 11:38:01 - INFO - TRAINING - Epoch: [20][140/196]	Time 0.133 (0.147)	Data 0.007 (0.014)	Loss 0.6967 (0.6812)	Prec@1 81.641 (83.713)	Prec@5 98.047 (98.997)
2025-05-20 11:38:02 - INFO - TRAINING - Epoch: [20][150/196]	Time 0.140 (0.146)	Data 0.000 (0.013)	Loss 0.6627 (0.6817)	Prec@1 84.766 (83.692)	Prec@5 99.609 (98.991)
2025-05-20 11:38:03 - INFO - TRAINING - Epoch: [20][160/196]	Time 0.132 (0.146)	Data 0.000 (0.012)	Loss 0.7430 (0.6838)	Prec@1 82.031 (83.606)	Prec@5 99.219 (98.979)
2025-05-20 11:38:05 - INFO - TRAINING - Epoch: [20][170/196]	Time 0.132 (0.145)	Data 0.001 (0.011)	Loss 0.6716 (0.6829)	Prec@1 85.547 (83.665)	Prec@5 98.828 (98.972)
2025-05-20 11:38:06 - INFO - TRAINING - Epoch: [20][180/196]	Time 0.140 (0.145)	Data 0.000 (0.011)	Loss 0.7355 (0.6838)	Prec@1 80.078 (83.602)	Prec@5 99.219 (98.964)
2025-05-20 11:38:07 - INFO - TRAINING - Epoch: [20][190/196]	Time 0.130 (0.144)	Data 0.000 (0.010)	Loss 0.7867 (0.6846)	Prec@1 77.344 (83.534)	Prec@5 97.656 (98.951)
2025-05-20 11:38:09 - INFO - EVALUATING - Epoch: [20][0/40]	Time 0.631 (0.631)	Data 0.558 (0.558)	Loss 0.7242 (0.7242)	Prec@1 82.422 (82.422)	Prec@5 98.828 (98.828)
2025-05-20 11:38:10 - INFO - EVALUATING - Epoch: [20][10/40]	Time 0.080 (0.146)	Data 0.000 (0.072)	Loss 0.6608 (0.7221)	Prec@1 83.984 (80.611)	Prec@5 98.828 (98.864)
2025-05-20 11:38:11 - INFO - EVALUATING - Epoch: [20][20/40]	Time 0.079 (0.113)	Data 0.005 (0.040)	Loss 0.6694 (0.7122)	Prec@1 85.547 (81.715)	Prec@5 100.000 (98.586)
2025-05-20 11:38:11 - INFO - EVALUATING - Epoch: [20][30/40]	Time 0.070 (0.100)	Data 0.000 (0.027)	Loss 0.7359 (0.7180)	Prec@1 78.906 (81.502)	Prec@5 98.828 (98.715)
2025-05-20 11:38:12 - INFO - 
 Epoch: 21	Training Loss 0.6851 	Training Prec@1 83.502 	Training Prec@5 98.944 	Validation Loss 0.7160 	Validation Prec@1 81.520 	Validation Prec@5 98.800 

2025-05-20 11:38:12 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:38:12 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:38:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:38:13 - INFO - TRAINING - Epoch: [21][0/196]	Time 0.851 (0.851)	Data 0.737 (0.737)	Loss 0.6310 (0.6310)	Prec@1 87.109 (87.109)	Prec@5 98.828 (98.828)
2025-05-20 11:38:14 - INFO - TRAINING - Epoch: [21][10/196]	Time 0.145 (0.204)	Data 0.009 (0.076)	Loss 0.6686 (0.6797)	Prec@1 82.812 (84.304)	Prec@5 98.438 (98.757)
2025-05-20 11:38:16 - INFO - TRAINING - Epoch: [21][20/196]	Time 0.133 (0.174)	Data 0.013 (0.043)	Loss 0.7160 (0.6931)	Prec@1 82.031 (83.426)	Prec@5 98.828 (98.642)
2025-05-20 11:38:17 - INFO - TRAINING - Epoch: [21][30/196]	Time 0.132 (0.161)	Data 0.000 (0.030)	Loss 0.6930 (0.6922)	Prec@1 84.375 (83.329)	Prec@5 98.828 (98.778)
2025-05-20 11:38:18 - INFO - TRAINING - Epoch: [21][40/196]	Time 0.157 (0.156)	Data 0.008 (0.023)	Loss 0.6071 (0.6873)	Prec@1 87.891 (83.565)	Prec@5 98.047 (98.761)
2025-05-20 11:38:20 - INFO - TRAINING - Epoch: [21][50/196]	Time 0.174 (0.156)	Data 0.000 (0.019)	Loss 0.6098 (0.6909)	Prec@1 86.328 (83.395)	Prec@5 99.609 (98.805)
2025-05-20 11:38:21 - INFO - TRAINING - Epoch: [21][60/196]	Time 0.137 (0.154)	Data 0.004 (0.017)	Loss 0.7613 (0.6890)	Prec@1 80.078 (83.389)	Prec@5 99.219 (98.835)
2025-05-20 11:38:23 - INFO - TRAINING - Epoch: [21][70/196]	Time 0.136 (0.151)	Data 0.000 (0.015)	Loss 0.7199 (0.6876)	Prec@1 83.594 (83.429)	Prec@5 98.828 (98.867)
2025-05-20 11:38:24 - INFO - TRAINING - Epoch: [21][80/196]	Time 0.135 (0.149)	Data 0.003 (0.013)	Loss 0.6484 (0.6888)	Prec@1 86.719 (83.425)	Prec@5 98.438 (98.881)
2025-05-20 11:38:25 - INFO - TRAINING - Epoch: [21][90/196]	Time 0.123 (0.147)	Data 0.000 (0.012)	Loss 0.7503 (0.6856)	Prec@1 80.469 (83.551)	Prec@5 97.656 (98.884)
2025-05-20 11:38:27 - INFO - TRAINING - Epoch: [21][100/196]	Time 0.133 (0.146)	Data 0.000 (0.011)	Loss 0.7271 (0.6864)	Prec@1 78.125 (83.416)	Prec@5 98.828 (98.878)
2025-05-20 11:38:28 - INFO - TRAINING - Epoch: [21][110/196]	Time 0.134 (0.145)	Data 0.006 (0.010)	Loss 0.6683 (0.6849)	Prec@1 82.422 (83.495)	Prec@5 99.609 (98.881)
2025-05-20 11:38:30 - INFO - TRAINING - Epoch: [21][120/196]	Time 0.135 (0.144)	Data 0.000 (0.009)	Loss 0.7285 (0.6831)	Prec@1 81.250 (83.616)	Prec@5 99.219 (98.922)
2025-05-20 11:38:31 - INFO - TRAINING - Epoch: [21][130/196]	Time 0.156 (0.144)	Data 0.000 (0.009)	Loss 0.6572 (0.6839)	Prec@1 85.938 (83.567)	Prec@5 98.828 (98.909)
2025-05-20 11:38:32 - INFO - TRAINING - Epoch: [21][140/196]	Time 0.136 (0.144)	Data 0.000 (0.009)	Loss 0.6753 (0.6835)	Prec@1 83.984 (83.544)	Prec@5 99.219 (98.908)
2025-05-20 11:38:34 - INFO - TRAINING - Epoch: [21][150/196]	Time 0.138 (0.144)	Data 0.000 (0.009)	Loss 0.6638 (0.6827)	Prec@1 84.375 (83.558)	Prec@5 99.219 (98.926)
2025-05-20 11:38:35 - INFO - TRAINING - Epoch: [21][160/196]	Time 0.134 (0.144)	Data 0.000 (0.008)	Loss 0.7218 (0.6823)	Prec@1 82.422 (83.589)	Prec@5 98.047 (98.923)
2025-05-20 11:38:37 - INFO - TRAINING - Epoch: [21][170/196]	Time 0.132 (0.143)	Data 0.000 (0.008)	Loss 0.6073 (0.6813)	Prec@1 87.109 (83.603)	Prec@5 99.609 (98.922)
2025-05-20 11:38:38 - INFO - TRAINING - Epoch: [21][180/196]	Time 0.127 (0.142)	Data 0.000 (0.008)	Loss 0.7081 (0.6801)	Prec@1 80.469 (83.661)	Prec@5 98.828 (98.917)
2025-05-20 11:38:39 - INFO - TRAINING - Epoch: [21][190/196]	Time 0.137 (0.142)	Data 0.000 (0.007)	Loss 0.6778 (0.6791)	Prec@1 83.203 (83.714)	Prec@5 100.000 (98.945)
2025-05-20 11:38:41 - INFO - EVALUATING - Epoch: [21][0/40]	Time 0.776 (0.776)	Data 0.707 (0.707)	Loss 0.7057 (0.7057)	Prec@1 81.641 (81.641)	Prec@5 97.656 (97.656)
2025-05-20 11:38:41 - INFO - EVALUATING - Epoch: [21][10/40]	Time 0.074 (0.141)	Data 0.003 (0.067)	Loss 0.6437 (0.7130)	Prec@1 84.766 (81.747)	Prec@5 98.828 (98.473)
2025-05-20 11:38:42 - INFO - EVALUATING - Epoch: [21][20/40]	Time 0.091 (0.111)	Data 0.007 (0.037)	Loss 0.7120 (0.7132)	Prec@1 81.250 (81.994)	Prec@5 98.828 (98.270)
2025-05-20 11:38:43 - INFO - EVALUATING - Epoch: [21][30/40]	Time 0.070 (0.100)	Data 0.000 (0.025)	Loss 0.7372 (0.7206)	Prec@1 80.859 (81.603)	Prec@5 98.828 (98.488)
2025-05-20 11:38:44 - INFO - 
 Epoch: 22	Training Loss 0.6789 	Training Prec@1 83.730 	Training Prec@5 98.962 	Validation Loss 0.7192 	Validation Prec@1 81.690 	Validation Prec@5 98.580 

2025-05-20 11:38:44 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:38:44 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:38:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:38:45 - INFO - TRAINING - Epoch: [22][0/196]	Time 1.524 (1.524)	Data 1.387 (1.387)	Loss 0.6012 (0.6012)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
2025-05-20 11:38:47 - INFO - TRAINING - Epoch: [22][10/196]	Time 0.172 (0.284)	Data 0.000 (0.133)	Loss 0.7399 (0.6768)	Prec@1 78.906 (83.345)	Prec@5 99.609 (99.361)
2025-05-20 11:38:48 - INFO - TRAINING - Epoch: [22][20/196]	Time 0.149 (0.219)	Data 0.005 (0.073)	Loss 0.6282 (0.6660)	Prec@1 87.891 (84.301)	Prec@5 98.828 (99.126)
2025-05-20 11:38:50 - INFO - TRAINING - Epoch: [22][30/196]	Time 0.133 (0.193)	Data 0.000 (0.050)	Loss 0.6370 (0.6707)	Prec@1 85.156 (83.972)	Prec@5 99.219 (99.156)
2025-05-20 11:38:51 - INFO - TRAINING - Epoch: [22][40/196]	Time 0.133 (0.179)	Data 0.000 (0.039)	Loss 0.7025 (0.6763)	Prec@1 82.812 (83.756)	Prec@5 99.219 (99.123)
2025-05-20 11:38:53 - INFO - TRAINING - Epoch: [22][50/196]	Time 0.134 (0.170)	Data 0.000 (0.031)	Loss 0.7186 (0.6724)	Prec@1 82.422 (84.046)	Prec@5 98.438 (99.073)
2025-05-20 11:38:54 - INFO - TRAINING - Epoch: [22][60/196]	Time 0.134 (0.164)	Data 0.000 (0.027)	Loss 0.7101 (0.6750)	Prec@1 81.641 (83.959)	Prec@5 99.219 (99.071)
2025-05-20 11:38:55 - INFO - TRAINING - Epoch: [22][70/196]	Time 0.134 (0.160)	Data 0.004 (0.023)	Loss 0.7164 (0.6723)	Prec@1 81.641 (84.028)	Prec@5 98.438 (99.098)
2025-05-20 11:38:57 - INFO - TRAINING - Epoch: [22][80/196]	Time 0.133 (0.157)	Data 0.000 (0.021)	Loss 0.7128 (0.6708)	Prec@1 80.469 (84.163)	Prec@5 98.047 (99.079)
2025-05-20 11:38:58 - INFO - TRAINING - Epoch: [22][90/196]	Time 0.151 (0.155)	Data 0.000 (0.019)	Loss 0.6830 (0.6689)	Prec@1 83.594 (84.263)	Prec@5 98.828 (99.090)
2025-05-20 11:38:59 - INFO - TRAINING - Epoch: [22][100/196]	Time 0.149 (0.154)	Data 0.000 (0.017)	Loss 0.6666 (0.6699)	Prec@1 85.156 (84.216)	Prec@5 98.828 (99.083)
2025-05-20 11:39:01 - INFO - TRAINING - Epoch: [22][110/196]	Time 0.137 (0.153)	Data 0.005 (0.016)	Loss 0.7234 (0.6704)	Prec@1 80.859 (84.203)	Prec@5 99.609 (99.085)
2025-05-20 11:39:02 - INFO - TRAINING - Epoch: [22][120/196]	Time 0.135 (0.152)	Data 0.004 (0.015)	Loss 0.5767 (0.6678)	Prec@1 87.500 (84.298)	Prec@5 100.000 (99.099)
2025-05-20 11:39:04 - INFO - TRAINING - Epoch: [22][130/196]	Time 0.135 (0.151)	Data 0.000 (0.014)	Loss 0.7015 (0.6681)	Prec@1 85.156 (84.289)	Prec@5 100.000 (99.117)
2025-05-20 11:39:05 - INFO - TRAINING - Epoch: [22][140/196]	Time 0.137 (0.149)	Data 0.000 (0.013)	Loss 0.7366 (0.6698)	Prec@1 80.859 (84.242)	Prec@5 98.828 (99.072)
2025-05-20 11:39:06 - INFO - TRAINING - Epoch: [22][150/196]	Time 0.131 (0.148)	Data 0.000 (0.013)	Loss 0.6922 (0.6692)	Prec@1 84.375 (84.266)	Prec@5 98.828 (99.066)
2025-05-20 11:39:08 - INFO - TRAINING - Epoch: [22][160/196]	Time 0.135 (0.148)	Data 0.000 (0.012)	Loss 0.6161 (0.6674)	Prec@1 86.328 (84.341)	Prec@5 98.438 (99.078)
2025-05-20 11:39:09 - INFO - TRAINING - Epoch: [22][170/196]	Time 0.158 (0.147)	Data 0.007 (0.011)	Loss 0.7316 (0.6681)	Prec@1 83.984 (84.341)	Prec@5 97.656 (99.077)
2025-05-20 11:39:10 - INFO - TRAINING - Epoch: [22][180/196]	Time 0.136 (0.146)	Data 0.000 (0.011)	Loss 0.7390 (0.6693)	Prec@1 81.641 (84.315)	Prec@5 98.047 (99.068)
2025-05-20 11:39:12 - INFO - TRAINING - Epoch: [22][190/196]	Time 0.135 (0.146)	Data 0.000 (0.010)	Loss 0.6651 (0.6688)	Prec@1 83.984 (84.316)	Prec@5 100.000 (99.074)
2025-05-20 11:39:14 - INFO - EVALUATING - Epoch: [22][0/40]	Time 1.190 (1.190)	Data 1.102 (1.102)	Loss 0.7193 (0.7193)	Prec@1 81.641 (81.641)	Prec@5 98.828 (98.828)
2025-05-20 11:39:14 - INFO - EVALUATING - Epoch: [22][10/40]	Time 0.077 (0.184)	Data 0.000 (0.109)	Loss 0.6489 (0.7176)	Prec@1 83.984 (81.357)	Prec@5 99.219 (98.473)
2025-05-20 11:39:15 - INFO - EVALUATING - Epoch: [22][20/40]	Time 0.069 (0.133)	Data 0.000 (0.060)	Loss 0.6890 (0.7165)	Prec@1 83.203 (81.938)	Prec@5 98.828 (98.549)
2025-05-20 11:39:16 - INFO - EVALUATING - Epoch: [22][30/40]	Time 0.070 (0.115)	Data 0.000 (0.043)	Loss 0.7371 (0.7210)	Prec@1 80.078 (81.930)	Prec@5 98.047 (98.627)
2025-05-20 11:39:17 - INFO - 
 Epoch: 23	Training Loss 0.6695 	Training Prec@1 84.286 	Training Prec@5 99.056 	Validation Loss 0.7205 	Validation Prec@1 81.940 	Validation Prec@5 98.660 

2025-05-20 11:39:17 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:39:17 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:39:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:39:18 - INFO - TRAINING - Epoch: [23][0/196]	Time 0.943 (0.943)	Data 0.834 (0.834)	Loss 0.6352 (0.6352)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
2025-05-20 11:39:19 - INFO - TRAINING - Epoch: [23][10/196]	Time 0.143 (0.217)	Data 0.000 (0.081)	Loss 0.6872 (0.7092)	Prec@1 82.812 (82.457)	Prec@5 98.828 (98.864)
2025-05-20 11:39:21 - INFO - TRAINING - Epoch: [23][20/196]	Time 0.133 (0.180)	Data 0.000 (0.045)	Loss 0.7121 (0.6936)	Prec@1 83.984 (83.185)	Prec@5 98.828 (98.996)
2025-05-20 11:39:22 - INFO - TRAINING - Epoch: [23][30/196]	Time 0.134 (0.165)	Data 0.000 (0.031)	Loss 0.6810 (0.6789)	Prec@1 84.766 (84.047)	Prec@5 99.609 (99.080)
2025-05-20 11:39:23 - INFO - TRAINING - Epoch: [23][40/196]	Time 0.145 (0.158)	Data 0.007 (0.024)	Loss 0.7157 (0.6818)	Prec@1 83.203 (83.908)	Prec@5 97.656 (99.028)
2025-05-20 11:39:25 - INFO - TRAINING - Epoch: [23][50/196]	Time 0.157 (0.155)	Data 0.000 (0.020)	Loss 0.6417 (0.6820)	Prec@1 85.156 (83.770)	Prec@5 99.219 (98.997)
2025-05-20 11:39:26 - INFO - TRAINING - Epoch: [23][60/196]	Time 0.137 (0.155)	Data 0.015 (0.018)	Loss 0.5863 (0.6786)	Prec@1 85.938 (83.895)	Prec@5 99.609 (99.014)
2025-05-20 11:39:28 - INFO - TRAINING - Epoch: [23][70/196]	Time 0.133 (0.152)	Data 0.000 (0.016)	Loss 0.6577 (0.6766)	Prec@1 83.594 (83.902)	Prec@5 99.609 (99.010)
2025-05-20 11:39:29 - INFO - TRAINING - Epoch: [23][80/196]	Time 0.134 (0.150)	Data 0.000 (0.014)	Loss 0.6403 (0.6740)	Prec@1 85.547 (84.033)	Prec@5 98.047 (99.016)
2025-05-20 11:39:30 - INFO - TRAINING - Epoch: [23][90/196]	Time 0.122 (0.148)	Data 0.000 (0.013)	Loss 0.7010 (0.6710)	Prec@1 83.203 (84.152)	Prec@5 98.828 (99.047)
2025-05-20 11:39:32 - INFO - TRAINING - Epoch: [23][100/196]	Time 0.134 (0.147)	Data 0.000 (0.012)	Loss 0.7105 (0.6734)	Prec@1 80.078 (84.081)	Prec@5 98.828 (99.014)
2025-05-20 11:39:33 - INFO - TRAINING - Epoch: [23][110/196]	Time 0.134 (0.146)	Data 0.007 (0.011)	Loss 0.5579 (0.6706)	Prec@1 89.062 (84.174)	Prec@5 99.609 (99.050)
2025-05-20 11:39:34 - INFO - TRAINING - Epoch: [23][120/196]	Time 0.136 (0.145)	Data 0.000 (0.010)	Loss 0.7319 (0.6704)	Prec@1 84.375 (84.185)	Prec@5 97.266 (99.032)
2025-05-20 11:39:36 - INFO - TRAINING - Epoch: [23][130/196]	Time 0.133 (0.144)	Data 0.007 (0.010)	Loss 0.7061 (0.6696)	Prec@1 82.031 (84.208)	Prec@5 98.047 (99.043)
2025-05-20 11:39:37 - INFO - TRAINING - Epoch: [23][140/196]	Time 0.134 (0.143)	Data 0.004 (0.009)	Loss 0.7038 (0.6709)	Prec@1 82.422 (84.189)	Prec@5 98.438 (99.039)
2025-05-20 11:39:39 - INFO - TRAINING - Epoch: [23][150/196]	Time 0.156 (0.144)	Data 0.015 (0.009)	Loss 0.6461 (0.6720)	Prec@1 84.375 (84.168)	Prec@5 99.219 (99.035)
2025-05-20 11:39:40 - INFO - TRAINING - Epoch: [23][160/196]	Time 0.133 (0.144)	Data 0.005 (0.009)	Loss 0.6759 (0.6719)	Prec@1 86.328 (84.183)	Prec@5 99.219 (99.039)
2025-05-20 11:39:41 - INFO - TRAINING - Epoch: [23][170/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.7199 (0.6714)	Prec@1 82.812 (84.192)	Prec@5 98.828 (99.020)
2025-05-20 11:39:43 - INFO - TRAINING - Epoch: [23][180/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.6977 (0.6712)	Prec@1 84.375 (84.205)	Prec@5 98.438 (99.009)
2025-05-20 11:39:44 - INFO - TRAINING - Epoch: [23][190/196]	Time 0.130 (0.142)	Data 0.000 (0.008)	Loss 0.6238 (0.6698)	Prec@1 87.109 (84.248)	Prec@5 99.609 (99.016)
2025-05-20 11:39:46 - INFO - EVALUATING - Epoch: [23][0/40]	Time 0.760 (0.760)	Data 0.691 (0.691)	Loss 0.7429 (0.7429)	Prec@1 80.078 (80.078)	Prec@5 97.266 (97.266)
2025-05-20 11:39:46 - INFO - EVALUATING - Epoch: [23][10/40]	Time 0.074 (0.142)	Data 0.000 (0.068)	Loss 0.6674 (0.7548)	Prec@1 83.984 (80.256)	Prec@5 96.484 (97.798)
2025-05-20 11:39:47 - INFO - EVALUATING - Epoch: [23][20/40]	Time 0.078 (0.111)	Data 0.006 (0.038)	Loss 0.7135 (0.7473)	Prec@1 83.984 (80.952)	Prec@5 97.266 (97.675)
2025-05-20 11:39:48 - INFO - EVALUATING - Epoch: [23][30/40]	Time 0.070 (0.099)	Data 0.000 (0.026)	Loss 0.7799 (0.7508)	Prec@1 80.078 (80.834)	Prec@5 97.656 (97.770)
2025-05-20 11:39:49 - INFO - 
 Epoch: 24	Training Loss 0.6695 	Training Prec@1 84.258 	Training Prec@5 99.012 	Validation Loss 0.7460 	Validation Prec@1 81.040 	Validation Prec@5 97.850 

2025-05-20 11:39:49 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:39:49 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:39:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:39:50 - INFO - TRAINING - Epoch: [24][0/196]	Time 0.941 (0.941)	Data 0.804 (0.804)	Loss 0.6860 (0.6860)	Prec@1 83.203 (83.203)	Prec@5 99.609 (99.609)
2025-05-20 11:39:51 - INFO - TRAINING - Epoch: [24][10/196]	Time 0.159 (0.237)	Data 0.002 (0.095)	Loss 0.7226 (0.6555)	Prec@1 81.250 (84.624)	Prec@5 98.047 (99.290)
2025-05-20 11:39:53 - INFO - TRAINING - Epoch: [24][20/196]	Time 0.141 (0.205)	Data 0.000 (0.052)	Loss 0.6444 (0.6536)	Prec@1 85.938 (85.063)	Prec@5 100.000 (99.107)
2025-05-20 11:39:54 - INFO - TRAINING - Epoch: [24][30/196]	Time 0.138 (0.185)	Data 0.000 (0.037)	Loss 0.6637 (0.6626)	Prec@1 84.375 (84.766)	Prec@5 98.828 (98.992)
2025-05-20 11:39:56 - INFO - TRAINING - Epoch: [24][40/196]	Time 0.135 (0.173)	Data 0.000 (0.028)	Loss 0.5835 (0.6593)	Prec@1 87.891 (84.851)	Prec@5 99.219 (99.047)
2025-05-20 11:39:57 - INFO - TRAINING - Epoch: [24][50/196]	Time 0.134 (0.165)	Data 0.000 (0.023)	Loss 0.6762 (0.6568)	Prec@1 83.594 (84.949)	Prec@5 99.609 (99.112)
2025-05-20 11:39:58 - INFO - TRAINING - Epoch: [24][60/196]	Time 0.134 (0.160)	Data 0.002 (0.020)	Loss 0.6512 (0.6570)	Prec@1 84.766 (84.939)	Prec@5 100.000 (99.161)
2025-05-20 11:40:00 - INFO - TRAINING - Epoch: [24][70/196]	Time 0.132 (0.156)	Data 0.002 (0.017)	Loss 0.7413 (0.6588)	Prec@1 80.078 (84.848)	Prec@5 98.438 (99.147)
2025-05-20 11:40:01 - INFO - TRAINING - Epoch: [24][80/196]	Time 0.132 (0.154)	Data 0.000 (0.015)	Loss 0.5918 (0.6583)	Prec@1 86.328 (84.795)	Prec@5 98.438 (99.132)
2025-05-20 11:40:02 - INFO - TRAINING - Epoch: [24][90/196]	Time 0.133 (0.151)	Data 0.000 (0.014)	Loss 0.5910 (0.6578)	Prec@1 87.500 (84.770)	Prec@5 99.609 (99.146)
2025-05-20 11:40:04 - INFO - TRAINING - Epoch: [24][100/196]	Time 0.146 (0.150)	Data 0.012 (0.013)	Loss 0.5789 (0.6565)	Prec@1 86.719 (84.828)	Prec@5 100.000 (99.161)
2025-05-20 11:40:05 - INFO - TRAINING - Epoch: [24][110/196]	Time 0.161 (0.150)	Data 0.000 (0.013)	Loss 0.6295 (0.6559)	Prec@1 87.109 (84.878)	Prec@5 98.438 (99.159)
2025-05-20 11:40:07 - INFO - TRAINING - Epoch: [24][120/196]	Time 0.137 (0.149)	Data 0.000 (0.013)	Loss 0.6162 (0.6558)	Prec@1 85.938 (84.866)	Prec@5 99.609 (99.138)
2025-05-20 11:40:08 - INFO - TRAINING - Epoch: [24][130/196]	Time 0.134 (0.148)	Data 0.000 (0.012)	Loss 0.6986 (0.6556)	Prec@1 83.203 (84.864)	Prec@5 98.438 (99.123)
2025-05-20 11:40:09 - INFO - TRAINING - Epoch: [24][140/196]	Time 0.134 (0.147)	Data 0.002 (0.011)	Loss 0.6374 (0.6546)	Prec@1 85.547 (84.879)	Prec@5 99.219 (99.122)
2025-05-20 11:40:11 - INFO - TRAINING - Epoch: [24][150/196]	Time 0.127 (0.146)	Data 0.012 (0.011)	Loss 0.7206 (0.6576)	Prec@1 81.641 (84.724)	Prec@5 98.047 (99.100)
2025-05-20 11:40:12 - INFO - TRAINING - Epoch: [24][160/196]	Time 0.133 (0.145)	Data 0.000 (0.010)	Loss 0.6719 (0.6581)	Prec@1 82.812 (84.683)	Prec@5 99.609 (99.100)
2025-05-20 11:40:13 - INFO - TRAINING - Epoch: [24][170/196]	Time 0.132 (0.145)	Data 0.000 (0.010)	Loss 0.6074 (0.6592)	Prec@1 87.891 (84.626)	Prec@5 99.609 (99.114)
2025-05-20 11:40:15 - INFO - TRAINING - Epoch: [24][180/196]	Time 0.133 (0.144)	Data 0.000 (0.010)	Loss 0.6249 (0.6581)	Prec@1 85.156 (84.688)	Prec@5 100.000 (99.126)
2025-05-20 11:40:16 - INFO - TRAINING - Epoch: [24][190/196]	Time 0.137 (0.144)	Data 0.000 (0.009)	Loss 0.6531 (0.6575)	Prec@1 85.156 (84.706)	Prec@5 99.609 (99.131)
2025-05-20 11:40:18 - INFO - EVALUATING - Epoch: [24][0/40]	Time 1.192 (1.192)	Data 1.061 (1.061)	Loss 0.7128 (0.7128)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
2025-05-20 11:40:19 - INFO - EVALUATING - Epoch: [24][10/40]	Time 0.072 (0.193)	Data 0.004 (0.112)	Loss 0.6742 (0.7167)	Prec@1 82.422 (81.925)	Prec@5 98.438 (98.438)
2025-05-20 11:40:20 - INFO - EVALUATING - Epoch: [24][20/40]	Time 0.081 (0.138)	Data 0.003 (0.062)	Loss 0.6907 (0.7082)	Prec@1 83.203 (82.812)	Prec@5 99.219 (98.289)
2025-05-20 11:40:21 - INFO - EVALUATING - Epoch: [24][30/40]	Time 0.071 (0.117)	Data 0.000 (0.042)	Loss 0.7307 (0.7163)	Prec@1 78.906 (82.220)	Prec@5 98.047 (98.337)
2025-05-20 11:40:21 - INFO - 
 Epoch: 25	Training Loss 0.6580 	Training Prec@1 84.678 	Training Prec@5 99.132 	Validation Loss 0.7138 	Validation Prec@1 82.300 	Validation Prec@5 98.420 

2025-05-20 11:40:21 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:40:21 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:40:21 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:40:22 - INFO - TRAINING - Epoch: [25][0/196]	Time 0.984 (0.984)	Data 0.845 (0.845)	Loss 0.6781 (0.6781)	Prec@1 84.766 (84.766)	Prec@5 99.219 (99.219)
2025-05-20 11:40:24 - INFO - TRAINING - Epoch: [25][10/196]	Time 0.139 (0.219)	Data 0.006 (0.081)	Loss 0.7206 (0.6470)	Prec@1 79.688 (85.334)	Prec@5 98.828 (99.077)
2025-05-20 11:40:25 - INFO - TRAINING - Epoch: [25][20/196]	Time 0.134 (0.181)	Data 0.000 (0.045)	Loss 0.7341 (0.6536)	Prec@1 83.984 (85.249)	Prec@5 98.438 (99.070)
2025-05-20 11:40:27 - INFO - TRAINING - Epoch: [25][30/196]	Time 0.132 (0.166)	Data 0.000 (0.031)	Loss 0.7383 (0.6534)	Prec@1 80.469 (85.106)	Prec@5 99.219 (99.055)
2025-05-20 11:40:28 - INFO - TRAINING - Epoch: [25][40/196]	Time 0.134 (0.158)	Data 0.000 (0.024)	Loss 0.7144 (0.6550)	Prec@1 83.203 (85.051)	Prec@5 99.219 (99.047)
2025-05-20 11:40:29 - INFO - TRAINING - Epoch: [25][50/196]	Time 0.124 (0.154)	Data 0.000 (0.019)	Loss 0.6899 (0.6534)	Prec@1 83.203 (85.080)	Prec@5 99.609 (99.066)
2025-05-20 11:40:31 - INFO - TRAINING - Epoch: [25][60/196]	Time 0.152 (0.152)	Data 0.010 (0.017)	Loss 0.6589 (0.6506)	Prec@1 86.328 (85.195)	Prec@5 100.000 (99.136)
2025-05-20 11:40:32 - INFO - TRAINING - Epoch: [25][70/196]	Time 0.139 (0.151)	Data 0.009 (0.015)	Loss 0.6880 (0.6537)	Prec@1 82.812 (84.997)	Prec@5 98.828 (99.087)
2025-05-20 11:40:33 - INFO - TRAINING - Epoch: [25][80/196]	Time 0.134 (0.149)	Data 0.006 (0.014)	Loss 0.6126 (0.6558)	Prec@1 86.328 (84.823)	Prec@5 99.219 (99.084)
2025-05-20 11:40:35 - INFO - TRAINING - Epoch: [25][90/196]	Time 0.135 (0.148)	Data 0.000 (0.012)	Loss 0.6256 (0.6524)	Prec@1 86.328 (84.963)	Prec@5 98.438 (99.086)
2025-05-20 11:40:36 - INFO - TRAINING - Epoch: [25][100/196]	Time 0.134 (0.146)	Data 0.000 (0.011)	Loss 0.6396 (0.6535)	Prec@1 86.328 (84.878)	Prec@5 98.438 (99.107)
2025-05-20 11:40:37 - INFO - TRAINING - Epoch: [25][110/196]	Time 0.132 (0.145)	Data 0.010 (0.010)	Loss 0.6420 (0.6549)	Prec@1 85.938 (84.780)	Prec@5 98.438 (99.113)
2025-05-20 11:40:39 - INFO - TRAINING - Epoch: [25][120/196]	Time 0.133 (0.144)	Data 0.003 (0.010)	Loss 0.6667 (0.6533)	Prec@1 83.984 (84.875)	Prec@5 99.609 (99.144)
2025-05-20 11:40:40 - INFO - TRAINING - Epoch: [25][130/196]	Time 0.143 (0.143)	Data 0.004 (0.009)	Loss 0.6199 (0.6543)	Prec@1 87.500 (84.828)	Prec@5 99.219 (99.129)
2025-05-20 11:40:42 - INFO - TRAINING - Epoch: [25][140/196]	Time 0.132 (0.143)	Data 0.000 (0.009)	Loss 0.6241 (0.6541)	Prec@1 87.500 (84.901)	Prec@5 99.609 (99.152)
2025-05-20 11:40:43 - INFO - TRAINING - Epoch: [25][150/196]	Time 0.140 (0.143)	Data 0.015 (0.008)	Loss 0.5700 (0.6532)	Prec@1 89.453 (84.957)	Prec@5 99.609 (99.133)
2025-05-20 11:40:44 - INFO - TRAINING - Epoch: [25][160/196]	Time 0.149 (0.143)	Data 0.000 (0.009)	Loss 0.6679 (0.6531)	Prec@1 84.766 (84.923)	Prec@5 97.266 (99.134)
2025-05-20 11:40:46 - INFO - TRAINING - Epoch: [25][170/196]	Time 0.140 (0.143)	Data 0.018 (0.009)	Loss 0.6804 (0.6538)	Prec@1 83.203 (84.900)	Prec@5 100.000 (99.148)
2025-05-20 11:40:47 - INFO - TRAINING - Epoch: [25][180/196]	Time 0.134 (0.142)	Data 0.000 (0.009)	Loss 0.6353 (0.6537)	Prec@1 86.719 (84.938)	Prec@5 99.219 (99.132)
2025-05-20 11:40:49 - INFO - TRAINING - Epoch: [25][190/196]	Time 0.133 (0.142)	Data 0.000 (0.008)	Loss 0.7334 (0.6535)	Prec@1 82.031 (84.901)	Prec@5 98.438 (99.127)
2025-05-20 11:40:50 - INFO - EVALUATING - Epoch: [25][0/40]	Time 0.722 (0.722)	Data 0.653 (0.653)	Loss 0.7285 (0.7285)	Prec@1 82.812 (82.812)	Prec@5 97.266 (97.266)
2025-05-20 11:40:51 - INFO - EVALUATING - Epoch: [25][10/40]	Time 0.072 (0.135)	Data 0.004 (0.061)	Loss 0.6640 (0.7109)	Prec@1 85.938 (82.493)	Prec@5 99.219 (98.260)
2025-05-20 11:40:51 - INFO - EVALUATING - Epoch: [25][20/40]	Time 0.072 (0.108)	Data 0.003 (0.033)	Loss 0.6364 (0.7070)	Prec@1 85.938 (82.757)	Prec@5 98.828 (98.196)
2025-05-20 11:40:52 - INFO - EVALUATING - Epoch: [25][30/40]	Time 0.070 (0.097)	Data 0.000 (0.023)	Loss 0.7358 (0.7127)	Prec@1 83.203 (82.737)	Prec@5 98.828 (98.286)
2025-05-20 11:40:53 - INFO - 
 Epoch: 26	Training Loss 0.6528 	Training Prec@1 84.924 	Training Prec@5 99.130 	Validation Loss 0.7121 	Validation Prec@1 82.540 	Validation Prec@5 98.390 

2025-05-20 11:40:53 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:40:53 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:40:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:40:54 - INFO - TRAINING - Epoch: [26][0/196]	Time 1.032 (1.032)	Data 0.886 (0.886)	Loss 0.6482 (0.6482)	Prec@1 84.766 (84.766)	Prec@5 99.219 (99.219)
2025-05-20 11:40:56 - INFO - TRAINING - Epoch: [26][10/196]	Time 0.164 (0.228)	Data 0.002 (0.088)	Loss 0.6479 (0.6355)	Prec@1 83.984 (85.831)	Prec@5 99.609 (99.432)
2025-05-20 11:40:57 - INFO - TRAINING - Epoch: [26][20/196]	Time 0.144 (0.191)	Data 0.000 (0.047)	Loss 0.6670 (0.6437)	Prec@1 85.156 (85.193)	Prec@5 99.609 (99.330)
2025-05-20 11:40:59 - INFO - TRAINING - Epoch: [26][30/196]	Time 0.150 (0.178)	Data 0.005 (0.033)	Loss 0.5772 (0.6370)	Prec@1 88.672 (85.660)	Prec@5 98.828 (99.244)
2025-05-20 11:41:00 - INFO - TRAINING - Epoch: [26][40/196]	Time 0.134 (0.168)	Data 0.007 (0.027)	Loss 0.6733 (0.6363)	Prec@1 84.375 (85.747)	Prec@5 96.484 (99.123)
2025-05-20 11:41:01 - INFO - TRAINING - Epoch: [26][50/196]	Time 0.133 (0.161)	Data 0.000 (0.022)	Loss 0.6389 (0.6402)	Prec@1 85.938 (85.578)	Prec@5 99.219 (99.134)
2025-05-20 11:41:03 - INFO - TRAINING - Epoch: [26][60/196]	Time 0.134 (0.156)	Data 0.000 (0.019)	Loss 0.6201 (0.6381)	Prec@1 87.500 (85.771)	Prec@5 98.828 (99.136)
2025-05-20 11:41:04 - INFO - TRAINING - Epoch: [26][70/196]	Time 0.134 (0.153)	Data 0.000 (0.016)	Loss 0.6194 (0.6395)	Prec@1 86.719 (85.734)	Prec@5 99.609 (99.125)
2025-05-20 11:41:05 - INFO - TRAINING - Epoch: [26][80/196]	Time 0.133 (0.151)	Data 0.000 (0.015)	Loss 0.5965 (0.6401)	Prec@1 90.625 (85.706)	Prec@5 98.438 (99.074)
2025-05-20 11:41:07 - INFO - TRAINING - Epoch: [26][90/196]	Time 0.134 (0.149)	Data 0.000 (0.013)	Loss 0.5902 (0.6388)	Prec@1 87.891 (85.792)	Prec@5 100.000 (99.081)
2025-05-20 11:41:08 - INFO - TRAINING - Epoch: [26][100/196]	Time 0.142 (0.148)	Data 0.017 (0.012)	Loss 0.6292 (0.6392)	Prec@1 86.719 (85.806)	Prec@5 100.000 (99.107)
2025-05-20 11:41:09 - INFO - TRAINING - Epoch: [26][110/196]	Time 0.145 (0.147)	Data 0.015 (0.012)	Loss 0.6789 (0.6391)	Prec@1 84.766 (85.818)	Prec@5 99.219 (99.074)
2025-05-20 11:41:11 - INFO - TRAINING - Epoch: [26][120/196]	Time 0.146 (0.147)	Data 0.006 (0.012)	Loss 0.6327 (0.6387)	Prec@1 86.719 (85.850)	Prec@5 100.000 (99.103)
2025-05-20 11:41:12 - INFO - TRAINING - Epoch: [26][130/196]	Time 0.135 (0.147)	Data 0.007 (0.012)	Loss 0.6306 (0.6404)	Prec@1 87.109 (85.768)	Prec@5 98.047 (99.088)
2025-05-20 11:41:14 - INFO - TRAINING - Epoch: [26][140/196]	Time 0.134 (0.146)	Data 0.000 (0.011)	Loss 0.6711 (0.6407)	Prec@1 85.938 (85.738)	Prec@5 98.828 (99.091)
2025-05-20 11:41:15 - INFO - TRAINING - Epoch: [26][150/196]	Time 0.133 (0.145)	Data 0.003 (0.011)	Loss 0.6130 (0.6417)	Prec@1 86.719 (85.637)	Prec@5 99.609 (99.115)
2025-05-20 11:41:16 - INFO - TRAINING - Epoch: [26][160/196]	Time 0.142 (0.144)	Data 0.001 (0.010)	Loss 0.6599 (0.6432)	Prec@1 83.594 (85.583)	Prec@5 99.219 (99.107)
2025-05-20 11:41:18 - INFO - TRAINING - Epoch: [26][170/196]	Time 0.133 (0.144)	Data 0.000 (0.010)	Loss 0.6849 (0.6453)	Prec@1 82.422 (85.435)	Prec@5 98.438 (99.098)
2025-05-20 11:41:19 - INFO - TRAINING - Epoch: [26][180/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.6447 (0.6454)	Prec@1 86.328 (85.420)	Prec@5 98.047 (99.096)
2025-05-20 11:41:20 - INFO - TRAINING - Epoch: [26][190/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.6561 (0.6454)	Prec@1 85.156 (85.410)	Prec@5 99.219 (99.092)
2025-05-20 11:41:22 - INFO - EVALUATING - Epoch: [26][0/40]	Time 1.310 (1.310)	Data 1.233 (1.233)	Loss 0.7279 (0.7279)	Prec@1 83.203 (83.203)	Prec@5 98.828 (98.828)
2025-05-20 11:41:24 - INFO - EVALUATING - Epoch: [26][10/40]	Time 0.083 (0.218)	Data 0.000 (0.134)	Loss 0.6864 (0.7184)	Prec@1 82.422 (82.209)	Prec@5 99.609 (98.757)
2025-05-20 11:41:24 - INFO - EVALUATING - Epoch: [26][20/40]	Time 0.074 (0.157)	Data 0.000 (0.077)	Loss 0.7323 (0.7238)	Prec@1 80.859 (82.050)	Prec@5 97.656 (98.307)
2025-05-20 11:41:25 - INFO - EVALUATING - Epoch: [26][30/40]	Time 0.070 (0.130)	Data 0.000 (0.053)	Loss 0.6803 (0.7241)	Prec@1 82.812 (82.094)	Prec@5 97.656 (98.475)
2025-05-20 11:41:26 - INFO - 
 Epoch: 27	Training Loss 0.6453 	Training Prec@1 85.422 	Training Prec@5 99.088 	Validation Loss 0.7213 	Validation Prec@1 82.120 	Validation Prec@5 98.540 

2025-05-20 11:41:26 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:41:26 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:41:26 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:41:27 - INFO - TRAINING - Epoch: [27][0/196]	Time 0.749 (0.749)	Data 0.635 (0.635)	Loss 0.6909 (0.6909)	Prec@1 84.766 (84.766)	Prec@5 98.438 (98.438)
2025-05-20 11:41:28 - INFO - TRAINING - Epoch: [27][10/196]	Time 0.156 (0.215)	Data 0.004 (0.083)	Loss 0.7360 (0.6631)	Prec@1 82.422 (84.872)	Prec@5 98.047 (99.148)
2025-05-20 11:41:30 - INFO - TRAINING - Epoch: [27][20/196]	Time 0.138 (0.178)	Data 0.000 (0.045)	Loss 0.6681 (0.6571)	Prec@1 82.031 (84.803)	Prec@5 98.828 (99.144)
2025-05-20 11:41:31 - INFO - TRAINING - Epoch: [27][30/196]	Time 0.147 (0.164)	Data 0.000 (0.031)	Loss 0.6742 (0.6629)	Prec@1 82.812 (84.677)	Prec@5 99.609 (99.080)
2025-05-20 11:41:32 - INFO - TRAINING - Epoch: [27][40/196]	Time 0.134 (0.157)	Data 0.000 (0.024)	Loss 0.6094 (0.6601)	Prec@1 88.281 (84.766)	Prec@5 98.828 (99.057)
2025-05-20 11:41:34 - INFO - TRAINING - Epoch: [27][50/196]	Time 0.148 (0.152)	Data 0.000 (0.020)	Loss 0.6092 (0.6561)	Prec@1 89.062 (84.980)	Prec@5 98.047 (99.089)
2025-05-20 11:41:35 - INFO - TRAINING - Epoch: [27][60/196]	Time 0.157 (0.151)	Data 0.000 (0.017)	Loss 0.6110 (0.6547)	Prec@1 87.109 (85.047)	Prec@5 100.000 (99.110)
2025-05-20 11:41:37 - INFO - TRAINING - Epoch: [27][70/196]	Time 0.136 (0.150)	Data 0.000 (0.016)	Loss 0.6411 (0.6493)	Prec@1 84.375 (85.261)	Prec@5 99.219 (99.169)
2025-05-20 11:41:38 - INFO - TRAINING - Epoch: [27][80/196]	Time 0.133 (0.149)	Data 0.002 (0.015)	Loss 0.6133 (0.6485)	Prec@1 84.375 (85.253)	Prec@5 99.219 (99.171)
2025-05-20 11:41:39 - INFO - TRAINING - Epoch: [27][90/196]	Time 0.133 (0.147)	Data 0.000 (0.014)	Loss 0.5849 (0.6497)	Prec@1 87.891 (85.259)	Prec@5 99.609 (99.146)
2025-05-20 11:41:41 - INFO - TRAINING - Epoch: [27][100/196]	Time 0.134 (0.146)	Data 0.000 (0.012)	Loss 0.6046 (0.6465)	Prec@1 87.500 (85.412)	Prec@5 98.828 (99.157)
2025-05-20 11:41:42 - INFO - TRAINING - Epoch: [27][110/196]	Time 0.134 (0.145)	Data 0.007 (0.011)	Loss 0.6672 (0.6455)	Prec@1 83.203 (85.459)	Prec@5 99.609 (99.177)
2025-05-20 11:41:43 - INFO - TRAINING - Epoch: [27][120/196]	Time 0.133 (0.144)	Data 0.006 (0.011)	Loss 0.6708 (0.6444)	Prec@1 86.328 (85.524)	Prec@5 100.000 (99.206)
2025-05-20 11:41:45 - INFO - TRAINING - Epoch: [27][130/196]	Time 0.134 (0.143)	Data 0.007 (0.010)	Loss 0.6515 (0.6429)	Prec@1 82.812 (85.577)	Prec@5 99.609 (99.216)
2025-05-20 11:41:46 - INFO - TRAINING - Epoch: [27][140/196]	Time 0.135 (0.143)	Data 0.006 (0.010)	Loss 0.7255 (0.6450)	Prec@1 80.859 (85.461)	Prec@5 98.828 (99.208)
2025-05-20 11:41:47 - INFO - TRAINING - Epoch: [27][150/196]	Time 0.144 (0.142)	Data 0.000 (0.009)	Loss 0.7464 (0.6455)	Prec@1 78.906 (85.425)	Prec@5 98.828 (99.206)
2025-05-20 11:41:49 - INFO - TRAINING - Epoch: [27][160/196]	Time 0.161 (0.143)	Data 0.008 (0.009)	Loss 0.5859 (0.6443)	Prec@1 89.062 (85.484)	Prec@5 99.609 (99.226)
2025-05-20 11:41:50 - INFO - TRAINING - Epoch: [27][170/196]	Time 0.154 (0.143)	Data 0.015 (0.010)	Loss 0.6036 (0.6436)	Prec@1 88.281 (85.535)	Prec@5 99.609 (99.232)
2025-05-20 11:41:52 - INFO - TRAINING - Epoch: [27][180/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.7274 (0.6436)	Prec@1 81.250 (85.523)	Prec@5 99.609 (99.232)
2025-05-20 11:41:53 - INFO - TRAINING - Epoch: [27][190/196]	Time 0.133 (0.142)	Data 0.000 (0.009)	Loss 0.6985 (0.6435)	Prec@1 83.984 (85.547)	Prec@5 98.828 (99.229)
2025-05-20 11:41:55 - INFO - EVALUATING - Epoch: [27][0/40]	Time 0.694 (0.694)	Data 0.624 (0.624)	Loss 0.6935 (0.6935)	Prec@1 82.031 (82.031)	Prec@5 97.266 (97.266)
2025-05-20 11:41:55 - INFO - EVALUATING - Epoch: [27][10/40]	Time 0.072 (0.134)	Data 0.003 (0.063)	Loss 0.6570 (0.6894)	Prec@1 83.594 (82.777)	Prec@5 98.828 (98.473)
2025-05-20 11:41:56 - INFO - EVALUATING - Epoch: [27][20/40]	Time 0.075 (0.107)	Data 0.006 (0.035)	Loss 0.6596 (0.6966)	Prec@1 83.984 (82.645)	Prec@5 98.438 (98.363)
2025-05-20 11:41:57 - INFO - EVALUATING - Epoch: [27][30/40]	Time 0.069 (0.097)	Data 0.000 (0.024)	Loss 0.7121 (0.6989)	Prec@1 83.594 (82.623)	Prec@5 98.828 (98.463)
2025-05-20 11:41:58 - INFO - 
 Epoch: 28	Training Loss 0.6433 	Training Prec@1 85.566 	Training Prec@5 99.230 	Validation Loss 0.6986 	Validation Prec@1 82.480 	Validation Prec@5 98.490 

2025-05-20 11:41:58 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:41:58 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:41:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:41:59 - INFO - TRAINING - Epoch: [28][0/196]	Time 0.989 (0.989)	Data 0.861 (0.861)	Loss 0.5834 (0.5834)	Prec@1 87.109 (87.109)	Prec@5 99.219 (99.219)
2025-05-20 11:42:00 - INFO - TRAINING - Epoch: [28][10/196]	Time 0.144 (0.223)	Data 0.011 (0.086)	Loss 0.6043 (0.6447)	Prec@1 85.156 (84.872)	Prec@5 99.609 (99.112)
2025-05-20 11:42:02 - INFO - TRAINING - Epoch: [28][20/196]	Time 0.169 (0.189)	Data 0.007 (0.047)	Loss 0.6623 (0.6375)	Prec@1 84.766 (85.603)	Prec@5 99.219 (99.144)
2025-05-20 11:42:03 - INFO - TRAINING - Epoch: [28][30/196]	Time 0.149 (0.177)	Data 0.010 (0.035)	Loss 0.5952 (0.6396)	Prec@1 87.891 (85.572)	Prec@5 99.219 (99.118)
2025-05-20 11:42:05 - INFO - TRAINING - Epoch: [28][40/196]	Time 0.133 (0.169)	Data 0.001 (0.029)	Loss 0.6888 (0.6354)	Prec@1 83.594 (85.728)	Prec@5 99.609 (99.162)
2025-05-20 11:42:06 - INFO - TRAINING - Epoch: [28][50/196]	Time 0.135 (0.162)	Data 0.000 (0.023)	Loss 0.6547 (0.6338)	Prec@1 85.938 (85.685)	Prec@5 98.438 (99.165)
2025-05-20 11:42:07 - INFO - TRAINING - Epoch: [28][60/196]	Time 0.119 (0.158)	Data 0.000 (0.020)	Loss 0.6053 (0.6291)	Prec@1 86.328 (85.893)	Prec@5 99.609 (99.232)
2025-05-20 11:42:09 - INFO - TRAINING - Epoch: [28][70/196]	Time 0.134 (0.155)	Data 0.006 (0.018)	Loss 0.6136 (0.6293)	Prec@1 85.547 (85.943)	Prec@5 99.609 (99.230)
2025-05-20 11:42:10 - INFO - TRAINING - Epoch: [28][80/196]	Time 0.134 (0.152)	Data 0.000 (0.016)	Loss 0.5683 (0.6294)	Prec@1 88.281 (85.904)	Prec@5 99.219 (99.214)
2025-05-20 11:42:11 - INFO - TRAINING - Epoch: [28][90/196]	Time 0.134 (0.150)	Data 0.012 (0.014)	Loss 0.6575 (0.6286)	Prec@1 85.156 (85.925)	Prec@5 99.219 (99.253)
2025-05-20 11:42:13 - INFO - TRAINING - Epoch: [28][100/196]	Time 0.134 (0.149)	Data 0.000 (0.013)	Loss 0.6742 (0.6301)	Prec@1 83.984 (85.872)	Prec@5 98.047 (99.250)
2025-05-20 11:42:14 - INFO - TRAINING - Epoch: [28][110/196]	Time 0.127 (0.148)	Data 0.024 (0.012)	Loss 0.5892 (0.6331)	Prec@1 87.500 (85.712)	Prec@5 99.609 (99.222)
2025-05-20 11:42:16 - INFO - TRAINING - Epoch: [28][120/196]	Time 0.153 (0.147)	Data 0.012 (0.012)	Loss 0.6351 (0.6326)	Prec@1 83.594 (85.708)	Prec@5 99.219 (99.238)
2025-05-20 11:42:17 - INFO - TRAINING - Epoch: [28][130/196]	Time 0.148 (0.147)	Data 0.017 (0.012)	Loss 0.6341 (0.6324)	Prec@1 84.375 (85.714)	Prec@5 98.828 (99.213)
2025-05-20 11:42:18 - INFO - TRAINING - Epoch: [28][140/196]	Time 0.136 (0.147)	Data 0.000 (0.011)	Loss 0.6173 (0.6330)	Prec@1 89.062 (85.732)	Prec@5 99.609 (99.205)
2025-05-20 11:42:20 - INFO - TRAINING - Epoch: [28][150/196]	Time 0.133 (0.146)	Data 0.000 (0.011)	Loss 0.5908 (0.6318)	Prec@1 89.062 (85.826)	Prec@5 98.438 (99.201)
2025-05-20 11:42:21 - INFO - TRAINING - Epoch: [28][160/196]	Time 0.134 (0.145)	Data 0.007 (0.010)	Loss 0.6963 (0.6331)	Prec@1 82.422 (85.814)	Prec@5 98.438 (99.199)
2025-05-20 11:42:22 - INFO - TRAINING - Epoch: [28][170/196]	Time 0.134 (0.145)	Data 0.008 (0.010)	Loss 0.6773 (0.6346)	Prec@1 83.594 (85.748)	Prec@5 99.609 (99.200)
2025-05-20 11:42:24 - INFO - TRAINING - Epoch: [28][180/196]	Time 0.134 (0.144)	Data 0.000 (0.009)	Loss 0.6895 (0.6350)	Prec@1 83.594 (85.745)	Prec@5 98.047 (99.191)
2025-05-20 11:42:25 - INFO - TRAINING - Epoch: [28][190/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.5500 (0.6342)	Prec@1 90.625 (85.778)	Prec@5 99.219 (99.192)
2025-05-20 11:42:27 - INFO - EVALUATING - Epoch: [28][0/40]	Time 0.887 (0.887)	Data 0.817 (0.817)	Loss 0.7198 (0.7198)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
2025-05-20 11:42:28 - INFO - EVALUATING - Epoch: [28][10/40]	Time 0.087 (0.157)	Data 0.010 (0.081)	Loss 0.6498 (0.7047)	Prec@1 85.547 (82.812)	Prec@5 98.438 (98.224)
2025-05-20 11:42:29 - INFO - EVALUATING - Epoch: [28][20/40]	Time 0.093 (0.128)	Data 0.000 (0.044)	Loss 0.6358 (0.6961)	Prec@1 85.156 (82.850)	Prec@5 99.219 (98.270)
2025-05-20 11:42:29 - INFO - EVALUATING - Epoch: [28][30/40]	Time 0.071 (0.115)	Data 0.000 (0.033)	Loss 0.7356 (0.6972)	Prec@1 81.250 (82.951)	Prec@5 98.047 (98.236)
2025-05-20 11:42:30 - INFO - 
 Epoch: 29	Training Loss 0.6351 	Training Prec@1 85.748 	Training Prec@5 99.190 	Validation Loss 0.6966 	Validation Prec@1 82.820 	Validation Prec@5 98.280 

2025-05-20 11:42:30 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:42:30 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:42:30 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:42:31 - INFO - TRAINING - Epoch: [29][0/196]	Time 0.754 (0.754)	Data 0.654 (0.654)	Loss 0.6289 (0.6289)	Prec@1 86.328 (86.328)	Prec@5 97.656 (97.656)
2025-05-20 11:42:33 - INFO - TRAINING - Epoch: [29][10/196]	Time 0.143 (0.222)	Data 0.011 (0.089)	Loss 0.7172 (0.6557)	Prec@1 80.859 (84.801)	Prec@5 98.438 (98.615)
2025-05-20 11:42:34 - INFO - TRAINING - Epoch: [29][20/196]	Time 0.134 (0.182)	Data 0.000 (0.049)	Loss 0.6625 (0.6469)	Prec@1 85.547 (85.193)	Prec@5 99.609 (98.865)
2025-05-20 11:42:36 - INFO - TRAINING - Epoch: [29][30/196]	Time 0.134 (0.167)	Data 0.000 (0.033)	Loss 0.6492 (0.6444)	Prec@1 85.156 (85.358)	Prec@5 99.219 (98.916)
2025-05-20 11:42:37 - INFO - TRAINING - Epoch: [29][40/196]	Time 0.134 (0.159)	Data 0.007 (0.026)	Loss 0.6587 (0.6405)	Prec@1 83.203 (85.366)	Prec@5 98.828 (99.009)
2025-05-20 11:42:38 - INFO - TRAINING - Epoch: [29][50/196]	Time 0.134 (0.154)	Data 0.000 (0.022)	Loss 0.6426 (0.6363)	Prec@1 85.156 (85.401)	Prec@5 99.219 (99.081)
2025-05-20 11:42:40 - INFO - TRAINING - Epoch: [29][60/196]	Time 0.134 (0.151)	Data 0.007 (0.018)	Loss 0.6039 (0.6345)	Prec@1 89.844 (85.624)	Prec@5 99.219 (99.123)
2025-05-20 11:42:41 - INFO - TRAINING - Epoch: [29][70/196]	Time 0.142 (0.149)	Data 0.006 (0.016)	Loss 0.6496 (0.6339)	Prec@1 85.547 (85.657)	Prec@5 99.219 (99.109)
2025-05-20 11:42:42 - INFO - TRAINING - Epoch: [29][80/196]	Time 0.143 (0.149)	Data 0.018 (0.015)	Loss 0.6110 (0.6311)	Prec@1 86.328 (85.831)	Prec@5 99.609 (99.127)
2025-05-20 11:42:44 - INFO - TRAINING - Epoch: [29][90/196]	Time 0.144 (0.149)	Data 0.010 (0.014)	Loss 0.6753 (0.6313)	Prec@1 82.812 (85.822)	Prec@5 99.219 (99.154)
2025-05-20 11:42:45 - INFO - TRAINING - Epoch: [29][100/196]	Time 0.134 (0.148)	Data 0.000 (0.013)	Loss 0.6342 (0.6293)	Prec@1 82.031 (85.852)	Prec@5 100.000 (99.172)
2025-05-20 11:42:47 - INFO - TRAINING - Epoch: [29][110/196]	Time 0.139 (0.146)	Data 0.000 (0.013)	Loss 0.5942 (0.6281)	Prec@1 87.500 (85.980)	Prec@5 99.219 (99.184)
2025-05-20 11:42:48 - INFO - TRAINING - Epoch: [29][120/196]	Time 0.136 (0.145)	Data 0.000 (0.012)	Loss 0.5907 (0.6269)	Prec@1 86.719 (86.083)	Prec@5 99.219 (99.183)
2025-05-20 11:42:49 - INFO - TRAINING - Epoch: [29][130/196]	Time 0.144 (0.145)	Data 0.023 (0.011)	Loss 0.6344 (0.6288)	Prec@1 85.156 (86.000)	Prec@5 99.219 (99.180)
2025-05-20 11:42:51 - INFO - TRAINING - Epoch: [29][140/196]	Time 0.130 (0.144)	Data 0.000 (0.011)	Loss 0.6349 (0.6280)	Prec@1 86.328 (86.034)	Prec@5 99.219 (99.199)
2025-05-20 11:42:52 - INFO - TRAINING - Epoch: [29][150/196]	Time 0.133 (0.143)	Data 0.002 (0.010)	Loss 0.6737 (0.6291)	Prec@1 84.375 (85.981)	Prec@5 98.047 (99.190)
2025-05-20 11:42:53 - INFO - TRAINING - Epoch: [29][160/196]	Time 0.133 (0.143)	Data 0.000 (0.010)	Loss 0.6171 (0.6299)	Prec@1 86.719 (85.925)	Prec@5 99.609 (99.190)
2025-05-20 11:42:55 - INFO - TRAINING - Epoch: [29][170/196]	Time 0.161 (0.143)	Data 0.009 (0.010)	Loss 0.5880 (0.6312)	Prec@1 87.891 (85.823)	Prec@5 99.219 (99.187)
2025-05-20 11:42:56 - INFO - TRAINING - Epoch: [29][180/196]	Time 0.149 (0.143)	Data 0.000 (0.009)	Loss 0.6709 (0.6297)	Prec@1 83.203 (85.888)	Prec@5 99.609 (99.199)
2025-05-20 11:42:58 - INFO - TRAINING - Epoch: [29][190/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.6015 (0.6302)	Prec@1 88.672 (85.907)	Prec@5 100.000 (99.209)
2025-05-20 11:42:59 - INFO - EVALUATING - Epoch: [29][0/40]	Time 0.781 (0.781)	Data 0.712 (0.712)	Loss 0.6380 (0.6380)	Prec@1 85.547 (85.547)	Prec@5 99.609 (99.609)
2025-05-20 11:43:00 - INFO - EVALUATING - Epoch: [29][10/40]	Time 0.070 (0.143)	Data 0.001 (0.069)	Loss 0.6426 (0.6715)	Prec@1 83.984 (83.700)	Prec@5 99.219 (98.544)
2025-05-20 11:43:01 - INFO - EVALUATING - Epoch: [29][20/40]	Time 0.078 (0.113)	Data 0.000 (0.038)	Loss 0.6664 (0.6632)	Prec@1 83.984 (84.115)	Prec@5 98.438 (98.661)
2025-05-20 11:43:01 - INFO - EVALUATING - Epoch: [29][30/40]	Time 0.070 (0.101)	Data 0.000 (0.026)	Loss 0.7282 (0.6716)	Prec@1 80.859 (83.657)	Prec@5 97.656 (98.677)
2025-05-20 11:43:02 - INFO - 
 Epoch: 30	Training Loss 0.6312 	Training Prec@1 85.864 	Training Prec@5 99.202 	Validation Loss 0.6735 	Validation Prec@1 83.380 	Validation Prec@5 98.690 

2025-05-20 11:43:02 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:43:02 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:43:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:43:03 - INFO - TRAINING - Epoch: [30][0/196]	Time 1.059 (1.059)	Data 0.945 (0.945)	Loss 0.5942 (0.5942)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
2025-05-20 11:43:05 - INFO - TRAINING - Epoch: [30][10/196]	Time 0.156 (0.228)	Data 0.007 (0.092)	Loss 0.5442 (0.6124)	Prec@1 90.234 (86.683)	Prec@5 99.219 (99.467)
2025-05-20 11:43:06 - INFO - TRAINING - Epoch: [30][20/196]	Time 0.133 (0.185)	Data 0.000 (0.049)	Loss 0.6805 (0.6195)	Prec@1 83.594 (86.496)	Prec@5 98.047 (99.330)
2025-05-20 11:43:08 - INFO - TRAINING - Epoch: [30][30/196]	Time 0.145 (0.170)	Data 0.000 (0.034)	Loss 0.6609 (0.6289)	Prec@1 83.594 (86.190)	Prec@5 99.609 (99.282)
2025-05-20 11:43:09 - INFO - TRAINING - Epoch: [30][40/196]	Time 0.143 (0.166)	Data 0.000 (0.026)	Loss 0.5654 (0.6276)	Prec@1 88.672 (86.195)	Prec@5 99.609 (99.181)
2025-05-20 11:43:11 - INFO - TRAINING - Epoch: [30][50/196]	Time 0.135 (0.162)	Data 0.000 (0.022)	Loss 0.5912 (0.6268)	Prec@1 86.719 (86.190)	Prec@5 99.219 (99.219)
2025-05-20 11:43:12 - INFO - TRAINING - Epoch: [30][60/196]	Time 0.133 (0.158)	Data 0.000 (0.019)	Loss 0.5932 (0.6268)	Prec@1 87.891 (86.226)	Prec@5 99.609 (99.225)
2025-05-20 11:43:13 - INFO - TRAINING - Epoch: [30][70/196]	Time 0.137 (0.154)	Data 0.000 (0.017)	Loss 0.6021 (0.6266)	Prec@1 88.672 (86.213)	Prec@5 99.219 (99.219)
2025-05-20 11:43:15 - INFO - TRAINING - Epoch: [30][80/196]	Time 0.134 (0.152)	Data 0.000 (0.015)	Loss 0.6098 (0.6241)	Prec@1 87.500 (86.314)	Prec@5 98.828 (99.233)
2025-05-20 11:43:16 - INFO - TRAINING - Epoch: [30][90/196]	Time 0.134 (0.150)	Data 0.000 (0.014)	Loss 0.5865 (0.6233)	Prec@1 89.453 (86.328)	Prec@5 100.000 (99.249)
2025-05-20 11:43:17 - INFO - TRAINING - Epoch: [30][100/196]	Time 0.134 (0.148)	Data 0.000 (0.013)	Loss 0.6639 (0.6237)	Prec@1 84.766 (86.297)	Prec@5 98.047 (99.238)
2025-05-20 11:43:19 - INFO - TRAINING - Epoch: [30][110/196]	Time 0.134 (0.147)	Data 0.007 (0.012)	Loss 0.5694 (0.6239)	Prec@1 89.844 (86.321)	Prec@5 99.219 (99.215)
2025-05-20 11:43:20 - INFO - TRAINING - Epoch: [30][120/196]	Time 0.128 (0.146)	Data 0.000 (0.011)	Loss 0.7079 (0.6255)	Prec@1 82.812 (86.264)	Prec@5 99.219 (99.235)
2025-05-20 11:43:21 - INFO - TRAINING - Epoch: [30][130/196]	Time 0.142 (0.146)	Data 0.005 (0.011)	Loss 0.6009 (0.6263)	Prec@1 85.547 (86.206)	Prec@5 99.609 (99.231)
2025-05-20 11:43:23 - INFO - TRAINING - Epoch: [30][140/196]	Time 0.166 (0.147)	Data 0.005 (0.010)	Loss 0.6746 (0.6282)	Prec@1 85.156 (86.154)	Prec@5 99.609 (99.208)
2025-05-20 11:43:25 - INFO - TRAINING - Epoch: [30][150/196]	Time 0.137 (0.147)	Data 0.000 (0.010)	Loss 0.5793 (0.6271)	Prec@1 87.891 (86.222)	Prec@5 99.609 (99.214)
2025-05-20 11:43:26 - INFO - TRAINING - Epoch: [30][160/196]	Time 0.133 (0.146)	Data 0.002 (0.009)	Loss 0.6872 (0.6275)	Prec@1 85.156 (86.214)	Prec@5 99.219 (99.228)
2025-05-20 11:43:27 - INFO - TRAINING - Epoch: [30][170/196]	Time 0.134 (0.146)	Data 0.007 (0.009)	Loss 0.5809 (0.6266)	Prec@1 88.672 (86.282)	Prec@5 98.047 (99.210)
2025-05-20 11:43:29 - INFO - TRAINING - Epoch: [30][180/196]	Time 0.133 (0.145)	Data 0.000 (0.009)	Loss 0.6512 (0.6261)	Prec@1 87.891 (86.315)	Prec@5 97.656 (99.197)
2025-05-20 11:43:30 - INFO - TRAINING - Epoch: [30][190/196]	Time 0.134 (0.144)	Data 0.000 (0.008)	Loss 0.6031 (0.6261)	Prec@1 87.109 (86.306)	Prec@5 99.219 (99.192)
2025-05-20 11:43:31 - INFO - EVALUATING - Epoch: [30][0/40]	Time 0.850 (0.850)	Data 0.777 (0.777)	Loss 0.7252 (0.7252)	Prec@1 80.859 (80.859)	Prec@5 98.047 (98.047)
2025-05-20 11:43:32 - INFO - EVALUATING - Epoch: [30][10/40]	Time 0.079 (0.147)	Data 0.000 (0.074)	Loss 0.6010 (0.6943)	Prec@1 86.719 (82.422)	Prec@5 99.609 (98.438)
2025-05-20 11:43:33 - INFO - EVALUATING - Epoch: [30][20/40]	Time 0.081 (0.113)	Data 0.001 (0.040)	Loss 0.6548 (0.6862)	Prec@1 84.375 (83.315)	Prec@5 99.219 (98.289)
2025-05-20 11:43:34 - INFO - EVALUATING - Epoch: [30][30/40]	Time 0.069 (0.101)	Data 0.000 (0.028)	Loss 0.7167 (0.6952)	Prec@1 80.859 (82.888)	Prec@5 98.828 (98.400)
2025-05-20 11:43:35 - INFO - 
 Epoch: 31	Training Loss 0.6260 	Training Prec@1 86.296 	Training Prec@5 99.200 	Validation Loss 0.6944 	Validation Prec@1 82.710 	Validation Prec@5 98.500 

2025-05-20 11:43:35 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:43:35 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:43:35 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:43:36 - INFO - TRAINING - Epoch: [31][0/196]	Time 1.690 (1.690)	Data 1.538 (1.538)	Loss 0.5838 (0.5838)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
2025-05-20 11:43:38 - INFO - TRAINING - Epoch: [31][10/196]	Time 0.138 (0.283)	Data 0.000 (0.145)	Loss 0.6574 (0.6338)	Prec@1 85.547 (86.257)	Prec@5 98.438 (98.899)
2025-05-20 11:43:39 - INFO - TRAINING - Epoch: [31][20/196]	Time 0.133 (0.213)	Data 0.007 (0.078)	Loss 0.6436 (0.6245)	Prec@1 84.375 (86.496)	Prec@5 99.609 (99.107)
2025-05-20 11:43:41 - INFO - TRAINING - Epoch: [31][30/196]	Time 0.133 (0.187)	Data 0.000 (0.054)	Loss 0.7386 (0.6277)	Prec@1 80.859 (86.164)	Prec@5 99.609 (99.156)
2025-05-20 11:43:42 - INFO - TRAINING - Epoch: [31][40/196]	Time 0.142 (0.175)	Data 0.001 (0.041)	Loss 0.6819 (0.6262)	Prec@1 81.641 (86.119)	Prec@5 98.438 (99.190)
2025-05-20 11:43:43 - INFO - TRAINING - Epoch: [31][50/196]	Time 0.134 (0.167)	Data 0.000 (0.034)	Loss 0.5951 (0.6232)	Prec@1 87.109 (86.167)	Prec@5 99.609 (99.226)
2025-05-20 11:43:45 - INFO - TRAINING - Epoch: [31][60/196]	Time 0.134 (0.161)	Data 0.001 (0.028)	Loss 0.6162 (0.6217)	Prec@1 85.547 (86.238)	Prec@5 99.219 (99.251)
2025-05-20 11:43:46 - INFO - TRAINING - Epoch: [31][70/196]	Time 0.131 (0.157)	Data 0.000 (0.025)	Loss 0.5913 (0.6213)	Prec@1 88.672 (86.262)	Prec@5 98.828 (99.246)
2025-05-20 11:43:47 - INFO - TRAINING - Epoch: [31][80/196]	Time 0.138 (0.155)	Data 0.012 (0.022)	Loss 0.6499 (0.6196)	Prec@1 84.375 (86.323)	Prec@5 100.000 (99.272)
2025-05-20 11:43:49 - INFO - TRAINING - Epoch: [31][90/196]	Time 0.148 (0.154)	Data 0.000 (0.020)	Loss 0.7273 (0.6203)	Prec@1 82.422 (86.354)	Prec@5 98.828 (99.240)
2025-05-20 11:43:50 - INFO - TRAINING - Epoch: [31][100/196]	Time 0.133 (0.153)	Data 0.007 (0.019)	Loss 0.6052 (0.6215)	Prec@1 87.891 (86.247)	Prec@5 98.828 (99.261)
2025-05-20 11:43:52 - INFO - TRAINING - Epoch: [31][110/196]	Time 0.124 (0.151)	Data 0.000 (0.017)	Loss 0.6857 (0.6219)	Prec@1 82.422 (86.219)	Prec@5 98.828 (99.254)
2025-05-20 11:43:53 - INFO - TRAINING - Epoch: [31][120/196]	Time 0.134 (0.150)	Data 0.011 (0.016)	Loss 0.6726 (0.6227)	Prec@1 83.984 (86.244)	Prec@5 98.828 (99.241)
2025-05-20 11:43:54 - INFO - TRAINING - Epoch: [31][130/196]	Time 0.132 (0.149)	Data 0.003 (0.015)	Loss 0.6395 (0.6229)	Prec@1 85.547 (86.209)	Prec@5 100.000 (99.278)
2025-05-20 11:43:56 - INFO - TRAINING - Epoch: [31][140/196]	Time 0.132 (0.148)	Data 0.000 (0.014)	Loss 0.5980 (0.6229)	Prec@1 88.281 (86.162)	Prec@5 99.219 (99.269)
2025-05-20 11:43:57 - INFO - TRAINING - Epoch: [31][150/196]	Time 0.133 (0.147)	Data 0.000 (0.013)	Loss 0.5373 (0.6222)	Prec@1 89.062 (86.201)	Prec@5 100.000 (99.265)
2025-05-20 11:43:58 - INFO - TRAINING - Epoch: [31][160/196]	Time 0.134 (0.146)	Data 0.008 (0.013)	Loss 0.5381 (0.6215)	Prec@1 91.406 (86.250)	Prec@5 99.609 (99.277)
2025-05-20 11:44:00 - INFO - TRAINING - Epoch: [31][170/196]	Time 0.133 (0.145)	Data 0.004 (0.012)	Loss 0.5980 (0.6215)	Prec@1 89.062 (86.257)	Prec@5 99.609 (99.276)
2025-05-20 11:44:01 - INFO - TRAINING - Epoch: [31][180/196]	Time 0.151 (0.145)	Data 0.000 (0.012)	Loss 0.6217 (0.6226)	Prec@1 86.719 (86.220)	Prec@5 98.438 (99.275)
2025-05-20 11:44:02 - INFO - TRAINING - Epoch: [31][190/196]	Time 0.133 (0.145)	Data 0.000 (0.011)	Loss 0.6151 (0.6223)	Prec@1 85.547 (86.224)	Prec@5 98.047 (99.268)
2025-05-20 11:44:04 - INFO - EVALUATING - Epoch: [31][0/40]	Time 0.724 (0.724)	Data 0.656 (0.656)	Loss 0.7027 (0.7027)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)
2025-05-20 11:44:05 - INFO - EVALUATING - Epoch: [31][10/40]	Time 0.084 (0.141)	Data 0.007 (0.069)	Loss 0.6366 (0.6815)	Prec@1 86.328 (83.771)	Prec@5 98.438 (98.473)
2025-05-20 11:44:05 - INFO - EVALUATING - Epoch: [31][20/40]	Time 0.076 (0.111)	Data 0.005 (0.038)	Loss 0.6552 (0.6817)	Prec@1 84.375 (83.650)	Prec@5 99.219 (98.512)
2025-05-20 11:44:06 - INFO - EVALUATING - Epoch: [31][30/40]	Time 0.070 (0.099)	Data 0.000 (0.026)	Loss 0.7078 (0.6870)	Prec@1 81.250 (83.443)	Prec@5 98.438 (98.702)
2025-05-20 11:44:07 - INFO - 
 Epoch: 32	Training Loss 0.6215 	Training Prec@1 86.264 	Training Prec@5 99.276 	Validation Loss 0.6859 	Validation Prec@1 83.570 	Validation Prec@5 98.710 

2025-05-20 11:44:07 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:44:07 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:44:07 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:44:08 - INFO - TRAINING - Epoch: [32][0/196]	Time 0.904 (0.904)	Data 0.805 (0.805)	Loss 0.5710 (0.5710)	Prec@1 88.281 (88.281)	Prec@5 98.828 (98.828)
2025-05-20 11:44:09 - INFO - TRAINING - Epoch: [32][10/196]	Time 0.142 (0.224)	Data 0.006 (0.089)	Loss 0.6813 (0.6117)	Prec@1 83.203 (87.358)	Prec@5 98.828 (99.254)
2025-05-20 11:44:11 - INFO - TRAINING - Epoch: [32][20/196]	Time 0.134 (0.183)	Data 0.007 (0.048)	Loss 0.6677 (0.6110)	Prec@1 83.984 (87.128)	Prec@5 98.438 (99.237)
2025-05-20 11:44:12 - INFO - TRAINING - Epoch: [32][30/196]	Time 0.133 (0.167)	Data 0.005 (0.034)	Loss 0.5899 (0.6144)	Prec@1 89.062 (86.971)	Prec@5 99.219 (99.257)
2025-05-20 11:44:14 - INFO - TRAINING - Epoch: [32][40/196]	Time 0.160 (0.161)	Data 0.011 (0.026)	Loss 0.5569 (0.6139)	Prec@1 91.797 (86.986)	Prec@5 99.609 (99.152)
2025-05-20 11:44:15 - INFO - TRAINING - Epoch: [32][50/196]	Time 0.136 (0.158)	Data 0.010 (0.024)	Loss 0.6754 (0.6180)	Prec@1 84.766 (86.673)	Prec@5 100.000 (99.157)
2025-05-20 11:44:16 - INFO - TRAINING - Epoch: [32][60/196]	Time 0.134 (0.154)	Data 0.007 (0.021)	Loss 0.5880 (0.6184)	Prec@1 89.062 (86.591)	Prec@5 99.609 (99.174)
2025-05-20 11:44:18 - INFO - TRAINING - Epoch: [32][70/196]	Time 0.133 (0.152)	Data 0.000 (0.018)	Loss 0.6071 (0.6145)	Prec@1 85.938 (86.691)	Prec@5 99.609 (99.230)
2025-05-20 11:44:19 - INFO - TRAINING - Epoch: [32][80/196]	Time 0.134 (0.149)	Data 0.001 (0.016)	Loss 0.5640 (0.6105)	Prec@1 89.453 (86.912)	Prec@5 99.609 (99.253)
2025-05-20 11:44:20 - INFO - TRAINING - Epoch: [32][90/196]	Time 0.133 (0.148)	Data 0.000 (0.014)	Loss 0.6896 (0.6141)	Prec@1 82.031 (86.732)	Prec@5 99.609 (99.266)
2025-05-20 11:44:22 - INFO - TRAINING - Epoch: [32][100/196]	Time 0.138 (0.146)	Data 0.000 (0.013)	Loss 0.5920 (0.6135)	Prec@1 86.328 (86.707)	Prec@5 100.000 (99.254)
2025-05-20 11:44:23 - INFO - TRAINING - Epoch: [32][110/196]	Time 0.133 (0.146)	Data 0.007 (0.012)	Loss 0.6204 (0.6121)	Prec@1 87.891 (86.786)	Prec@5 99.219 (99.286)
2025-05-20 11:44:24 - INFO - TRAINING - Epoch: [32][120/196]	Time 0.133 (0.145)	Data 0.000 (0.011)	Loss 0.6200 (0.6116)	Prec@1 86.719 (86.838)	Prec@5 98.438 (99.274)
2025-05-20 11:44:26 - INFO - TRAINING - Epoch: [32][130/196]	Time 0.136 (0.144)	Data 0.000 (0.011)	Loss 0.6130 (0.6127)	Prec@1 88.672 (86.817)	Prec@5 98.828 (99.272)
2025-05-20 11:44:27 - INFO - TRAINING - Epoch: [32][140/196]	Time 0.143 (0.144)	Data 0.000 (0.010)	Loss 0.5965 (0.6145)	Prec@1 86.719 (86.686)	Prec@5 99.219 (99.269)
2025-05-20 11:44:29 - INFO - TRAINING - Epoch: [32][150/196]	Time 0.142 (0.144)	Data 0.010 (0.010)	Loss 0.5794 (0.6146)	Prec@1 87.891 (86.672)	Prec@5 99.609 (99.263)
2025-05-20 11:44:30 - INFO - TRAINING - Epoch: [32][160/196]	Time 0.132 (0.144)	Data 0.000 (0.010)	Loss 0.5954 (0.6150)	Prec@1 89.062 (86.682)	Prec@5 97.656 (99.250)
2025-05-20 11:44:31 - INFO - TRAINING - Epoch: [32][170/196]	Time 0.131 (0.143)	Data 0.000 (0.009)	Loss 0.5310 (0.6139)	Prec@1 91.016 (86.735)	Prec@5 99.609 (99.248)
2025-05-20 11:44:33 - INFO - TRAINING - Epoch: [32][180/196]	Time 0.133 (0.142)	Data 0.000 (0.009)	Loss 0.6126 (0.6137)	Prec@1 87.891 (86.764)	Prec@5 99.609 (99.258)
2025-05-20 11:44:34 - INFO - TRAINING - Epoch: [32][190/196]	Time 0.132 (0.142)	Data 0.000 (0.008)	Loss 0.6510 (0.6145)	Prec@1 84.375 (86.721)	Prec@5 98.828 (99.272)
2025-05-20 11:44:36 - INFO - EVALUATING - Epoch: [32][0/40]	Time 0.790 (0.790)	Data 0.721 (0.721)	Loss 0.6782 (0.6782)	Prec@1 83.594 (83.594)	Prec@5 98.828 (98.828)
2025-05-20 11:44:36 - INFO - EVALUATING - Epoch: [32][10/40]	Time 0.072 (0.142)	Data 0.000 (0.069)	Loss 0.6618 (0.6937)	Prec@1 83.984 (82.919)	Prec@5 99.219 (98.899)
2025-05-20 11:44:37 - INFO - EVALUATING - Epoch: [32][20/40]	Time 0.072 (0.111)	Data 0.003 (0.037)	Loss 0.6579 (0.6894)	Prec@1 84.766 (83.278)	Prec@5 99.609 (98.586)
2025-05-20 11:44:38 - INFO - EVALUATING - Epoch: [32][30/40]	Time 0.070 (0.099)	Data 0.000 (0.026)	Loss 0.6793 (0.6908)	Prec@1 83.984 (83.128)	Prec@5 98.828 (98.664)
2025-05-20 11:44:39 - INFO - 
 Epoch: 33	Training Loss 0.6155 	Training Prec@1 86.678 	Training Prec@5 99.268 	Validation Loss 0.6900 	Validation Prec@1 83.090 	Validation Prec@5 98.630 

2025-05-20 11:44:39 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:44:39 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:44:39 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:44:40 - INFO - TRAINING - Epoch: [33][0/196]	Time 1.615 (1.615)	Data 1.454 (1.454)	Loss 0.5685 (0.5685)	Prec@1 89.453 (89.453)	Prec@5 99.219 (99.219)
2025-05-20 11:44:42 - INFO - TRAINING - Epoch: [33][10/196]	Time 0.134 (0.285)	Data 0.004 (0.136)	Loss 0.6120 (0.6164)	Prec@1 85.547 (86.186)	Prec@5 100.000 (99.219)
2025-05-20 11:44:43 - INFO - TRAINING - Epoch: [33][20/196]	Time 0.145 (0.217)	Data 0.004 (0.074)	Loss 0.6373 (0.6178)	Prec@1 85.938 (86.607)	Prec@5 98.828 (99.126)
2025-05-20 11:44:45 - INFO - TRAINING - Epoch: [33][30/196]	Time 0.133 (0.190)	Data 0.010 (0.051)	Loss 0.5676 (0.6166)	Prec@1 87.891 (86.769)	Prec@5 100.000 (99.206)
2025-05-20 11:44:46 - INFO - TRAINING - Epoch: [33][40/196]	Time 0.133 (0.176)	Data 0.004 (0.039)	Loss 0.5890 (0.6182)	Prec@1 86.328 (86.604)	Prec@5 99.609 (99.228)
2025-05-20 11:44:47 - INFO - TRAINING - Epoch: [33][50/196]	Time 0.133 (0.168)	Data 0.000 (0.032)	Loss 0.5324 (0.6139)	Prec@1 90.625 (86.795)	Prec@5 99.219 (99.219)
2025-05-20 11:44:49 - INFO - TRAINING - Epoch: [33][60/196]	Time 0.135 (0.162)	Data 0.000 (0.027)	Loss 0.5815 (0.6118)	Prec@1 88.672 (86.834)	Prec@5 99.609 (99.232)
2025-05-20 11:44:50 - INFO - TRAINING - Epoch: [33][70/196]	Time 0.134 (0.158)	Data 0.000 (0.023)	Loss 0.6508 (0.6140)	Prec@1 85.547 (86.587)	Prec@5 98.438 (99.246)
2025-05-20 11:44:51 - INFO - TRAINING - Epoch: [33][80/196]	Time 0.137 (0.155)	Data 0.000 (0.020)	Loss 0.5617 (0.6121)	Prec@1 89.062 (86.699)	Prec@5 100.000 (99.262)
2025-05-20 11:44:53 - INFO - TRAINING - Epoch: [33][90/196]	Time 0.163 (0.154)	Data 0.025 (0.019)	Loss 0.5887 (0.6117)	Prec@1 89.062 (86.783)	Prec@5 99.219 (99.270)
2025-05-20 11:44:54 - INFO - TRAINING - Epoch: [33][100/196]	Time 0.180 (0.154)	Data 0.027 (0.019)	Loss 0.6252 (0.6114)	Prec@1 88.672 (86.858)	Prec@5 99.219 (99.284)
2025-05-20 11:44:56 - INFO - TRAINING - Epoch: [33][110/196]	Time 0.133 (0.153)	Data 0.000 (0.018)	Loss 0.5637 (0.6115)	Prec@1 89.062 (86.891)	Prec@5 99.219 (99.282)
2025-05-20 11:44:57 - INFO - TRAINING - Epoch: [33][120/196]	Time 0.145 (0.152)	Data 0.000 (0.016)	Loss 0.6031 (0.6117)	Prec@1 86.328 (86.877)	Prec@5 99.609 (99.280)
2025-05-20 11:44:58 - INFO - TRAINING - Epoch: [33][130/196]	Time 0.135 (0.150)	Data 0.000 (0.015)	Loss 0.6174 (0.6125)	Prec@1 87.109 (86.850)	Prec@5 99.219 (99.290)
2025-05-20 11:45:00 - INFO - TRAINING - Epoch: [33][140/196]	Time 0.133 (0.149)	Data 0.000 (0.014)	Loss 0.5439 (0.6123)	Prec@1 90.625 (86.841)	Prec@5 100.000 (99.296)
2025-05-20 11:45:01 - INFO - TRAINING - Epoch: [33][150/196]	Time 0.134 (0.148)	Data 0.000 (0.013)	Loss 0.5755 (0.6110)	Prec@1 88.672 (86.921)	Prec@5 98.828 (99.270)
2025-05-20 11:45:02 - INFO - TRAINING - Epoch: [33][160/196]	Time 0.134 (0.147)	Data 0.000 (0.013)	Loss 0.5583 (0.6110)	Prec@1 89.844 (86.889)	Prec@5 99.609 (99.272)
2025-05-20 11:45:04 - INFO - TRAINING - Epoch: [33][170/196]	Time 0.134 (0.146)	Data 0.009 (0.012)	Loss 0.5928 (0.6104)	Prec@1 88.281 (86.911)	Prec@5 100.000 (99.280)
2025-05-20 11:45:05 - INFO - TRAINING - Epoch: [33][180/196]	Time 0.137 (0.146)	Data 0.000 (0.012)	Loss 0.5605 (0.6111)	Prec@1 87.500 (86.891)	Prec@5 99.219 (99.268)
2025-05-20 11:45:06 - INFO - TRAINING - Epoch: [33][190/196]	Time 0.137 (0.145)	Data 0.000 (0.011)	Loss 0.6285 (0.6104)	Prec@1 84.766 (86.901)	Prec@5 99.609 (99.286)
2025-05-20 11:45:08 - INFO - EVALUATING - Epoch: [33][0/40]	Time 0.812 (0.812)	Data 0.737 (0.737)	Loss 0.7089 (0.7089)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
2025-05-20 11:45:09 - INFO - EVALUATING - Epoch: [33][10/40]	Time 0.079 (0.160)	Data 0.001 (0.086)	Loss 0.6778 (0.7161)	Prec@1 83.203 (82.173)	Prec@5 98.047 (98.153)
2025-05-20 11:45:10 - INFO - EVALUATING - Epoch: [33][20/40]	Time 0.076 (0.120)	Data 0.006 (0.046)	Loss 0.6923 (0.7161)	Prec@1 83.594 (82.180)	Prec@5 99.219 (98.103)
2025-05-20 11:45:11 - INFO - EVALUATING - Epoch: [33][30/40]	Time 0.070 (0.105)	Data 0.000 (0.032)	Loss 0.7407 (0.7175)	Prec@1 80.078 (82.019)	Prec@5 97.656 (98.236)
2025-05-20 11:45:11 - INFO - 
 Epoch: 34	Training Loss 0.6098 	Training Prec@1 86.914 	Training Prec@5 99.290 	Validation Loss 0.7140 	Validation Prec@1 82.290 	Validation Prec@5 98.320 

2025-05-20 11:45:11 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:45:11 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:45:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:45:12 - INFO - TRAINING - Epoch: [34][0/196]	Time 1.026 (1.026)	Data 0.907 (0.907)	Loss 0.6599 (0.6599)	Prec@1 83.984 (83.984)	Prec@5 99.609 (99.609)
2025-05-20 11:45:14 - INFO - TRAINING - Epoch: [34][10/196]	Time 0.148 (0.223)	Data 0.002 (0.089)	Loss 0.6282 (0.6174)	Prec@1 85.938 (86.506)	Prec@5 99.609 (99.254)
2025-05-20 11:45:15 - INFO - TRAINING - Epoch: [34][20/196]	Time 0.136 (0.183)	Data 0.000 (0.049)	Loss 0.6825 (0.6246)	Prec@1 85.156 (86.217)	Prec@5 98.828 (99.200)
2025-05-20 11:45:17 - INFO - TRAINING - Epoch: [34][30/196]	Time 0.133 (0.167)	Data 0.007 (0.033)	Loss 0.5643 (0.6127)	Prec@1 87.500 (86.794)	Prec@5 99.609 (99.332)
2025-05-20 11:45:18 - INFO - TRAINING - Epoch: [34][40/196]	Time 0.136 (0.159)	Data 0.000 (0.026)	Loss 0.5636 (0.6096)	Prec@1 88.281 (86.890)	Prec@5 99.219 (99.343)
2025-05-20 11:45:19 - INFO - TRAINING - Epoch: [34][50/196]	Time 0.146 (0.156)	Data 0.013 (0.022)	Loss 0.5321 (0.6052)	Prec@1 91.016 (87.209)	Prec@5 99.609 (99.364)
2025-05-20 11:45:21 - INFO - TRAINING - Epoch: [34][60/196]	Time 0.151 (0.156)	Data 0.007 (0.019)	Loss 0.5745 (0.6061)	Prec@1 88.672 (87.129)	Prec@5 99.219 (99.372)
2025-05-20 11:45:22 - INFO - TRAINING - Epoch: [34][70/196]	Time 0.138 (0.154)	Data 0.000 (0.017)	Loss 0.6311 (0.6080)	Prec@1 83.984 (87.049)	Prec@5 99.219 (99.323)
2025-05-20 11:45:24 - INFO - TRAINING - Epoch: [34][80/196]	Time 0.135 (0.151)	Data 0.007 (0.015)	Loss 0.6093 (0.6089)	Prec@1 87.109 (87.042)	Prec@5 100.000 (99.320)
2025-05-20 11:45:25 - INFO - TRAINING - Epoch: [34][90/196]	Time 0.133 (0.150)	Data 0.000 (0.014)	Loss 0.5250 (0.6071)	Prec@1 90.234 (87.148)	Prec@5 99.609 (99.330)
2025-05-20 11:45:26 - INFO - TRAINING - Epoch: [34][100/196]	Time 0.136 (0.148)	Data 0.000 (0.013)	Loss 0.5745 (0.6080)	Prec@1 89.062 (87.121)	Prec@5 98.828 (99.327)
2025-05-20 11:45:28 - INFO - TRAINING - Epoch: [34][110/196]	Time 0.134 (0.147)	Data 0.000 (0.012)	Loss 0.5851 (0.6090)	Prec@1 88.672 (87.053)	Prec@5 100.000 (99.331)
2025-05-20 11:45:29 - INFO - TRAINING - Epoch: [34][120/196]	Time 0.136 (0.146)	Data 0.000 (0.011)	Loss 0.6166 (0.6104)	Prec@1 85.547 (86.964)	Prec@5 99.609 (99.332)
2025-05-20 11:45:30 - INFO - TRAINING - Epoch: [34][130/196]	Time 0.133 (0.145)	Data 0.000 (0.010)	Loss 0.5869 (0.6106)	Prec@1 87.109 (86.954)	Prec@5 98.438 (99.305)
2025-05-20 11:45:32 - INFO - TRAINING - Epoch: [34][140/196]	Time 0.142 (0.144)	Data 0.000 (0.010)	Loss 0.6030 (0.6100)	Prec@1 87.891 (86.974)	Prec@5 98.828 (99.302)
2025-05-20 11:45:33 - INFO - TRAINING - Epoch: [34][150/196]	Time 0.164 (0.145)	Data 0.018 (0.009)	Loss 0.5803 (0.6096)	Prec@1 88.672 (86.998)	Prec@5 98.828 (99.317)
2025-05-20 11:45:35 - INFO - TRAINING - Epoch: [34][160/196]	Time 0.133 (0.145)	Data 0.005 (0.009)	Loss 0.6332 (0.6095)	Prec@1 84.375 (87.010)	Prec@5 99.219 (99.328)
2025-05-20 11:45:36 - INFO - TRAINING - Epoch: [34][170/196]	Time 0.135 (0.144)	Data 0.007 (0.009)	Loss 0.6225 (0.6094)	Prec@1 87.109 (87.002)	Prec@5 98.438 (99.326)
2025-05-20 11:45:37 - INFO - TRAINING - Epoch: [34][180/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.5873 (0.6096)	Prec@1 87.500 (86.958)	Prec@5 99.609 (99.324)
2025-05-20 11:45:39 - INFO - TRAINING - Epoch: [34][190/196]	Time 0.133 (0.143)	Data 0.000 (0.008)	Loss 0.6107 (0.6106)	Prec@1 87.500 (86.915)	Prec@5 99.609 (99.325)
2025-05-20 11:45:40 - INFO - EVALUATING - Epoch: [34][0/40]	Time 0.804 (0.804)	Data 0.710 (0.710)	Loss 0.6483 (0.6483)	Prec@1 83.984 (83.984)	Prec@5 99.219 (99.219)
2025-05-20 11:45:41 - INFO - EVALUATING - Epoch: [34][10/40]	Time 0.077 (0.142)	Data 0.004 (0.067)	Loss 0.6173 (0.6758)	Prec@1 85.156 (83.558)	Prec@5 98.828 (98.757)
2025-05-20 11:45:42 - INFO - EVALUATING - Epoch: [34][20/40]	Time 0.073 (0.111)	Data 0.000 (0.037)	Loss 0.6536 (0.6743)	Prec@1 83.594 (83.817)	Prec@5 98.828 (98.438)
2025-05-20 11:45:42 - INFO - EVALUATING - Epoch: [34][30/40]	Time 0.070 (0.099)	Data 0.000 (0.026)	Loss 0.7028 (0.6803)	Prec@1 80.859 (83.669)	Prec@5 98.438 (98.475)
2025-05-20 11:45:43 - INFO - 
 Epoch: 35	Training Loss 0.6105 	Training Prec@1 86.902 	Training Prec@5 99.312 	Validation Loss 0.6765 	Validation Prec@1 83.900 	Validation Prec@5 98.580 

2025-05-20 11:45:43 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:45:43 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:45:43 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:45:44 - INFO - TRAINING - Epoch: [35][0/196]	Time 0.962 (0.962)	Data 0.812 (0.812)	Loss 0.5386 (0.5386)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
2025-05-20 11:45:46 - INFO - TRAINING - Epoch: [35][10/196]	Time 0.174 (0.235)	Data 0.067 (0.090)	Loss 0.6504 (0.6048)	Prec@1 85.156 (87.393)	Prec@5 99.609 (99.361)
2025-05-20 11:45:48 - INFO - TRAINING - Epoch: [35][20/196]	Time 0.160 (0.201)	Data 0.000 (0.051)	Loss 0.5943 (0.6105)	Prec@1 87.500 (86.868)	Prec@5 99.609 (99.386)
2025-05-20 11:45:49 - INFO - TRAINING - Epoch: [35][30/196]	Time 0.146 (0.184)	Data 0.010 (0.037)	Loss 0.5705 (0.6087)	Prec@1 87.891 (86.883)	Prec@5 99.219 (99.370)
2025-05-20 11:45:50 - INFO - TRAINING - Epoch: [35][40/196]	Time 0.132 (0.173)	Data 0.006 (0.029)	Loss 0.5782 (0.6072)	Prec@1 88.672 (87.033)	Prec@5 99.609 (99.352)
2025-05-20 11:45:52 - INFO - TRAINING - Epoch: [35][50/196]	Time 0.132 (0.165)	Data 0.000 (0.024)	Loss 0.5345 (0.6027)	Prec@1 91.016 (87.155)	Prec@5 98.828 (99.395)
2025-05-20 11:45:53 - INFO - TRAINING - Epoch: [35][60/196]	Time 0.132 (0.160)	Data 0.000 (0.021)	Loss 0.6087 (0.6037)	Prec@1 87.500 (87.109)	Prec@5 98.438 (99.340)
2025-05-20 11:45:54 - INFO - TRAINING - Epoch: [35][70/196]	Time 0.143 (0.157)	Data 0.000 (0.018)	Loss 0.6231 (0.6063)	Prec@1 86.719 (87.060)	Prec@5 98.438 (99.318)
2025-05-20 11:45:56 - INFO - TRAINING - Epoch: [35][80/196]	Time 0.135 (0.154)	Data 0.000 (0.016)	Loss 0.6051 (0.6059)	Prec@1 89.062 (87.124)	Prec@5 100.000 (99.306)
2025-05-20 11:45:57 - INFO - TRAINING - Epoch: [35][90/196]	Time 0.134 (0.152)	Data 0.000 (0.014)	Loss 0.6036 (0.6066)	Prec@1 85.938 (87.088)	Prec@5 99.609 (99.305)
2025-05-20 11:45:59 - INFO - TRAINING - Epoch: [35][100/196]	Time 0.171 (0.151)	Data 0.010 (0.013)	Loss 0.6401 (0.6077)	Prec@1 83.984 (87.047)	Prec@5 98.438 (99.304)
2025-05-20 11:46:00 - INFO - TRAINING - Epoch: [35][110/196]	Time 0.140 (0.150)	Data 0.015 (0.013)	Loss 0.6066 (0.6071)	Prec@1 87.891 (87.050)	Prec@5 99.219 (99.293)
2025-05-20 11:46:01 - INFO - TRAINING - Epoch: [35][120/196]	Time 0.133 (0.150)	Data 0.000 (0.012)	Loss 0.6478 (0.6076)	Prec@1 85.938 (87.022)	Prec@5 100.000 (99.303)
2025-05-20 11:46:03 - INFO - TRAINING - Epoch: [35][130/196]	Time 0.133 (0.149)	Data 0.000 (0.012)	Loss 0.6814 (0.6090)	Prec@1 83.594 (86.996)	Prec@5 98.047 (99.299)
2025-05-20 11:46:04 - INFO - TRAINING - Epoch: [35][140/196]	Time 0.133 (0.148)	Data 0.000 (0.011)	Loss 0.5513 (0.6067)	Prec@1 88.672 (87.112)	Prec@5 98.828 (99.316)
2025-05-20 11:46:05 - INFO - TRAINING - Epoch: [35][150/196]	Time 0.133 (0.147)	Data 0.000 (0.011)	Loss 0.6458 (0.6080)	Prec@1 85.156 (87.047)	Prec@5 98.828 (99.286)
2025-05-20 11:46:07 - INFO - TRAINING - Epoch: [35][160/196]	Time 0.134 (0.146)	Data 0.008 (0.010)	Loss 0.5858 (0.6074)	Prec@1 87.891 (87.051)	Prec@5 100.000 (99.299)
2025-05-20 11:46:08 - INFO - TRAINING - Epoch: [35][170/196]	Time 0.138 (0.145)	Data 0.000 (0.010)	Loss 0.6490 (0.6080)	Prec@1 86.328 (87.018)	Prec@5 98.047 (99.287)
2025-05-20 11:46:09 - INFO - TRAINING - Epoch: [35][180/196]	Time 0.134 (0.145)	Data 0.000 (0.009)	Loss 0.5979 (0.6080)	Prec@1 87.891 (86.991)	Prec@5 100.000 (99.286)
2025-05-20 11:46:11 - INFO - TRAINING - Epoch: [35][190/196]	Time 0.132 (0.144)	Data 0.000 (0.009)	Loss 0.6657 (0.6084)	Prec@1 84.375 (86.948)	Prec@5 99.219 (99.292)
2025-05-20 11:46:13 - INFO - EVALUATING - Epoch: [35][0/40]	Time 1.111 (1.111)	Data 1.040 (1.040)	Loss 0.6724 (0.6724)	Prec@1 84.375 (84.375)	Prec@5 99.609 (99.609)
2025-05-20 11:46:14 - INFO - EVALUATING - Epoch: [35][10/40]	Time 0.076 (0.203)	Data 0.003 (0.122)	Loss 0.6763 (0.7007)	Prec@1 83.984 (82.812)	Prec@5 98.438 (98.473)
2025-05-20 11:46:15 - INFO - EVALUATING - Epoch: [35][20/40]	Time 0.081 (0.144)	Data 0.000 (0.065)	Loss 0.6398 (0.6882)	Prec@1 86.328 (83.389)	Prec@5 98.438 (98.214)
2025-05-20 11:46:15 - INFO - EVALUATING - Epoch: [35][30/40]	Time 0.069 (0.122)	Data 0.000 (0.045)	Loss 0.6789 (0.6880)	Prec@1 82.031 (83.317)	Prec@5 98.828 (98.412)
2025-05-20 11:46:16 - INFO - 
 Epoch: 36	Training Loss 0.6088 	Training Prec@1 86.920 	Training Prec@5 99.284 	Validation Loss 0.6874 	Validation Prec@1 83.320 	Validation Prec@5 98.370 

2025-05-20 11:46:16 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:46:16 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:46:16 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:46:17 - INFO - TRAINING - Epoch: [36][0/196]	Time 0.929 (0.929)	Data 0.830 (0.830)	Loss 0.6203 (0.6203)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
2025-05-20 11:46:19 - INFO - TRAINING - Epoch: [36][10/196]	Time 0.142 (0.215)	Data 0.000 (0.083)	Loss 0.5679 (0.6166)	Prec@1 88.281 (86.470)	Prec@5 98.828 (99.467)
2025-05-20 11:46:20 - INFO - TRAINING - Epoch: [36][20/196]	Time 0.139 (0.179)	Data 0.000 (0.046)	Loss 0.7233 (0.6236)	Prec@1 82.812 (86.328)	Prec@5 98.438 (99.312)
2025-05-20 11:46:21 - INFO - TRAINING - Epoch: [36][30/196]	Time 0.134 (0.164)	Data 0.000 (0.032)	Loss 0.6089 (0.6046)	Prec@1 85.547 (87.235)	Prec@5 99.609 (99.307)
2025-05-20 11:46:23 - INFO - TRAINING - Epoch: [36][40/196]	Time 0.133 (0.157)	Data 0.000 (0.024)	Loss 0.5665 (0.6055)	Prec@1 89.062 (87.252)	Prec@5 99.219 (99.276)
2025-05-20 11:46:24 - INFO - TRAINING - Epoch: [36][50/196]	Time 0.144 (0.153)	Data 0.010 (0.020)	Loss 0.6317 (0.6051)	Prec@1 87.109 (87.270)	Prec@5 99.219 (99.318)
2025-05-20 11:46:25 - INFO - TRAINING - Epoch: [36][60/196]	Time 0.141 (0.151)	Data 0.011 (0.018)	Loss 0.5570 (0.5984)	Prec@1 89.844 (87.558)	Prec@5 99.609 (99.334)
2025-05-20 11:46:27 - INFO - TRAINING - Epoch: [36][70/196]	Time 0.155 (0.151)	Data 0.006 (0.016)	Loss 0.5442 (0.5994)	Prec@1 89.844 (87.500)	Prec@5 99.219 (99.323)
2025-05-20 11:46:28 - INFO - TRAINING - Epoch: [36][80/196]	Time 0.134 (0.150)	Data 0.000 (0.015)	Loss 0.5580 (0.5988)	Prec@1 89.453 (87.568)	Prec@5 99.219 (99.339)
2025-05-20 11:46:30 - INFO - TRAINING - Epoch: [36][90/196]	Time 0.133 (0.148)	Data 0.007 (0.013)	Loss 0.5627 (0.5995)	Prec@1 88.672 (87.517)	Prec@5 100.000 (99.343)
2025-05-20 11:46:31 - INFO - TRAINING - Epoch: [36][100/196]	Time 0.133 (0.146)	Data 0.000 (0.012)	Loss 0.5824 (0.5993)	Prec@1 87.500 (87.543)	Prec@5 99.219 (99.362)
2025-05-20 11:46:32 - INFO - TRAINING - Epoch: [36][110/196]	Time 0.134 (0.145)	Data 0.003 (0.011)	Loss 0.5726 (0.6008)	Prec@1 88.281 (87.451)	Prec@5 100.000 (99.321)
2025-05-20 11:46:34 - INFO - TRAINING - Epoch: [36][120/196]	Time 0.144 (0.144)	Data 0.000 (0.011)	Loss 0.6121 (0.5994)	Prec@1 88.281 (87.526)	Prec@5 98.438 (99.319)
2025-05-20 11:46:35 - INFO - TRAINING - Epoch: [36][130/196]	Time 0.139 (0.144)	Data 0.000 (0.010)	Loss 0.5608 (0.5992)	Prec@1 89.453 (87.506)	Prec@5 98.828 (99.317)
2025-05-20 11:46:36 - INFO - TRAINING - Epoch: [36][140/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.6114 (0.5978)	Prec@1 86.719 (87.536)	Prec@5 98.828 (99.310)
2025-05-20 11:46:38 - INFO - TRAINING - Epoch: [36][150/196]	Time 0.131 (0.142)	Data 0.000 (0.009)	Loss 0.6333 (0.5993)	Prec@1 85.156 (87.430)	Prec@5 99.609 (99.299)
2025-05-20 11:46:39 - INFO - TRAINING - Epoch: [36][160/196]	Time 0.158 (0.143)	Data 0.010 (0.009)	Loss 0.6143 (0.5996)	Prec@1 86.719 (87.434)	Prec@5 100.000 (99.306)
2025-05-20 11:46:41 - INFO - TRAINING - Epoch: [36][170/196]	Time 0.137 (0.143)	Data 0.008 (0.008)	Loss 0.5967 (0.5998)	Prec@1 86.719 (87.420)	Prec@5 99.219 (99.319)
2025-05-20 11:46:42 - INFO - TRAINING - Epoch: [36][180/196]	Time 0.134 (0.142)	Data 0.000 (0.008)	Loss 0.6540 (0.6005)	Prec@1 83.594 (87.390)	Prec@5 98.828 (99.324)
2025-05-20 11:46:43 - INFO - TRAINING - Epoch: [36][190/196]	Time 0.132 (0.142)	Data 0.000 (0.008)	Loss 0.6456 (0.6008)	Prec@1 87.500 (87.388)	Prec@5 99.219 (99.335)
2025-05-20 11:46:45 - INFO - EVALUATING - Epoch: [36][0/40]	Time 0.886 (0.886)	Data 0.807 (0.807)	Loss 0.6929 (0.6929)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)
2025-05-20 11:46:46 - INFO - EVALUATING - Epoch: [36][10/40]	Time 0.080 (0.153)	Data 0.000 (0.078)	Loss 0.6451 (0.7083)	Prec@1 85.938 (82.315)	Prec@5 99.609 (98.295)
2025-05-20 11:46:46 - INFO - EVALUATING - Epoch: [36][20/40]	Time 0.086 (0.117)	Data 0.017 (0.044)	Loss 0.7014 (0.7136)	Prec@1 82.422 (82.273)	Prec@5 97.656 (97.991)
2025-05-20 11:46:47 - INFO - EVALUATING - Epoch: [36][30/40]	Time 0.069 (0.103)	Data 0.000 (0.030)	Loss 0.7566 (0.7139)	Prec@1 79.297 (82.132)	Prec@5 98.047 (98.248)
2025-05-20 11:46:48 - INFO - 
 Epoch: 37	Training Loss 0.6011 	Training Prec@1 87.372 	Training Prec@5 99.332 	Validation Loss 0.7092 	Validation Prec@1 82.470 	Validation Prec@5 98.290 

2025-05-20 11:46:48 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:46:48 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:46:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:46:49 - INFO - TRAINING - Epoch: [37][0/196]	Time 0.947 (0.947)	Data 0.840 (0.840)	Loss 0.5773 (0.5773)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
2025-05-20 11:46:50 - INFO - TRAINING - Epoch: [37][10/196]	Time 0.144 (0.214)	Data 0.000 (0.080)	Loss 0.5284 (0.5927)	Prec@1 91.797 (87.855)	Prec@5 99.609 (99.325)
2025-05-20 11:46:52 - INFO - TRAINING - Epoch: [37][20/196]	Time 0.156 (0.180)	Data 0.013 (0.046)	Loss 0.5652 (0.6014)	Prec@1 89.062 (87.481)	Prec@5 99.219 (99.275)
2025-05-20 11:46:53 - INFO - TRAINING - Epoch: [37][30/196]	Time 0.164 (0.170)	Data 0.000 (0.033)	Loss 0.5464 (0.5976)	Prec@1 88.672 (87.550)	Prec@5 99.609 (99.395)
2025-05-20 11:46:55 - INFO - TRAINING - Epoch: [37][40/196]	Time 0.135 (0.162)	Data 0.000 (0.026)	Loss 0.5286 (0.5961)	Prec@1 90.234 (87.662)	Prec@5 100.000 (99.409)
2025-05-20 11:46:56 - INFO - TRAINING - Epoch: [37][50/196]	Time 0.134 (0.157)	Data 0.000 (0.021)	Loss 0.6397 (0.5955)	Prec@1 85.547 (87.707)	Prec@5 98.828 (99.341)
2025-05-20 11:46:57 - INFO - TRAINING - Epoch: [37][60/196]	Time 0.149 (0.153)	Data 0.000 (0.018)	Loss 0.5982 (0.6011)	Prec@1 87.500 (87.526)	Prec@5 99.609 (99.328)
2025-05-20 11:46:59 - INFO - TRAINING - Epoch: [37][70/196]	Time 0.131 (0.151)	Data 0.002 (0.016)	Loss 0.5755 (0.6017)	Prec@1 89.062 (87.489)	Prec@5 99.219 (99.296)
2025-05-20 11:47:00 - INFO - TRAINING - Epoch: [37][80/196]	Time 0.134 (0.148)	Data 0.000 (0.014)	Loss 0.5830 (0.6017)	Prec@1 88.672 (87.510)	Prec@5 100.000 (99.306)
2025-05-20 11:47:01 - INFO - TRAINING - Epoch: [37][90/196]	Time 0.132 (0.147)	Data 0.007 (0.013)	Loss 0.5972 (0.5990)	Prec@1 87.891 (87.620)	Prec@5 99.219 (99.313)
2025-05-20 11:47:03 - INFO - TRAINING - Epoch: [37][100/196]	Time 0.133 (0.145)	Data 0.002 (0.012)	Loss 0.6125 (0.5990)	Prec@1 85.938 (87.601)	Prec@5 98.828 (99.281)
2025-05-20 11:47:04 - INFO - TRAINING - Epoch: [37][110/196]	Time 0.132 (0.145)	Data 0.000 (0.011)	Loss 0.5706 (0.5957)	Prec@1 87.891 (87.729)	Prec@5 100.000 (99.310)
2025-05-20 11:47:05 - INFO - TRAINING - Epoch: [37][120/196]	Time 0.151 (0.144)	Data 0.016 (0.010)	Loss 0.5503 (0.5968)	Prec@1 88.672 (87.655)	Prec@5 99.609 (99.332)
2025-05-20 11:47:07 - INFO - TRAINING - Epoch: [37][130/196]	Time 0.143 (0.144)	Data 0.011 (0.010)	Loss 0.6011 (0.5964)	Prec@1 87.109 (87.694)	Prec@5 99.219 (99.344)
2025-05-20 11:47:08 - INFO - TRAINING - Epoch: [37][140/196]	Time 0.134 (0.144)	Data 0.007 (0.010)	Loss 0.5806 (0.5966)	Prec@1 87.109 (87.691)	Prec@5 99.609 (99.338)
2025-05-20 11:47:10 - INFO - TRAINING - Epoch: [37][150/196]	Time 0.134 (0.143)	Data 0.000 (0.010)	Loss 0.5661 (0.5964)	Prec@1 90.625 (87.710)	Prec@5 98.828 (99.340)
2025-05-20 11:47:11 - INFO - TRAINING - Epoch: [37][160/196]	Time 0.134 (0.143)	Data 0.007 (0.009)	Loss 0.5871 (0.5959)	Prec@1 89.062 (87.728)	Prec@5 99.219 (99.321)
2025-05-20 11:47:12 - INFO - TRAINING - Epoch: [37][170/196]	Time 0.135 (0.142)	Data 0.001 (0.009)	Loss 0.5721 (0.5968)	Prec@1 88.281 (87.687)	Prec@5 100.000 (99.310)
2025-05-20 11:47:14 - INFO - TRAINING - Epoch: [37][180/196]	Time 0.133 (0.142)	Data 0.000 (0.008)	Loss 0.5286 (0.5971)	Prec@1 89.453 (87.645)	Prec@5 99.219 (99.318)
2025-05-20 11:47:15 - INFO - TRAINING - Epoch: [37][190/196]	Time 0.132 (0.141)	Data 0.000 (0.008)	Loss 0.6063 (0.5980)	Prec@1 87.109 (87.576)	Prec@5 99.609 (99.311)
2025-05-20 11:47:16 - INFO - EVALUATING - Epoch: [37][0/40]	Time 0.684 (0.684)	Data 0.616 (0.616)	Loss 0.6707 (0.6707)	Prec@1 83.984 (83.984)	Prec@5 99.219 (99.219)
2025-05-20 11:47:17 - INFO - EVALUATING - Epoch: [37][10/40]	Time 0.073 (0.137)	Data 0.000 (0.061)	Loss 0.5926 (0.6661)	Prec@1 85.547 (84.126)	Prec@5 99.609 (98.651)
2025-05-20 11:47:18 - INFO - EVALUATING - Epoch: [37][20/40]	Time 0.073 (0.122)	Data 0.002 (0.046)	Loss 0.6256 (0.6614)	Prec@1 85.938 (84.487)	Prec@5 98.828 (98.326)
2025-05-20 11:47:19 - INFO - EVALUATING - Epoch: [37][30/40]	Time 0.084 (0.115)	Data 0.000 (0.037)	Loss 0.6868 (0.6670)	Prec@1 82.031 (84.337)	Prec@5 99.609 (98.475)
2025-05-20 11:47:20 - INFO - 
 Epoch: 38	Training Loss 0.5979 	Training Prec@1 87.574 	Training Prec@5 99.310 	Validation Loss 0.6635 	Validation Prec@1 84.450 	Validation Prec@5 98.550 

2025-05-20 11:47:20 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:47:20 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:47:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:47:21 - INFO - TRAINING - Epoch: [38][0/196]	Time 1.168 (1.168)	Data 1.063 (1.063)	Loss 0.5650 (0.5650)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
2025-05-20 11:47:23 - INFO - TRAINING - Epoch: [38][10/196]	Time 0.136 (0.236)	Data 0.000 (0.102)	Loss 0.6235 (0.5895)	Prec@1 86.328 (87.749)	Prec@5 98.047 (99.148)
2025-05-20 11:47:24 - INFO - TRAINING - Epoch: [38][20/196]	Time 0.133 (0.187)	Data 0.000 (0.055)	Loss 0.5566 (0.5922)	Prec@1 88.672 (87.723)	Prec@5 100.000 (99.330)
2025-05-20 11:47:25 - INFO - TRAINING - Epoch: [38][30/196]	Time 0.133 (0.170)	Data 0.000 (0.038)	Loss 0.5660 (0.5871)	Prec@1 87.891 (87.853)	Prec@5 99.219 (99.332)
2025-05-20 11:47:27 - INFO - TRAINING - Epoch: [38][40/196]	Time 0.133 (0.161)	Data 0.006 (0.030)	Loss 0.6393 (0.5918)	Prec@1 87.109 (87.795)	Prec@5 98.828 (99.228)
2025-05-20 11:47:28 - INFO - TRAINING - Epoch: [38][50/196]	Time 0.134 (0.156)	Data 0.000 (0.024)	Loss 0.5027 (0.5868)	Prec@1 93.750 (88.128)	Prec@5 99.219 (99.203)
2025-05-20 11:47:29 - INFO - TRAINING - Epoch: [38][60/196]	Time 0.136 (0.153)	Data 0.000 (0.021)	Loss 0.6018 (0.5893)	Prec@1 88.281 (87.878)	Prec@5 98.828 (99.238)
2025-05-20 11:47:31 - INFO - TRAINING - Epoch: [38][70/196]	Time 0.148 (0.152)	Data 0.000 (0.018)	Loss 0.5552 (0.5903)	Prec@1 89.062 (87.841)	Prec@5 99.609 (99.252)
2025-05-20 11:47:32 - INFO - TRAINING - Epoch: [38][80/196]	Time 0.153 (0.151)	Data 0.000 (0.017)	Loss 0.5866 (0.5914)	Prec@1 87.109 (87.789)	Prec@5 100.000 (99.291)
2025-05-20 11:47:34 - INFO - TRAINING - Epoch: [38][90/196]	Time 0.133 (0.150)	Data 0.000 (0.016)	Loss 0.6001 (0.5926)	Prec@1 86.719 (87.689)	Prec@5 99.609 (99.287)
2025-05-20 11:47:35 - INFO - TRAINING - Epoch: [38][100/196]	Time 0.132 (0.148)	Data 0.000 (0.014)	Loss 0.5546 (0.5909)	Prec@1 88.672 (87.782)	Prec@5 99.609 (99.288)
2025-05-20 11:47:36 - INFO - TRAINING - Epoch: [38][110/196]	Time 0.133 (0.147)	Data 0.000 (0.013)	Loss 0.6368 (0.5911)	Prec@1 87.500 (87.774)	Prec@5 98.828 (99.300)
2025-05-20 11:47:38 - INFO - TRAINING - Epoch: [38][120/196]	Time 0.133 (0.146)	Data 0.007 (0.012)	Loss 0.6448 (0.5920)	Prec@1 84.766 (87.729)	Prec@5 99.609 (99.316)
2025-05-20 11:47:39 - INFO - TRAINING - Epoch: [38][130/196]	Time 0.133 (0.145)	Data 0.000 (0.012)	Loss 0.5678 (0.5926)	Prec@1 87.109 (87.676)	Prec@5 98.438 (99.293)
2025-05-20 11:47:40 - INFO - TRAINING - Epoch: [38][140/196]	Time 0.134 (0.144)	Data 0.007 (0.011)	Loss 0.6270 (0.5941)	Prec@1 85.938 (87.614)	Prec@5 98.828 (99.299)
2025-05-20 11:47:42 - INFO - TRAINING - Epoch: [38][150/196]	Time 0.133 (0.143)	Data 0.000 (0.010)	Loss 0.6207 (0.5950)	Prec@1 86.328 (87.575)	Prec@5 99.219 (99.307)
2025-05-20 11:47:43 - INFO - TRAINING - Epoch: [38][160/196]	Time 0.146 (0.143)	Data 0.000 (0.010)	Loss 0.6376 (0.5957)	Prec@1 84.766 (87.502)	Prec@5 98.828 (99.294)
2025-05-20 11:47:44 - INFO - TRAINING - Epoch: [38][170/196]	Time 0.139 (0.143)	Data 0.017 (0.010)	Loss 0.6351 (0.5958)	Prec@1 85.938 (87.468)	Prec@5 98.828 (99.301)
2025-05-20 11:47:46 - INFO - TRAINING - Epoch: [38][180/196]	Time 0.151 (0.143)	Data 0.000 (0.010)	Loss 0.6030 (0.5957)	Prec@1 86.719 (87.446)	Prec@5 99.219 (99.314)
2025-05-20 11:47:47 - INFO - TRAINING - Epoch: [38][190/196]	Time 0.132 (0.142)	Data 0.000 (0.009)	Loss 0.5459 (0.5953)	Prec@1 89.844 (87.475)	Prec@5 100.000 (99.331)
2025-05-20 11:47:49 - INFO - EVALUATING - Epoch: [38][0/40]	Time 0.742 (0.742)	Data 0.662 (0.662)	Loss 0.6535 (0.6535)	Prec@1 85.938 (85.938)	Prec@5 98.828 (98.828)
2025-05-20 11:47:50 - INFO - EVALUATING - Epoch: [38][10/40]	Time 0.089 (0.142)	Data 0.000 (0.065)	Loss 0.6454 (0.6941)	Prec@1 84.375 (83.771)	Prec@5 98.438 (98.118)
2025-05-20 11:47:50 - INFO - EVALUATING - Epoch: [38][20/40]	Time 0.075 (0.111)	Data 0.001 (0.036)	Loss 0.6552 (0.6954)	Prec@1 85.156 (83.426)	Prec@5 98.828 (97.991)
2025-05-20 11:47:51 - INFO - EVALUATING - Epoch: [38][30/40]	Time 0.069 (0.099)	Data 0.000 (0.025)	Loss 0.7167 (0.6981)	Prec@1 80.469 (83.165)	Prec@5 98.438 (98.248)
2025-05-20 11:47:52 - INFO - 
 Epoch: 39	Training Loss 0.5955 	Training Prec@1 87.470 	Training Prec@5 99.336 	Validation Loss 0.6979 	Validation Prec@1 83.140 	Validation Prec@5 98.360 

2025-05-20 11:47:52 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:47:52 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:47:52 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:47:53 - INFO - TRAINING - Epoch: [39][0/196]	Time 1.071 (1.071)	Data 0.951 (0.951)	Loss 0.5840 (0.5840)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
2025-05-20 11:47:54 - INFO - TRAINING - Epoch: [39][10/196]	Time 0.148 (0.230)	Data 0.013 (0.092)	Loss 0.6099 (0.5901)	Prec@1 85.938 (88.175)	Prec@5 99.219 (99.396)
2025-05-20 11:47:56 - INFO - TRAINING - Epoch: [39][20/196]	Time 0.133 (0.184)	Data 0.000 (0.049)	Loss 0.5876 (0.5820)	Prec@1 89.453 (88.318)	Prec@5 99.219 (99.479)
2025-05-20 11:47:57 - INFO - TRAINING - Epoch: [39][30/196]	Time 0.136 (0.169)	Data 0.000 (0.035)	Loss 0.5469 (0.5865)	Prec@1 91.797 (88.117)	Prec@5 98.828 (99.345)
2025-05-20 11:47:59 - INFO - TRAINING - Epoch: [39][40/196]	Time 0.166 (0.164)	Data 0.000 (0.027)	Loss 0.5641 (0.5846)	Prec@1 89.062 (88.138)	Prec@5 99.219 (99.400)
2025-05-20 11:48:00 - INFO - TRAINING - Epoch: [39][50/196]	Time 0.131 (0.161)	Data 0.009 (0.024)	Loss 0.5582 (0.5840)	Prec@1 87.109 (88.159)	Prec@5 100.000 (99.426)
2025-05-20 11:48:01 - INFO - TRAINING - Epoch: [39][60/196]	Time 0.133 (0.157)	Data 0.001 (0.021)	Loss 0.5338 (0.5842)	Prec@1 90.234 (88.032)	Prec@5 99.219 (99.456)
2025-05-20 11:48:03 - INFO - TRAINING - Epoch: [39][70/196]	Time 0.133 (0.153)	Data 0.007 (0.018)	Loss 0.5945 (0.5848)	Prec@1 87.500 (88.028)	Prec@5 100.000 (99.477)
2025-05-20 11:48:04 - INFO - TRAINING - Epoch: [39][80/196]	Time 0.134 (0.151)	Data 0.003 (0.017)	Loss 0.6259 (0.5850)	Prec@1 86.719 (87.973)	Prec@5 99.219 (99.455)
2025-05-20 11:48:05 - INFO - TRAINING - Epoch: [39][90/196]	Time 0.133 (0.149)	Data 0.003 (0.015)	Loss 0.6664 (0.5849)	Prec@1 83.594 (87.972)	Prec@5 98.047 (99.451)
2025-05-20 11:48:07 - INFO - TRAINING - Epoch: [39][100/196]	Time 0.134 (0.147)	Data 0.000 (0.014)	Loss 0.5841 (0.5843)	Prec@1 87.891 (88.057)	Prec@5 100.000 (99.459)
2025-05-20 11:48:08 - INFO - TRAINING - Epoch: [39][110/196]	Time 0.133 (0.146)	Data 0.003 (0.013)	Loss 0.6210 (0.5838)	Prec@1 86.328 (88.116)	Prec@5 99.219 (99.451)
2025-05-20 11:48:09 - INFO - TRAINING - Epoch: [39][120/196]	Time 0.134 (0.145)	Data 0.000 (0.012)	Loss 0.5815 (0.5832)	Prec@1 88.672 (88.159)	Prec@5 99.219 (99.432)
2025-05-20 11:48:11 - INFO - TRAINING - Epoch: [39][130/196]	Time 0.142 (0.145)	Data 0.009 (0.011)	Loss 0.6332 (0.5843)	Prec@1 85.156 (88.090)	Prec@5 99.219 (99.422)
2025-05-20 11:48:12 - INFO - TRAINING - Epoch: [39][140/196]	Time 0.142 (0.145)	Data 0.001 (0.011)	Loss 0.5773 (0.5847)	Prec@1 89.844 (88.051)	Prec@5 99.219 (99.427)
2025-05-20 11:48:14 - INFO - TRAINING - Epoch: [39][150/196]	Time 0.144 (0.145)	Data 0.010 (0.011)	Loss 0.6568 (0.5861)	Prec@1 84.766 (87.979)	Prec@5 99.609 (99.421)
2025-05-20 11:48:15 - INFO - TRAINING - Epoch: [39][160/196]	Time 0.138 (0.144)	Data 0.000 (0.010)	Loss 0.5924 (0.5871)	Prec@1 85.547 (87.917)	Prec@5 99.219 (99.420)
2025-05-20 11:48:16 - INFO - TRAINING - Epoch: [39][170/196]	Time 0.134 (0.144)	Data 0.007 (0.010)	Loss 0.6384 (0.5875)	Prec@1 87.109 (87.893)	Prec@5 100.000 (99.427)
2025-05-20 11:48:18 - INFO - TRAINING - Epoch: [39][180/196]	Time 0.132 (0.143)	Data 0.000 (0.009)	Loss 0.6419 (0.5888)	Prec@1 84.766 (87.811)	Prec@5 98.828 (99.422)
2025-05-20 11:48:19 - INFO - TRAINING - Epoch: [39][190/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.5797 (0.5885)	Prec@1 89.844 (87.835)	Prec@5 99.219 (99.427)
2025-05-20 11:48:20 - INFO - EVALUATING - Epoch: [39][0/40]	Time 0.599 (0.599)	Data 0.496 (0.496)	Loss 0.7243 (0.7243)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)
2025-05-20 11:48:21 - INFO - EVALUATING - Epoch: [39][10/40]	Time 0.098 (0.147)	Data 0.018 (0.072)	Loss 0.5952 (0.6799)	Prec@1 86.328 (83.523)	Prec@5 99.609 (98.722)
2025-05-20 11:48:22 - INFO - EVALUATING - Epoch: [39][20/40]	Time 0.070 (0.114)	Data 0.001 (0.039)	Loss 0.6392 (0.6752)	Prec@1 85.938 (84.170)	Prec@5 98.047 (98.438)
2025-05-20 11:48:23 - INFO - EVALUATING - Epoch: [39][30/40]	Time 0.070 (0.101)	Data 0.000 (0.027)	Loss 0.6941 (0.6823)	Prec@1 83.203 (83.770)	Prec@5 98.047 (98.475)
2025-05-20 11:48:24 - INFO - 
 Epoch: 40	Training Loss 0.5884 	Training Prec@1 87.824 	Training Prec@5 99.430 	Validation Loss 0.6814 	Validation Prec@1 83.830 	Validation Prec@5 98.570 

2025-05-20 11:48:24 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:48:24 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:48:24 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:48:24 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:48:26 - INFO - TRAINING - Epoch: [40][0/196]	Time 1.713 (1.713)	Data 1.525 (1.525)	Loss 0.5552 (0.5552)	Prec@1 90.625 (90.625)	Prec@5 99.609 (99.609)
2025-05-20 11:48:27 - INFO - TRAINING - Epoch: [40][10/196]	Time 0.137 (0.286)	Data 0.001 (0.142)	Loss 0.6407 (0.5680)	Prec@1 84.766 (88.388)	Prec@5 99.219 (99.716)
2025-05-20 11:48:28 - INFO - TRAINING - Epoch: [40][20/196]	Time 0.134 (0.216)	Data 0.004 (0.076)	Loss 0.5702 (0.5636)	Prec@1 89.844 (88.523)	Prec@5 98.438 (99.554)
2025-05-20 11:48:30 - INFO - TRAINING - Epoch: [40][30/196]	Time 0.148 (0.190)	Data 0.003 (0.052)	Loss 0.5297 (0.5671)	Prec@1 89.453 (88.508)	Prec@5 100.000 (99.597)
2025-05-20 11:48:31 - INFO - TRAINING - Epoch: [40][40/196]	Time 0.137 (0.177)	Data 0.000 (0.040)	Loss 0.5347 (0.5634)	Prec@1 90.234 (88.729)	Prec@5 99.219 (99.609)
2025-05-20 11:48:32 - INFO - TRAINING - Epoch: [40][50/196]	Time 0.133 (0.169)	Data 0.000 (0.033)	Loss 0.5244 (0.5551)	Prec@1 91.406 (89.162)	Prec@5 98.828 (99.625)
2025-05-20 11:48:34 - INFO - TRAINING - Epoch: [40][60/196]	Time 0.133 (0.163)	Data 0.000 (0.028)	Loss 0.5619 (0.5545)	Prec@1 87.109 (89.159)	Prec@5 100.000 (99.635)
2025-05-20 11:48:35 - INFO - TRAINING - Epoch: [40][70/196]	Time 0.132 (0.159)	Data 0.000 (0.024)	Loss 0.5940 (0.5550)	Prec@1 86.328 (89.074)	Prec@5 99.609 (99.642)
2025-05-20 11:48:36 - INFO - TRAINING - Epoch: [40][80/196]	Time 0.125 (0.156)	Data 0.010 (0.021)	Loss 0.5261 (0.5557)	Prec@1 90.625 (89.120)	Prec@5 99.609 (99.629)
2025-05-20 11:48:38 - INFO - TRAINING - Epoch: [40][90/196]	Time 0.148 (0.155)	Data 0.012 (0.020)	Loss 0.6053 (0.5559)	Prec@1 87.500 (89.144)	Prec@5 99.219 (99.584)
2025-05-20 11:48:39 - INFO - TRAINING - Epoch: [40][100/196]	Time 0.147 (0.154)	Data 0.007 (0.020)	Loss 0.4710 (0.5535)	Prec@1 91.797 (89.279)	Prec@5 99.609 (99.575)
2025-05-20 11:48:41 - INFO - TRAINING - Epoch: [40][110/196]	Time 0.135 (0.152)	Data 0.000 (0.018)	Loss 0.5234 (0.5533)	Prec@1 89.062 (89.302)	Prec@5 99.609 (99.560)
2025-05-20 11:48:42 - INFO - TRAINING - Epoch: [40][120/196]	Time 0.132 (0.151)	Data 0.000 (0.016)	Loss 0.4883 (0.5524)	Prec@1 91.797 (89.324)	Prec@5 100.000 (99.577)
2025-05-20 11:48:43 - INFO - TRAINING - Epoch: [40][130/196]	Time 0.130 (0.150)	Data 0.000 (0.015)	Loss 0.5237 (0.5502)	Prec@1 90.625 (89.489)	Prec@5 100.000 (99.574)
2025-05-20 11:48:45 - INFO - TRAINING - Epoch: [40][140/196]	Time 0.131 (0.149)	Data 0.000 (0.014)	Loss 0.5203 (0.5505)	Prec@1 89.062 (89.464)	Prec@5 99.609 (99.573)
2025-05-20 11:48:46 - INFO - TRAINING - Epoch: [40][150/196]	Time 0.135 (0.148)	Data 0.000 (0.014)	Loss 0.5397 (0.5503)	Prec@1 89.062 (89.484)	Prec@5 99.609 (99.573)
2025-05-20 11:48:47 - INFO - TRAINING - Epoch: [40][160/196]	Time 0.134 (0.147)	Data 0.000 (0.013)	Loss 0.5514 (0.5494)	Prec@1 90.234 (89.528)	Prec@5 99.219 (99.571)
2025-05-20 11:48:49 - INFO - TRAINING - Epoch: [40][170/196]	Time 0.133 (0.146)	Data 0.000 (0.012)	Loss 0.5593 (0.5478)	Prec@1 87.891 (89.572)	Prec@5 99.219 (99.575)
2025-05-20 11:48:50 - INFO - TRAINING - Epoch: [40][180/196]	Time 0.126 (0.146)	Data 0.000 (0.012)	Loss 0.5633 (0.5485)	Prec@1 87.891 (89.520)	Prec@5 99.219 (99.575)
2025-05-20 11:48:52 - INFO - TRAINING - Epoch: [40][190/196]	Time 0.135 (0.145)	Data 0.000 (0.011)	Loss 0.5545 (0.5479)	Prec@1 90.625 (89.508)	Prec@5 99.609 (99.585)
2025-05-20 11:48:53 - INFO - EVALUATING - Epoch: [40][0/40]	Time 0.779 (0.779)	Data 0.701 (0.701)	Loss 0.6003 (0.6003)	Prec@1 87.109 (87.109)	Prec@5 98.828 (98.828)
2025-05-20 11:48:54 - INFO - EVALUATING - Epoch: [40][10/40]	Time 0.094 (0.144)	Data 0.013 (0.068)	Loss 0.6052 (0.6365)	Prec@1 86.328 (85.511)	Prec@5 98.047 (98.544)
2025-05-20 11:48:55 - INFO - EVALUATING - Epoch: [40][20/40]	Time 0.090 (0.114)	Data 0.007 (0.037)	Loss 0.5920 (0.6383)	Prec@1 87.891 (85.547)	Prec@5 98.828 (98.363)
2025-05-20 11:48:55 - INFO - EVALUATING - Epoch: [40][30/40]	Time 0.070 (0.101)	Data 0.000 (0.026)	Loss 0.6597 (0.6436)	Prec@1 83.594 (85.370)	Prec@5 99.609 (98.513)
2025-05-20 11:48:56 - INFO - 
 Epoch: 41	Training Loss 0.5476 	Training Prec@1 89.518 	Training Prec@5 99.590 	Validation Loss 0.6441 	Validation Prec@1 85.310 	Validation Prec@5 98.540 

2025-05-20 11:48:56 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:48:56 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:48:56 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:48:56 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:48:57 - INFO - TRAINING - Epoch: [41][0/196]	Time 1.060 (1.060)	Data 0.931 (0.931)	Loss 0.5073 (0.5073)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2025-05-20 11:48:59 - INFO - TRAINING - Epoch: [41][10/196]	Time 0.138 (0.230)	Data 0.006 (0.090)	Loss 0.5671 (0.5422)	Prec@1 87.500 (89.879)	Prec@5 99.219 (99.716)
2025-05-20 11:49:00 - INFO - TRAINING - Epoch: [41][20/196]	Time 0.134 (0.185)	Data 0.000 (0.049)	Loss 0.5029 (0.5405)	Prec@1 91.016 (89.732)	Prec@5 99.219 (99.665)
2025-05-20 11:49:02 - INFO - TRAINING - Epoch: [41][30/196]	Time 0.135 (0.170)	Data 0.000 (0.034)	Loss 0.5502 (0.5347)	Prec@1 88.672 (90.121)	Prec@5 99.609 (99.647)
2025-05-20 11:49:03 - INFO - TRAINING - Epoch: [41][40/196]	Time 0.147 (0.163)	Data 0.012 (0.027)	Loss 0.5406 (0.5379)	Prec@1 91.797 (89.968)	Prec@5 99.609 (99.676)
2025-05-20 11:49:04 - INFO - TRAINING - Epoch: [41][50/196]	Time 0.159 (0.159)	Data 0.000 (0.023)	Loss 0.4875 (0.5385)	Prec@1 94.531 (89.936)	Prec@5 99.219 (99.671)
2025-05-20 11:49:06 - INFO - TRAINING - Epoch: [41][60/196]	Time 0.134 (0.157)	Data 0.000 (0.021)	Loss 0.5694 (0.5367)	Prec@1 88.672 (90.036)	Prec@5 100.000 (99.667)
2025-05-20 11:49:07 - INFO - TRAINING - Epoch: [41][70/196]	Time 0.135 (0.154)	Data 0.000 (0.018)	Loss 0.5372 (0.5365)	Prec@1 89.844 (90.042)	Prec@5 99.609 (99.642)
2025-05-20 11:49:09 - INFO - TRAINING - Epoch: [41][80/196]	Time 0.134 (0.151)	Data 0.003 (0.016)	Loss 0.5966 (0.5373)	Prec@1 85.938 (90.051)	Prec@5 98.828 (99.619)
2025-05-20 11:49:10 - INFO - TRAINING - Epoch: [41][90/196]	Time 0.134 (0.149)	Data 0.000 (0.015)	Loss 0.4816 (0.5381)	Prec@1 92.188 (89.942)	Prec@5 100.000 (99.627)
2025-05-20 11:49:11 - INFO - TRAINING - Epoch: [41][100/196]	Time 0.133 (0.148)	Data 0.000 (0.013)	Loss 0.5121 (0.5382)	Prec@1 91.406 (90.010)	Prec@5 100.000 (99.606)
2025-05-20 11:49:13 - INFO - TRAINING - Epoch: [41][110/196]	Time 0.133 (0.147)	Data 0.000 (0.012)	Loss 0.5475 (0.5393)	Prec@1 89.062 (89.988)	Prec@5 100.000 (99.585)
2025-05-20 11:49:14 - INFO - TRAINING - Epoch: [41][120/196]	Time 0.135 (0.145)	Data 0.000 (0.012)	Loss 0.5715 (0.5409)	Prec@1 89.062 (89.966)	Prec@5 98.438 (99.574)
2025-05-20 11:49:15 - INFO - TRAINING - Epoch: [41][130/196]	Time 0.149 (0.145)	Data 0.000 (0.011)	Loss 0.5188 (0.5405)	Prec@1 90.625 (89.954)	Prec@5 99.219 (99.565)
2025-05-20 11:49:17 - INFO - TRAINING - Epoch: [41][140/196]	Time 0.132 (0.145)	Data 0.000 (0.011)	Loss 0.5503 (0.5407)	Prec@1 88.281 (89.907)	Prec@5 100.000 (99.568)
2025-05-20 11:49:18 - INFO - TRAINING - Epoch: [41][150/196]	Time 0.152 (0.145)	Data 0.005 (0.010)	Loss 0.5572 (0.5404)	Prec@1 88.672 (89.919)	Prec@5 99.219 (99.571)
2025-05-20 11:49:20 - INFO - TRAINING - Epoch: [41][160/196]	Time 0.134 (0.144)	Data 0.000 (0.010)	Loss 0.5455 (0.5394)	Prec@1 89.844 (89.967)	Prec@5 100.000 (99.573)
2025-05-20 11:49:21 - INFO - TRAINING - Epoch: [41][170/196]	Time 0.144 (0.144)	Data 0.000 (0.010)	Loss 0.5296 (0.5386)	Prec@1 90.234 (89.999)	Prec@5 99.219 (99.575)
2025-05-20 11:49:22 - INFO - TRAINING - Epoch: [41][180/196]	Time 0.132 (0.143)	Data 0.000 (0.009)	Loss 0.4810 (0.5373)	Prec@1 93.359 (90.068)	Prec@5 99.219 (99.577)
2025-05-20 11:49:24 - INFO - TRAINING - Epoch: [41][190/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.5305 (0.5384)	Prec@1 91.406 (90.024)	Prec@5 99.609 (99.577)
2025-05-20 11:49:25 - INFO - EVALUATING - Epoch: [41][0/40]	Time 0.714 (0.714)	Data 0.624 (0.624)	Loss 0.6345 (0.6345)	Prec@1 86.328 (86.328)	Prec@5 98.828 (98.828)
2025-05-20 11:49:26 - INFO - EVALUATING - Epoch: [41][10/40]	Time 0.072 (0.150)	Data 0.003 (0.076)	Loss 0.5971 (0.6345)	Prec@1 86.328 (84.943)	Prec@5 99.219 (98.722)
2025-05-20 11:49:27 - INFO - EVALUATING - Epoch: [41][20/40]	Time 0.070 (0.116)	Data 0.000 (0.042)	Loss 0.5978 (0.6305)	Prec@1 86.719 (85.472)	Prec@5 98.438 (98.382)
2025-05-20 11:49:27 - INFO - EVALUATING - Epoch: [41][30/40]	Time 0.070 (0.102)	Data 0.000 (0.030)	Loss 0.6369 (0.6351)	Prec@1 83.594 (85.358)	Prec@5 99.219 (98.627)
2025-05-20 11:49:28 - INFO - 
 Epoch: 42	Training Loss 0.5386 	Training Prec@1 90.030 	Training Prec@5 99.570 	Validation Loss 0.6358 	Validation Prec@1 85.270 	Validation Prec@5 98.710 

2025-05-20 11:49:28 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:49:28 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:49:28 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:49:28 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:49:30 - INFO - TRAINING - Epoch: [42][0/196]	Time 1.346 (1.346)	Data 1.223 (1.223)	Loss 0.5107 (0.5107)	Prec@1 91.406 (91.406)	Prec@5 99.609 (99.609)
2025-05-20 11:49:31 - INFO - TRAINING - Epoch: [42][10/196]	Time 0.194 (0.278)	Data 0.002 (0.124)	Loss 0.5247 (0.5415)	Prec@1 91.016 (90.128)	Prec@5 99.609 (99.609)
2025-05-20 11:49:33 - INFO - TRAINING - Epoch: [42][20/196]	Time 0.134 (0.216)	Data 0.000 (0.067)	Loss 0.5027 (0.5338)	Prec@1 90.625 (90.346)	Prec@5 100.000 (99.628)
2025-05-20 11:49:34 - INFO - TRAINING - Epoch: [42][30/196]	Time 0.133 (0.191)	Data 0.000 (0.047)	Loss 0.5081 (0.5293)	Prec@1 91.797 (90.436)	Prec@5 99.219 (99.647)
2025-05-20 11:49:35 - INFO - TRAINING - Epoch: [42][40/196]	Time 0.133 (0.177)	Data 0.000 (0.036)	Loss 0.5605 (0.5290)	Prec@1 90.234 (90.501)	Prec@5 99.609 (99.619)
2025-05-20 11:49:37 - INFO - TRAINING - Epoch: [42][50/196]	Time 0.133 (0.169)	Data 0.007 (0.029)	Loss 0.5418 (0.5297)	Prec@1 89.453 (90.495)	Prec@5 99.609 (99.609)
2025-05-20 11:49:38 - INFO - TRAINING - Epoch: [42][60/196]	Time 0.133 (0.163)	Data 0.000 (0.025)	Loss 0.5360 (0.5295)	Prec@1 87.891 (90.401)	Prec@5 99.609 (99.590)
2025-05-20 11:49:39 - INFO - TRAINING - Epoch: [42][70/196]	Time 0.133 (0.159)	Data 0.000 (0.022)	Loss 0.5098 (0.5272)	Prec@1 91.406 (90.559)	Prec@5 99.609 (99.576)
2025-05-20 11:49:41 - INFO - TRAINING - Epoch: [42][80/196]	Time 0.133 (0.156)	Data 0.000 (0.019)	Loss 0.5410 (0.5274)	Prec@1 89.453 (90.533)	Prec@5 99.609 (99.595)
2025-05-20 11:49:42 - INFO - TRAINING - Epoch: [42][90/196]	Time 0.143 (0.154)	Data 0.007 (0.018)	Loss 0.5403 (0.5285)	Prec@1 89.453 (90.432)	Prec@5 100.000 (99.622)
2025-05-20 11:49:44 - INFO - TRAINING - Epoch: [42][100/196]	Time 0.134 (0.153)	Data 0.012 (0.016)	Loss 0.5066 (0.5284)	Prec@1 91.016 (90.451)	Prec@5 99.609 (99.633)
2025-05-20 11:49:45 - INFO - TRAINING - Epoch: [42][110/196]	Time 0.139 (0.152)	Data 0.016 (0.015)	Loss 0.4819 (0.5284)	Prec@1 92.969 (90.537)	Prec@5 99.609 (99.620)
2025-05-20 11:49:46 - INFO - TRAINING - Epoch: [42][120/196]	Time 0.132 (0.150)	Data 0.000 (0.014)	Loss 0.5227 (0.5279)	Prec@1 89.453 (90.570)	Prec@5 99.609 (99.616)
2025-05-20 11:49:48 - INFO - TRAINING - Epoch: [42][130/196]	Time 0.130 (0.149)	Data 0.000 (0.013)	Loss 0.4945 (0.5278)	Prec@1 91.406 (90.601)	Prec@5 100.000 (99.627)
2025-05-20 11:49:49 - INFO - TRAINING - Epoch: [42][140/196]	Time 0.133 (0.148)	Data 0.000 (0.012)	Loss 0.5394 (0.5280)	Prec@1 90.234 (90.589)	Prec@5 99.219 (99.615)
2025-05-20 11:49:50 - INFO - TRAINING - Epoch: [42][150/196]	Time 0.132 (0.147)	Data 0.000 (0.012)	Loss 0.5102 (0.5269)	Prec@1 90.625 (90.615)	Prec@5 98.828 (99.622)
2025-05-20 11:49:52 - INFO - TRAINING - Epoch: [42][160/196]	Time 0.134 (0.146)	Data 0.006 (0.011)	Loss 0.5093 (0.5277)	Prec@1 90.625 (90.579)	Prec@5 99.609 (99.612)
2025-05-20 11:49:53 - INFO - TRAINING - Epoch: [42][170/196]	Time 0.131 (0.145)	Data 0.000 (0.010)	Loss 0.5393 (0.5277)	Prec@1 89.844 (90.552)	Prec@5 100.000 (99.612)
2025-05-20 11:49:54 - INFO - TRAINING - Epoch: [42][180/196]	Time 0.133 (0.145)	Data 0.000 (0.010)	Loss 0.5248 (0.5278)	Prec@1 91.016 (90.582)	Prec@5 100.000 (99.594)
2025-05-20 11:49:56 - INFO - TRAINING - Epoch: [42][190/196]	Time 0.136 (0.144)	Data 0.000 (0.009)	Loss 0.5153 (0.5290)	Prec@1 90.625 (90.533)	Prec@5 100.000 (99.597)
2025-05-20 11:49:57 - INFO - EVALUATING - Epoch: [42][0/40]	Time 0.729 (0.729)	Data 0.658 (0.658)	Loss 0.6395 (0.6395)	Prec@1 86.328 (86.328)	Prec@5 98.828 (98.828)
2025-05-20 11:49:58 - INFO - EVALUATING - Epoch: [42][10/40]	Time 0.083 (0.160)	Data 0.003 (0.081)	Loss 0.6118 (0.6361)	Prec@1 85.938 (85.298)	Prec@5 98.438 (98.828)
2025-05-20 11:49:59 - INFO - EVALUATING - Epoch: [42][20/40]	Time 0.085 (0.120)	Data 0.000 (0.044)	Loss 0.6179 (0.6337)	Prec@1 86.328 (85.844)	Prec@5 98.438 (98.679)
2025-05-20 11:50:00 - INFO - EVALUATING - Epoch: [42][30/40]	Time 0.069 (0.105)	Data 0.000 (0.030)	Loss 0.6974 (0.6403)	Prec@1 83.203 (85.559)	Prec@5 98.828 (98.727)
2025-05-20 11:50:01 - INFO - 
 Epoch: 43	Training Loss 0.5288 	Training Prec@1 90.546 	Training Prec@5 99.598 	Validation Loss 0.6412 	Validation Prec@1 85.490 	Validation Prec@5 98.700 

2025-05-20 11:50:01 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:50:01 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:50:01 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:50:01 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:50:02 - INFO - TRAINING - Epoch: [43][0/196]	Time 0.997 (0.997)	Data 0.880 (0.880)	Loss 0.5288 (0.5288)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
2025-05-20 11:50:03 - INFO - TRAINING - Epoch: [43][10/196]	Time 0.141 (0.222)	Data 0.000 (0.082)	Loss 0.5116 (0.5383)	Prec@1 92.578 (90.412)	Prec@5 99.219 (99.574)
2025-05-20 11:50:04 - INFO - TRAINING - Epoch: [43][20/196]	Time 0.142 (0.184)	Data 0.010 (0.044)	Loss 0.5862 (0.5440)	Prec@1 89.844 (90.309)	Prec@5 98.828 (99.554)
2025-05-20 11:50:06 - INFO - TRAINING - Epoch: [43][30/196]	Time 0.134 (0.168)	Data 0.000 (0.030)	Loss 0.4622 (0.5465)	Prec@1 93.750 (90.171)	Prec@5 99.609 (99.559)
2025-05-20 11:50:07 - INFO - TRAINING - Epoch: [43][40/196]	Time 0.144 (0.160)	Data 0.000 (0.023)	Loss 0.5824 (0.5451)	Prec@1 87.109 (90.177)	Prec@5 100.000 (99.581)
2025-05-20 11:50:09 - INFO - TRAINING - Epoch: [43][50/196]	Time 0.145 (0.156)	Data 0.009 (0.020)	Loss 0.5282 (0.5395)	Prec@1 90.625 (90.334)	Prec@5 100.000 (99.617)
2025-05-20 11:50:10 - INFO - TRAINING - Epoch: [43][60/196]	Time 0.143 (0.155)	Data 0.028 (0.019)	Loss 0.5478 (0.5390)	Prec@1 88.281 (90.311)	Prec@5 99.609 (99.603)
2025-05-20 11:50:11 - INFO - TRAINING - Epoch: [43][70/196]	Time 0.133 (0.153)	Data 0.002 (0.017)	Loss 0.5415 (0.5380)	Prec@1 89.453 (90.278)	Prec@5 99.609 (99.587)
2025-05-20 11:50:13 - INFO - TRAINING - Epoch: [43][80/196]	Time 0.134 (0.150)	Data 0.000 (0.015)	Loss 0.5253 (0.5396)	Prec@1 90.625 (90.177)	Prec@5 99.609 (99.580)
2025-05-20 11:50:14 - INFO - TRAINING - Epoch: [43][90/196]	Time 0.133 (0.148)	Data 0.001 (0.014)	Loss 0.4986 (0.5377)	Prec@1 91.406 (90.273)	Prec@5 100.000 (99.605)
2025-05-20 11:50:15 - INFO - TRAINING - Epoch: [43][100/196]	Time 0.133 (0.147)	Data 0.011 (0.012)	Loss 0.5461 (0.5363)	Prec@1 90.625 (90.347)	Prec@5 98.828 (99.602)
2025-05-20 11:50:17 - INFO - TRAINING - Epoch: [43][110/196]	Time 0.136 (0.146)	Data 0.000 (0.011)	Loss 0.5274 (0.5335)	Prec@1 90.234 (90.460)	Prec@5 98.828 (99.595)
2025-05-20 11:50:18 - INFO - TRAINING - Epoch: [43][120/196]	Time 0.136 (0.145)	Data 0.000 (0.011)	Loss 0.5344 (0.5329)	Prec@1 88.672 (90.486)	Prec@5 100.000 (99.613)
2025-05-20 11:50:19 - INFO - TRAINING - Epoch: [43][130/196]	Time 0.133 (0.144)	Data 0.000 (0.010)	Loss 0.4896 (0.5318)	Prec@1 94.141 (90.556)	Prec@5 99.219 (99.627)
2025-05-20 11:50:21 - INFO - TRAINING - Epoch: [43][140/196]	Time 0.129 (0.143)	Data 0.004 (0.009)	Loss 0.4960 (0.5310)	Prec@1 92.188 (90.556)	Prec@5 99.219 (99.634)
2025-05-20 11:50:22 - INFO - TRAINING - Epoch: [43][150/196]	Time 0.152 (0.144)	Data 0.013 (0.009)	Loss 0.5634 (0.5300)	Prec@1 89.062 (90.612)	Prec@5 98.438 (99.640)
2025-05-20 11:50:24 - INFO - TRAINING - Epoch: [43][160/196]	Time 0.139 (0.144)	Data 0.009 (0.009)	Loss 0.5522 (0.5316)	Prec@1 89.453 (90.521)	Prec@5 100.000 (99.643)
2025-05-20 11:50:25 - INFO - TRAINING - Epoch: [43][170/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.5699 (0.5315)	Prec@1 88.672 (90.504)	Prec@5 99.219 (99.653)
2025-05-20 11:50:26 - INFO - TRAINING - Epoch: [43][180/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.4981 (0.5309)	Prec@1 92.578 (90.537)	Prec@5 100.000 (99.646)
2025-05-20 11:50:28 - INFO - TRAINING - Epoch: [43][190/196]	Time 0.132 (0.142)	Data 0.000 (0.008)	Loss 0.5296 (0.5308)	Prec@1 89.062 (90.508)	Prec@5 100.000 (99.650)
2025-05-20 11:50:29 - INFO - EVALUATING - Epoch: [43][0/40]	Time 0.711 (0.711)	Data 0.635 (0.635)	Loss 0.6011 (0.6011)	Prec@1 88.281 (88.281)	Prec@5 98.047 (98.047)
2025-05-20 11:50:30 - INFO - EVALUATING - Epoch: [43][10/40]	Time 0.072 (0.136)	Data 0.002 (0.060)	Loss 0.6154 (0.6560)	Prec@1 85.547 (84.979)	Prec@5 99.219 (98.580)
2025-05-20 11:50:31 - INFO - EVALUATING - Epoch: [43][20/40]	Time 0.083 (0.107)	Data 0.006 (0.033)	Loss 0.6533 (0.6563)	Prec@1 85.547 (85.045)	Prec@5 98.438 (98.456)
2025-05-20 11:50:32 - INFO - EVALUATING - Epoch: [43][30/40]	Time 0.070 (0.096)	Data 0.000 (0.023)	Loss 0.6814 (0.6588)	Prec@1 82.031 (85.144)	Prec@5 98.438 (98.501)
2025-05-20 11:50:32 - INFO - 
 Epoch: 44	Training Loss 0.5310 	Training Prec@1 90.486 	Training Prec@5 99.646 	Validation Loss 0.6573 	Validation Prec@1 85.220 	Validation Prec@5 98.510 

2025-05-20 11:50:32 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:50:32 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:50:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:50:32 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:50:33 - INFO - TRAINING - Epoch: [44][0/196]	Time 0.965 (0.965)	Data 0.846 (0.846)	Loss 0.5455 (0.5455)	Prec@1 89.453 (89.453)	Prec@5 99.219 (99.219)
2025-05-20 11:50:35 - INFO - TRAINING - Epoch: [44][10/196]	Time 0.170 (0.239)	Data 0.000 (0.082)	Loss 0.5562 (0.5413)	Prec@1 89.453 (90.234)	Prec@5 99.219 (99.503)
2025-05-20 11:50:36 - INFO - TRAINING - Epoch: [44][20/196]	Time 0.138 (0.199)	Data 0.000 (0.044)	Loss 0.4810 (0.5246)	Prec@1 92.969 (91.109)	Prec@5 99.609 (99.591)
2025-05-20 11:50:38 - INFO - TRAINING - Epoch: [44][30/196]	Time 0.135 (0.182)	Data 0.009 (0.032)	Loss 0.5124 (0.5264)	Prec@1 91.797 (91.016)	Prec@5 99.609 (99.572)
2025-05-20 11:50:39 - INFO - TRAINING - Epoch: [44][40/196]	Time 0.135 (0.171)	Data 0.000 (0.025)	Loss 0.5078 (0.5196)	Prec@1 91.016 (91.273)	Prec@5 99.609 (99.619)
2025-05-20 11:50:41 - INFO - TRAINING - Epoch: [44][50/196]	Time 0.133 (0.164)	Data 0.000 (0.021)	Loss 0.5147 (0.5191)	Prec@1 91.016 (91.207)	Prec@5 100.000 (99.648)
2025-05-20 11:50:42 - INFO - TRAINING - Epoch: [44][60/196]	Time 0.133 (0.159)	Data 0.000 (0.017)	Loss 0.5697 (0.5209)	Prec@1 89.062 (91.022)	Prec@5 98.828 (99.616)
2025-05-20 11:50:43 - INFO - TRAINING - Epoch: [44][70/196]	Time 0.134 (0.155)	Data 0.004 (0.016)	Loss 0.5342 (0.5214)	Prec@1 90.234 (90.950)	Prec@5 100.000 (99.631)
2025-05-20 11:50:45 - INFO - TRAINING - Epoch: [44][80/196]	Time 0.132 (0.153)	Data 0.000 (0.014)	Loss 0.5696 (0.5240)	Prec@1 89.844 (90.828)	Prec@5 98.438 (99.609)
2025-05-20 11:50:46 - INFO - TRAINING - Epoch: [44][90/196]	Time 0.134 (0.151)	Data 0.000 (0.013)	Loss 0.5431 (0.5242)	Prec@1 88.281 (90.840)	Prec@5 99.609 (99.614)
2025-05-20 11:50:47 - INFO - TRAINING - Epoch: [44][100/196]	Time 0.135 (0.149)	Data 0.001 (0.012)	Loss 0.5170 (0.5250)	Prec@1 91.406 (90.838)	Prec@5 99.609 (99.590)
2025-05-20 11:50:49 - INFO - TRAINING - Epoch: [44][110/196]	Time 0.141 (0.149)	Data 0.013 (0.011)	Loss 0.5087 (0.5245)	Prec@1 92.188 (90.843)	Prec@5 100.000 (99.592)
2025-05-20 11:50:50 - INFO - TRAINING - Epoch: [44][120/196]	Time 0.147 (0.148)	Data 0.007 (0.011)	Loss 0.5102 (0.5256)	Prec@1 91.016 (90.815)	Prec@5 99.609 (99.590)
2025-05-20 11:50:52 - INFO - TRAINING - Epoch: [44][130/196]	Time 0.135 (0.147)	Data 0.000 (0.010)	Loss 0.5130 (0.5253)	Prec@1 90.234 (90.816)	Prec@5 99.609 (99.591)
2025-05-20 11:50:53 - INFO - TRAINING - Epoch: [44][140/196]	Time 0.137 (0.146)	Data 0.000 (0.010)	Loss 0.5252 (0.5251)	Prec@1 92.188 (90.830)	Prec@5 100.000 (99.596)
2025-05-20 11:50:54 - INFO - TRAINING - Epoch: [44][150/196]	Time 0.123 (0.146)	Data 0.000 (0.009)	Loss 0.4799 (0.5235)	Prec@1 93.359 (90.871)	Prec@5 99.609 (99.602)
2025-05-20 11:50:56 - INFO - TRAINING - Epoch: [44][160/196]	Time 0.133 (0.145)	Data 0.000 (0.009)	Loss 0.5902 (0.5237)	Prec@1 87.109 (90.877)	Prec@5 100.000 (99.588)
2025-05-20 11:50:57 - INFO - TRAINING - Epoch: [44][170/196]	Time 0.135 (0.144)	Data 0.000 (0.008)	Loss 0.5054 (0.5241)	Prec@1 92.188 (90.849)	Prec@5 99.609 (99.587)
2025-05-20 11:50:58 - INFO - TRAINING - Epoch: [44][180/196]	Time 0.133 (0.144)	Data 0.000 (0.008)	Loss 0.5798 (0.5239)	Prec@1 88.672 (90.897)	Prec@5 99.609 (99.588)
2025-05-20 11:51:00 - INFO - TRAINING - Epoch: [44][190/196]	Time 0.132 (0.143)	Data 0.000 (0.007)	Loss 0.5329 (0.5241)	Prec@1 88.672 (90.864)	Prec@5 99.609 (99.583)
2025-05-20 11:51:02 - INFO - EVALUATING - Epoch: [44][0/40]	Time 1.307 (1.307)	Data 1.227 (1.227)	Loss 0.6590 (0.6590)	Prec@1 84.766 (84.766)	Prec@5 98.438 (98.438)
2025-05-20 11:51:03 - INFO - EVALUATING - Epoch: [44][10/40]	Time 0.078 (0.237)	Data 0.003 (0.157)	Loss 0.6169 (0.6360)	Prec@1 86.719 (86.186)	Prec@5 98.438 (98.544)
2025-05-20 11:51:04 - INFO - EVALUATING - Epoch: [44][20/40]	Time 0.096 (0.178)	Data 0.014 (0.098)	Loss 0.6411 (0.6499)	Prec@1 85.156 (85.733)	Prec@5 97.266 (98.065)
2025-05-20 11:51:05 - INFO - EVALUATING - Epoch: [44][30/40]	Time 0.083 (0.159)	Data 0.000 (0.077)	Loss 0.6832 (0.6530)	Prec@1 82.812 (85.585)	Prec@5 98.047 (98.311)
2025-05-20 11:51:06 - INFO - 
 Epoch: 45	Training Loss 0.5238 	Training Prec@1 90.874 	Training Prec@5 99.588 	Validation Loss 0.6495 	Validation Prec@1 85.750 	Validation Prec@5 98.370 

2025-05-20 11:51:06 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:51:06 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:51:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:51:06 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:51:07 - INFO - TRAINING - Epoch: [45][0/196]	Time 1.019 (1.019)	Data 0.910 (0.910)	Loss 0.5399 (0.5399)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
2025-05-20 11:51:09 - INFO - TRAINING - Epoch: [45][10/196]	Time 0.142 (0.225)	Data 0.006 (0.091)	Loss 0.5374 (0.5368)	Prec@1 88.281 (90.447)	Prec@5 99.609 (99.538)
2025-05-20 11:51:10 - INFO - TRAINING - Epoch: [45][20/196]	Time 0.133 (0.184)	Data 0.000 (0.049)	Loss 0.5563 (0.5304)	Prec@1 89.844 (90.625)	Prec@5 100.000 (99.572)
2025-05-20 11:51:12 - INFO - TRAINING - Epoch: [45][30/196]	Time 0.130 (0.168)	Data 0.000 (0.034)	Loss 0.5056 (0.5294)	Prec@1 91.016 (90.612)	Prec@5 99.219 (99.584)
2025-05-20 11:51:13 - INFO - TRAINING - Epoch: [45][40/196]	Time 0.133 (0.160)	Data 0.000 (0.027)	Loss 0.5108 (0.5263)	Prec@1 89.844 (90.673)	Prec@5 99.609 (99.619)
2025-05-20 11:51:14 - INFO - TRAINING - Epoch: [45][50/196]	Time 0.131 (0.155)	Data 0.000 (0.022)	Loss 0.4649 (0.5226)	Prec@1 92.969 (90.717)	Prec@5 100.000 (99.640)
2025-05-20 11:51:16 - INFO - TRAINING - Epoch: [45][60/196]	Time 0.136 (0.151)	Data 0.000 (0.019)	Loss 0.5699 (0.5207)	Prec@1 89.062 (90.888)	Prec@5 98.438 (99.616)
2025-05-20 11:51:17 - INFO - TRAINING - Epoch: [45][70/196]	Time 0.155 (0.150)	Data 0.000 (0.017)	Loss 0.5344 (0.5201)	Prec@1 90.625 (90.884)	Prec@5 99.219 (99.609)
2025-05-20 11:51:18 - INFO - TRAINING - Epoch: [45][80/196]	Time 0.151 (0.149)	Data 0.014 (0.016)	Loss 0.5674 (0.5211)	Prec@1 89.062 (90.910)	Prec@5 99.609 (99.609)
2025-05-20 11:51:20 - INFO - TRAINING - Epoch: [45][90/196]	Time 0.133 (0.148)	Data 0.000 (0.015)	Loss 0.5839 (0.5221)	Prec@1 87.500 (90.874)	Prec@5 99.609 (99.601)
2025-05-20 11:51:21 - INFO - TRAINING - Epoch: [45][100/196]	Time 0.138 (0.147)	Data 0.000 (0.014)	Loss 0.4922 (0.5224)	Prec@1 92.578 (90.900)	Prec@5 99.609 (99.606)
2025-05-20 11:51:23 - INFO - TRAINING - Epoch: [45][110/196]	Time 0.132 (0.146)	Data 0.000 (0.013)	Loss 0.5797 (0.5238)	Prec@1 87.891 (90.819)	Prec@5 98.828 (99.599)
2025-05-20 11:51:24 - INFO - TRAINING - Epoch: [45][120/196]	Time 0.135 (0.145)	Data 0.000 (0.012)	Loss 0.4822 (0.5226)	Prec@1 92.969 (90.896)	Prec@5 100.000 (99.606)
2025-05-20 11:51:25 - INFO - TRAINING - Epoch: [45][130/196]	Time 0.134 (0.144)	Data 0.007 (0.011)	Loss 0.5028 (0.5235)	Prec@1 91.797 (90.849)	Prec@5 99.609 (99.606)
2025-05-20 11:51:27 - INFO - TRAINING - Epoch: [45][140/196]	Time 0.133 (0.143)	Data 0.000 (0.011)	Loss 0.5497 (0.5241)	Prec@1 89.844 (90.824)	Prec@5 100.000 (99.620)
2025-05-20 11:51:28 - INFO - TRAINING - Epoch: [45][150/196]	Time 0.132 (0.143)	Data 0.000 (0.010)	Loss 0.4994 (0.5244)	Prec@1 92.578 (90.809)	Prec@5 99.609 (99.615)
2025-05-20 11:51:29 - INFO - TRAINING - Epoch: [45][160/196]	Time 0.140 (0.142)	Data 0.000 (0.010)	Loss 0.5351 (0.5237)	Prec@1 89.844 (90.848)	Prec@5 100.000 (99.631)
2025-05-20 11:51:31 - INFO - TRAINING - Epoch: [45][170/196]	Time 0.136 (0.142)	Data 0.000 (0.009)	Loss 0.5835 (0.5239)	Prec@1 89.062 (90.819)	Prec@5 99.219 (99.639)
2025-05-20 11:51:32 - INFO - TRAINING - Epoch: [45][180/196]	Time 0.130 (0.143)	Data 0.000 (0.009)	Loss 0.5085 (0.5239)	Prec@1 91.797 (90.817)	Prec@5 100.000 (99.648)
2025-05-20 11:51:33 - INFO - TRAINING - Epoch: [45][190/196]	Time 0.136 (0.142)	Data 0.000 (0.009)	Loss 0.5728 (0.5244)	Prec@1 87.109 (90.764)	Prec@5 99.219 (99.650)
2025-05-20 11:51:35 - INFO - EVALUATING - Epoch: [45][0/40]	Time 0.666 (0.666)	Data 0.592 (0.592)	Loss 0.6329 (0.6329)	Prec@1 86.328 (86.328)	Prec@5 99.219 (99.219)
2025-05-20 11:51:36 - INFO - EVALUATING - Epoch: [45][10/40]	Time 0.091 (0.144)	Data 0.003 (0.067)	Loss 0.5974 (0.6366)	Prec@1 86.328 (85.866)	Prec@5 98.438 (98.757)
2025-05-20 11:51:37 - INFO - EVALUATING - Epoch: [45][20/40]	Time 0.077 (0.118)	Data 0.001 (0.039)	Loss 0.6304 (0.6420)	Prec@1 86.719 (85.789)	Prec@5 97.656 (98.456)
2025-05-20 11:51:37 - INFO - EVALUATING - Epoch: [45][30/40]	Time 0.070 (0.104)	Data 0.000 (0.027)	Loss 0.6314 (0.6413)	Prec@1 84.375 (85.837)	Prec@5 98.438 (98.538)
2025-05-20 11:51:38 - INFO - 
 Epoch: 46	Training Loss 0.5245 	Training Prec@1 90.744 	Training Prec@5 99.654 	Validation Loss 0.6385 	Validation Prec@1 85.920 	Validation Prec@5 98.650 

2025-05-20 11:51:38 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:51:38 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:51:38 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:51:38 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:51:39 - INFO - TRAINING - Epoch: [46][0/196]	Time 1.120 (1.120)	Data 0.996 (0.996)	Loss 0.5386 (0.5386)	Prec@1 89.453 (89.453)	Prec@5 99.609 (99.609)
2025-05-20 11:51:41 - INFO - TRAINING - Epoch: [46][10/196]	Time 0.138 (0.231)	Data 0.014 (0.095)	Loss 0.5384 (0.5138)	Prec@1 90.234 (91.229)	Prec@5 99.609 (99.609)
2025-05-20 11:51:42 - INFO - TRAINING - Epoch: [46][20/196]	Time 0.142 (0.186)	Data 0.012 (0.053)	Loss 0.5319 (0.5153)	Prec@1 90.234 (91.127)	Prec@5 99.219 (99.591)
2025-05-20 11:51:44 - INFO - TRAINING - Epoch: [46][30/196]	Time 0.145 (0.172)	Data 0.014 (0.038)	Loss 0.5340 (0.5172)	Prec@1 90.234 (90.965)	Prec@5 98.828 (99.584)
2025-05-20 11:51:45 - INFO - TRAINING - Epoch: [46][40/196]	Time 0.148 (0.166)	Data 0.000 (0.031)	Loss 0.6143 (0.5225)	Prec@1 86.328 (90.758)	Prec@5 99.219 (99.581)
2025-05-20 11:51:46 - INFO - TRAINING - Epoch: [46][50/196]	Time 0.129 (0.160)	Data 0.011 (0.026)	Loss 0.5309 (0.5204)	Prec@1 90.234 (90.870)	Prec@5 99.609 (99.602)
2025-05-20 11:51:48 - INFO - TRAINING - Epoch: [46][60/196]	Time 0.133 (0.156)	Data 0.006 (0.022)	Loss 0.5211 (0.5177)	Prec@1 92.969 (91.028)	Prec@5 100.000 (99.603)
2025-05-20 11:51:49 - INFO - TRAINING - Epoch: [46][70/196]	Time 0.132 (0.153)	Data 0.000 (0.019)	Loss 0.4862 (0.5145)	Prec@1 91.406 (91.252)	Prec@5 99.609 (99.593)
2025-05-20 11:51:50 - INFO - TRAINING - Epoch: [46][80/196]	Time 0.134 (0.150)	Data 0.003 (0.017)	Loss 0.4650 (0.5153)	Prec@1 93.750 (91.184)	Prec@5 100.000 (99.609)
2025-05-20 11:51:52 - INFO - TRAINING - Epoch: [46][90/196]	Time 0.134 (0.149)	Data 0.000 (0.016)	Loss 0.4764 (0.5142)	Prec@1 92.578 (91.187)	Prec@5 100.000 (99.618)
2025-05-20 11:51:53 - INFO - TRAINING - Epoch: [46][100/196]	Time 0.133 (0.147)	Data 0.000 (0.014)	Loss 0.5635 (0.5151)	Prec@1 87.891 (91.112)	Prec@5 99.219 (99.621)
2025-05-20 11:51:54 - INFO - TRAINING - Epoch: [46][110/196]	Time 0.135 (0.146)	Data 0.009 (0.013)	Loss 0.5461 (0.5162)	Prec@1 90.625 (91.065)	Prec@5 99.609 (99.613)
2025-05-20 11:51:56 - INFO - TRAINING - Epoch: [46][120/196]	Time 0.125 (0.145)	Data 0.000 (0.012)	Loss 0.5628 (0.5160)	Prec@1 89.062 (91.100)	Prec@5 98.438 (99.600)
2025-05-20 11:51:57 - INFO - TRAINING - Epoch: [46][130/196]	Time 0.155 (0.145)	Data 0.013 (0.012)	Loss 0.4987 (0.5168)	Prec@1 92.188 (91.108)	Prec@5 99.609 (99.597)
2025-05-20 11:51:59 - INFO - TRAINING - Epoch: [46][140/196]	Time 0.137 (0.145)	Data 0.011 (0.012)	Loss 0.5497 (0.5179)	Prec@1 89.062 (91.063)	Prec@5 100.000 (99.615)
2025-05-20 11:52:00 - INFO - TRAINING - Epoch: [46][150/196]	Time 0.141 (0.145)	Data 0.007 (0.011)	Loss 0.5512 (0.5176)	Prec@1 91.797 (91.067)	Prec@5 99.219 (99.622)
2025-05-20 11:52:01 - INFO - TRAINING - Epoch: [46][160/196]	Time 0.133 (0.144)	Data 0.007 (0.011)	Loss 0.5249 (0.5186)	Prec@1 90.625 (91.011)	Prec@5 100.000 (99.622)
2025-05-20 11:52:03 - INFO - TRAINING - Epoch: [46][170/196]	Time 0.134 (0.143)	Data 0.000 (0.010)	Loss 0.5325 (0.5183)	Prec@1 89.453 (91.022)	Prec@5 99.609 (99.632)
2025-05-20 11:52:04 - INFO - TRAINING - Epoch: [46][180/196]	Time 0.134 (0.143)	Data 0.000 (0.010)	Loss 0.5348 (0.5190)	Prec@1 90.234 (91.007)	Prec@5 98.828 (99.620)
2025-05-20 11:52:05 - INFO - TRAINING - Epoch: [46][190/196]	Time 0.133 (0.142)	Data 0.000 (0.009)	Loss 0.5769 (0.5197)	Prec@1 88.281 (90.956)	Prec@5 100.000 (99.624)
2025-05-20 11:52:07 - INFO - EVALUATING - Epoch: [46][0/40]	Time 1.004 (1.004)	Data 0.930 (0.930)	Loss 0.6286 (0.6286)	Prec@1 86.328 (86.328)	Prec@5 98.438 (98.438)
2025-05-20 11:52:08 - INFO - EVALUATING - Epoch: [46][10/40]	Time 0.081 (0.163)	Data 0.000 (0.088)	Loss 0.5740 (0.6329)	Prec@1 90.234 (86.364)	Prec@5 98.828 (98.615)
2025-05-20 11:52:09 - INFO - EVALUATING - Epoch: [46][20/40]	Time 0.086 (0.124)	Data 0.000 (0.048)	Loss 0.5473 (0.6310)	Prec@1 89.453 (86.235)	Prec@5 99.219 (98.400)
2025-05-20 11:52:10 - INFO - EVALUATING - Epoch: [46][30/40]	Time 0.071 (0.110)	Data 0.000 (0.032)	Loss 0.7037 (0.6378)	Prec@1 83.984 (86.152)	Prec@5 98.047 (98.450)
2025-05-20 11:52:11 - INFO - 
 Epoch: 47	Training Loss 0.5203 	Training Prec@1 90.930 	Training Prec@5 99.618 	Validation Loss 0.6352 	Validation Prec@1 86.090 	Validation Prec@5 98.530 

2025-05-20 11:52:11 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:52:11 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:52:11 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:52:11 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:52:12 - INFO - TRAINING - Epoch: [47][0/196]	Time 1.246 (1.246)	Data 1.124 (1.124)	Loss 0.4493 (0.4493)	Prec@1 94.531 (94.531)	Prec@5 99.609 (99.609)
2025-05-20 11:52:13 - INFO - TRAINING - Epoch: [47][10/196]	Time 0.148 (0.248)	Data 0.005 (0.106)	Loss 0.5238 (0.4981)	Prec@1 91.016 (91.655)	Prec@5 99.609 (99.645)
2025-05-20 11:52:15 - INFO - TRAINING - Epoch: [47][20/196]	Time 0.132 (0.195)	Data 0.007 (0.058)	Loss 0.5194 (0.5052)	Prec@1 89.844 (91.369)	Prec@5 99.609 (99.554)
2025-05-20 11:52:16 - INFO - TRAINING - Epoch: [47][30/196]	Time 0.136 (0.176)	Data 0.000 (0.040)	Loss 0.4876 (0.5053)	Prec@1 94.531 (91.570)	Prec@5 100.000 (99.584)
2025-05-20 11:52:17 - INFO - TRAINING - Epoch: [47][40/196]	Time 0.135 (0.165)	Data 0.007 (0.032)	Loss 0.5024 (0.5057)	Prec@1 90.234 (91.454)	Prec@5 99.219 (99.609)
2025-05-20 11:52:19 - INFO - TRAINING - Epoch: [47][50/196]	Time 0.134 (0.159)	Data 0.000 (0.026)	Loss 0.5325 (0.5102)	Prec@1 90.234 (91.261)	Prec@5 100.000 (99.556)
2025-05-20 11:52:20 - INFO - TRAINING - Epoch: [47][60/196]	Time 0.134 (0.155)	Data 0.002 (0.022)	Loss 0.4821 (0.5139)	Prec@1 92.969 (91.131)	Prec@5 100.000 (99.577)
2025-05-20 11:52:21 - INFO - TRAINING - Epoch: [47][70/196]	Time 0.137 (0.152)	Data 0.000 (0.019)	Loss 0.4747 (0.5127)	Prec@1 92.578 (91.203)	Prec@5 99.609 (99.560)
2025-05-20 11:52:23 - INFO - TRAINING - Epoch: [47][80/196]	Time 0.145 (0.151)	Data 0.012 (0.017)	Loss 0.5167 (0.5154)	Prec@1 91.406 (91.030)	Prec@5 99.609 (99.571)
2025-05-20 11:52:24 - INFO - TRAINING - Epoch: [47][90/196]	Time 0.155 (0.150)	Data 0.015 (0.016)	Loss 0.4513 (0.5152)	Prec@1 94.531 (91.050)	Prec@5 100.000 (99.601)
2025-05-20 11:52:26 - INFO - TRAINING - Epoch: [47][100/196]	Time 0.134 (0.149)	Data 0.000 (0.015)	Loss 0.4887 (0.5177)	Prec@1 93.750 (90.931)	Prec@5 100.000 (99.609)
2025-05-20 11:52:27 - INFO - TRAINING - Epoch: [47][110/196]	Time 0.133 (0.148)	Data 0.007 (0.014)	Loss 0.5339 (0.5184)	Prec@1 89.453 (90.864)	Prec@5 100.000 (99.630)
2025-05-20 11:52:28 - INFO - TRAINING - Epoch: [47][120/196]	Time 0.133 (0.147)	Data 0.000 (0.013)	Loss 0.4891 (0.5174)	Prec@1 92.188 (90.883)	Prec@5 100.000 (99.648)
2025-05-20 11:52:30 - INFO - TRAINING - Epoch: [47][130/196]	Time 0.133 (0.146)	Data 0.000 (0.012)	Loss 0.5874 (0.5188)	Prec@1 87.500 (90.837)	Prec@5 99.609 (99.657)
2025-05-20 11:52:31 - INFO - TRAINING - Epoch: [47][140/196]	Time 0.134 (0.145)	Data 0.000 (0.011)	Loss 0.5779 (0.5197)	Prec@1 87.109 (90.791)	Prec@5 98.828 (99.654)
2025-05-20 11:52:32 - INFO - TRAINING - Epoch: [47][150/196]	Time 0.134 (0.144)	Data 0.000 (0.011)	Loss 0.5002 (0.5203)	Prec@1 89.453 (90.793)	Prec@5 100.000 (99.653)
2025-05-20 11:52:34 - INFO - TRAINING - Epoch: [47][160/196]	Time 0.133 (0.144)	Data 0.000 (0.010)	Loss 0.4946 (0.5205)	Prec@1 92.969 (90.773)	Prec@5 99.609 (99.641)
2025-05-20 11:52:35 - INFO - TRAINING - Epoch: [47][170/196]	Time 0.147 (0.143)	Data 0.000 (0.010)	Loss 0.5710 (0.5211)	Prec@1 87.109 (90.735)	Prec@5 99.609 (99.639)
2025-05-20 11:52:37 - INFO - TRAINING - Epoch: [47][180/196]	Time 0.146 (0.143)	Data 0.000 (0.010)	Loss 0.5087 (0.5211)	Prec@1 90.234 (90.731)	Prec@5 99.609 (99.633)
2025-05-20 11:52:38 - INFO - TRAINING - Epoch: [47][190/196]	Time 0.131 (0.143)	Data 0.000 (0.009)	Loss 0.5179 (0.5216)	Prec@1 92.188 (90.703)	Prec@5 99.609 (99.630)
2025-05-20 11:52:39 - INFO - EVALUATING - Epoch: [47][0/40]	Time 0.674 (0.674)	Data 0.605 (0.605)	Loss 0.6307 (0.6307)	Prec@1 85.938 (85.938)	Prec@5 98.828 (98.828)
2025-05-20 11:52:40 - INFO - EVALUATING - Epoch: [47][10/40]	Time 0.073 (0.138)	Data 0.004 (0.063)	Loss 0.6121 (0.6423)	Prec@1 86.328 (85.724)	Prec@5 98.828 (98.686)
2025-05-20 11:52:41 - INFO - EVALUATING - Epoch: [47][20/40]	Time 0.076 (0.109)	Data 0.005 (0.035)	Loss 0.6458 (0.6386)	Prec@1 86.328 (85.789)	Prec@5 99.219 (98.605)
2025-05-20 11:52:42 - INFO - EVALUATING - Epoch: [47][30/40]	Time 0.070 (0.098)	Data 0.000 (0.024)	Loss 0.6976 (0.6390)	Prec@1 81.250 (85.748)	Prec@5 98.047 (98.677)
2025-05-20 11:52:42 - INFO - 
 Epoch: 48	Training Loss 0.5216 	Training Prec@1 90.706 	Training Prec@5 99.632 	Validation Loss 0.6400 	Validation Prec@1 85.650 	Validation Prec@5 98.710 

2025-05-20 11:52:42 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:52:42 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:52:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:52:42 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:52:44 - INFO - TRAINING - Epoch: [48][0/196]	Time 1.085 (1.085)	Data 0.985 (0.985)	Loss 0.5361 (0.5361)	Prec@1 92.188 (92.188)	Prec@5 99.609 (99.609)
2025-05-20 11:52:45 - INFO - TRAINING - Epoch: [48][10/196]	Time 0.144 (0.231)	Data 0.008 (0.096)	Loss 0.5156 (0.5253)	Prec@1 91.016 (91.122)	Prec@5 100.000 (99.680)
2025-05-20 11:52:46 - INFO - TRAINING - Epoch: [48][20/196]	Time 0.133 (0.186)	Data 0.004 (0.053)	Loss 0.4833 (0.5235)	Prec@1 92.188 (91.053)	Prec@5 100.000 (99.721)
2025-05-20 11:52:48 - INFO - TRAINING - Epoch: [48][30/196]	Time 0.142 (0.169)	Data 0.000 (0.037)	Loss 0.5451 (0.5214)	Prec@1 89.062 (91.116)	Prec@5 99.219 (99.698)
2025-05-20 11:52:49 - INFO - TRAINING - Epoch: [48][40/196]	Time 0.143 (0.164)	Data 0.012 (0.029)	Loss 0.5156 (0.5228)	Prec@1 91.016 (91.006)	Prec@5 99.219 (99.676)
2025-05-20 11:52:51 - INFO - TRAINING - Epoch: [48][50/196]	Time 0.167 (0.161)	Data 0.000 (0.024)	Loss 0.5240 (0.5207)	Prec@1 92.578 (91.039)	Prec@5 98.828 (99.686)
2025-05-20 11:52:52 - INFO - TRAINING - Epoch: [48][60/196]	Time 0.137 (0.157)	Data 0.000 (0.021)	Loss 0.5034 (0.5200)	Prec@1 91.406 (91.067)	Prec@5 99.219 (99.673)
2025-05-20 11:52:53 - INFO - TRAINING - Epoch: [48][70/196]	Time 0.134 (0.154)	Data 0.011 (0.018)	Loss 0.4859 (0.5185)	Prec@1 92.188 (91.126)	Prec@5 99.609 (99.642)
2025-05-20 11:52:55 - INFO - TRAINING - Epoch: [48][80/196]	Time 0.133 (0.152)	Data 0.007 (0.016)	Loss 0.5496 (0.5199)	Prec@1 89.844 (91.035)	Prec@5 100.000 (99.667)
2025-05-20 11:52:56 - INFO - TRAINING - Epoch: [48][90/196]	Time 0.134 (0.150)	Data 0.000 (0.015)	Loss 0.4504 (0.5198)	Prec@1 95.312 (91.007)	Prec@5 100.000 (99.674)
2025-05-20 11:52:57 - INFO - TRAINING - Epoch: [48][100/196]	Time 0.137 (0.148)	Data 0.000 (0.014)	Loss 0.5350 (0.5206)	Prec@1 89.062 (90.903)	Prec@5 100.000 (99.671)
2025-05-20 11:52:59 - INFO - TRAINING - Epoch: [48][110/196]	Time 0.135 (0.147)	Data 0.000 (0.013)	Loss 0.5676 (0.5201)	Prec@1 89.062 (90.931)	Prec@5 99.609 (99.666)
2025-05-20 11:53:00 - INFO - TRAINING - Epoch: [48][120/196]	Time 0.132 (0.146)	Data 0.000 (0.012)	Loss 0.5596 (0.5213)	Prec@1 89.062 (90.922)	Prec@5 99.219 (99.648)
2025-05-20 11:53:01 - INFO - TRAINING - Epoch: [48][130/196]	Time 0.146 (0.145)	Data 0.002 (0.011)	Loss 0.5422 (0.5201)	Prec@1 90.625 (90.965)	Prec@5 99.609 (99.654)
2025-05-20 11:53:03 - INFO - TRAINING - Epoch: [48][140/196]	Time 0.135 (0.145)	Data 0.012 (0.011)	Loss 0.4622 (0.5194)	Prec@1 93.750 (90.993)	Prec@5 99.609 (99.656)
2025-05-20 11:53:04 - INFO - TRAINING - Epoch: [48][150/196]	Time 0.142 (0.145)	Data 0.005 (0.011)	Loss 0.5080 (0.5185)	Prec@1 92.578 (91.008)	Prec@5 99.219 (99.651)
2025-05-20 11:53:06 - INFO - TRAINING - Epoch: [48][160/196]	Time 0.133 (0.144)	Data 0.000 (0.010)	Loss 0.5279 (0.5186)	Prec@1 91.797 (91.016)	Prec@5 99.219 (99.638)
2025-05-20 11:53:07 - INFO - TRAINING - Epoch: [48][170/196]	Time 0.135 (0.144)	Data 0.002 (0.010)	Loss 0.4945 (0.5180)	Prec@1 91.797 (91.075)	Prec@5 100.000 (99.630)
2025-05-20 11:53:08 - INFO - TRAINING - Epoch: [48][180/196]	Time 0.132 (0.143)	Data 0.000 (0.010)	Loss 0.5321 (0.5186)	Prec@1 91.016 (91.061)	Prec@5 99.609 (99.627)
2025-05-20 11:53:10 - INFO - TRAINING - Epoch: [48][190/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.5385 (0.5184)	Prec@1 89.062 (91.069)	Prec@5 99.609 (99.624)
2025-05-20 11:53:11 - INFO - EVALUATING - Epoch: [48][0/40]	Time 0.776 (0.776)	Data 0.685 (0.685)	Loss 0.6125 (0.6125)	Prec@1 87.500 (87.500)	Prec@5 98.047 (98.047)
2025-05-20 11:53:12 - INFO - EVALUATING - Epoch: [48][10/40]	Time 0.085 (0.143)	Data 0.012 (0.067)	Loss 0.6010 (0.6304)	Prec@1 87.891 (85.831)	Prec@5 98.438 (98.509)
2025-05-20 11:53:13 - INFO - EVALUATING - Epoch: [48][20/40]	Time 0.071 (0.111)	Data 0.000 (0.036)	Loss 0.5952 (0.6322)	Prec@1 86.719 (86.217)	Prec@5 98.047 (98.438)
2025-05-20 11:53:13 - INFO - EVALUATING - Epoch: [48][30/40]	Time 0.069 (0.099)	Data 0.000 (0.025)	Loss 0.6887 (0.6362)	Prec@1 82.422 (85.849)	Prec@5 98.438 (98.576)
2025-05-20 11:53:14 - INFO - 
 Epoch: 49	Training Loss 0.5180 	Training Prec@1 91.078 	Training Prec@5 99.628 	Validation Loss 0.6314 	Validation Prec@1 85.940 	Validation Prec@5 98.580 

2025-05-20 11:53:14 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:53:14 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:53:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:53:14 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:53:16 - INFO - TRAINING - Epoch: [49][0/196]	Time 1.685 (1.685)	Data 1.516 (1.516)	Loss 0.4978 (0.4978)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2025-05-20 11:53:18 - INFO - TRAINING - Epoch: [49][10/196]	Time 0.153 (0.290)	Data 0.009 (0.143)	Loss 0.5572 (0.5200)	Prec@1 89.062 (90.838)	Prec@5 99.609 (99.893)
2025-05-20 11:53:19 - INFO - TRAINING - Epoch: [49][20/196]	Time 0.133 (0.218)	Data 0.000 (0.077)	Loss 0.5224 (0.5152)	Prec@1 91.797 (91.034)	Prec@5 98.438 (99.795)
2025-05-20 11:53:20 - INFO - TRAINING - Epoch: [49][30/196]	Time 0.134 (0.191)	Data 0.007 (0.054)	Loss 0.5018 (0.5177)	Prec@1 92.969 (91.028)	Prec@5 99.219 (99.786)
2025-05-20 11:53:22 - INFO - TRAINING - Epoch: [49][40/196]	Time 0.135 (0.177)	Data 0.000 (0.041)	Loss 0.5496 (0.5170)	Prec@1 88.281 (91.025)	Prec@5 100.000 (99.809)
2025-05-20 11:53:23 - INFO - TRAINING - Epoch: [49][50/196]	Time 0.131 (0.168)	Data 0.014 (0.034)	Loss 0.4930 (0.5187)	Prec@1 93.750 (90.954)	Prec@5 100.000 (99.770)
2025-05-20 11:53:24 - INFO - TRAINING - Epoch: [49][60/196]	Time 0.133 (0.163)	Data 0.000 (0.028)	Loss 0.4984 (0.5182)	Prec@1 91.016 (91.028)	Prec@5 99.609 (99.750)
2025-05-20 11:53:26 - INFO - TRAINING - Epoch: [49][70/196]	Time 0.134 (0.159)	Data 0.000 (0.025)	Loss 0.5147 (0.5177)	Prec@1 90.625 (91.076)	Prec@5 99.609 (99.730)
2025-05-20 11:53:27 - INFO - TRAINING - Epoch: [49][80/196]	Time 0.127 (0.156)	Data 0.008 (0.022)	Loss 0.4826 (0.5142)	Prec@1 91.797 (91.141)	Prec@5 100.000 (99.725)
2025-05-20 11:53:28 - INFO - TRAINING - Epoch: [49][90/196]	Time 0.150 (0.154)	Data 0.011 (0.021)	Loss 0.4673 (0.5152)	Prec@1 92.969 (91.093)	Prec@5 99.609 (99.704)
2025-05-20 11:53:30 - INFO - TRAINING - Epoch: [49][100/196]	Time 0.151 (0.154)	Data 0.008 (0.019)	Loss 0.4841 (0.5156)	Prec@1 93.750 (91.019)	Prec@5 98.828 (99.694)
2025-05-20 11:53:31 - INFO - TRAINING - Epoch: [49][110/196]	Time 0.134 (0.152)	Data 0.008 (0.018)	Loss 0.5217 (0.5156)	Prec@1 91.406 (91.009)	Prec@5 99.609 (99.701)
2025-05-20 11:53:33 - INFO - TRAINING - Epoch: [49][120/196]	Time 0.134 (0.150)	Data 0.007 (0.017)	Loss 0.5406 (0.5150)	Prec@1 91.797 (91.080)	Prec@5 99.609 (99.680)
2025-05-20 11:53:34 - INFO - TRAINING - Epoch: [49][130/196]	Time 0.135 (0.149)	Data 0.003 (0.016)	Loss 0.5262 (0.5161)	Prec@1 90.625 (91.028)	Prec@5 99.609 (99.681)
2025-05-20 11:53:35 - INFO - TRAINING - Epoch: [49][140/196]	Time 0.133 (0.148)	Data 0.005 (0.015)	Loss 0.5026 (0.5158)	Prec@1 90.625 (91.032)	Prec@5 100.000 (99.684)
2025-05-20 11:53:37 - INFO - TRAINING - Epoch: [49][150/196]	Time 0.134 (0.147)	Data 0.003 (0.014)	Loss 0.5235 (0.5151)	Prec@1 91.016 (91.075)	Prec@5 99.219 (99.692)
2025-05-20 11:53:38 - INFO - TRAINING - Epoch: [49][160/196]	Time 0.134 (0.146)	Data 0.010 (0.013)	Loss 0.5098 (0.5142)	Prec@1 91.016 (91.118)	Prec@5 99.609 (99.692)
2025-05-20 11:53:39 - INFO - TRAINING - Epoch: [49][170/196]	Time 0.139 (0.146)	Data 0.001 (0.013)	Loss 0.4894 (0.5149)	Prec@1 92.188 (91.082)	Prec@5 100.000 (99.694)
2025-05-20 11:53:41 - INFO - TRAINING - Epoch: [49][180/196]	Time 0.143 (0.145)	Data 0.000 (0.012)	Loss 0.5469 (0.5159)	Prec@1 89.844 (91.037)	Prec@5 99.609 (99.694)
2025-05-20 11:53:42 - INFO - TRAINING - Epoch: [49][190/196]	Time 0.135 (0.145)	Data 0.000 (0.012)	Loss 0.4919 (0.5157)	Prec@1 92.969 (91.057)	Prec@5 99.609 (99.693)
2025-05-20 11:53:44 - INFO - EVALUATING - Epoch: [49][0/40]	Time 0.843 (0.843)	Data 0.766 (0.766)	Loss 0.6163 (0.6163)	Prec@1 87.891 (87.891)	Prec@5 97.656 (97.656)
2025-05-20 11:53:44 - INFO - EVALUATING - Epoch: [49][10/40]	Time 0.073 (0.148)	Data 0.000 (0.073)	Loss 0.6266 (0.6336)	Prec@1 83.984 (85.902)	Prec@5 98.828 (98.651)
2025-05-20 11:53:45 - INFO - EVALUATING - Epoch: [49][20/40]	Time 0.078 (0.114)	Data 0.001 (0.039)	Loss 0.5679 (0.6309)	Prec@1 88.672 (86.049)	Prec@5 98.438 (98.493)
2025-05-20 11:53:46 - INFO - EVALUATING - Epoch: [49][30/40]	Time 0.069 (0.101)	Data 0.000 (0.027)	Loss 0.6738 (0.6340)	Prec@1 82.812 (85.698)	Prec@5 99.219 (98.715)
2025-05-20 11:53:47 - INFO - 
 Epoch: 50	Training Loss 0.5162 	Training Prec@1 91.046 	Training Prec@5 99.696 	Validation Loss 0.6332 	Validation Prec@1 85.750 	Validation Prec@5 98.790 

2025-05-20 11:53:47 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:53:47 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:53:47 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:53:47 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:53:48 - INFO - TRAINING - Epoch: [50][0/196]	Time 1.014 (1.014)	Data 0.908 (0.908)	Loss 0.5005 (0.5005)	Prec@1 91.797 (91.797)	Prec@5 99.609 (99.609)
2025-05-20 11:53:49 - INFO - TRAINING - Epoch: [50][10/196]	Time 0.141 (0.221)	Data 0.001 (0.088)	Loss 0.4944 (0.5047)	Prec@1 92.578 (91.832)	Prec@5 99.219 (99.716)
2025-05-20 11:53:50 - INFO - TRAINING - Epoch: [50][20/196]	Time 0.134 (0.181)	Data 0.002 (0.049)	Loss 0.5385 (0.5077)	Prec@1 89.453 (91.685)	Prec@5 99.609 (99.665)
2025-05-20 11:53:52 - INFO - TRAINING - Epoch: [50][30/196]	Time 0.134 (0.166)	Data 0.000 (0.034)	Loss 0.5204 (0.5062)	Prec@1 91.016 (91.683)	Prec@5 100.000 (99.723)
2025-05-20 11:53:53 - INFO - TRAINING - Epoch: [50][40/196]	Time 0.129 (0.159)	Data 0.000 (0.026)	Loss 0.4993 (0.5080)	Prec@1 91.406 (91.502)	Prec@5 100.000 (99.705)
2025-05-20 11:53:55 - INFO - TRAINING - Epoch: [50][50/196]	Time 0.142 (0.156)	Data 0.024 (0.022)	Loss 0.5186 (0.5084)	Prec@1 91.016 (91.506)	Prec@5 99.609 (99.701)
2025-05-20 11:53:56 - INFO - TRAINING - Epoch: [50][60/196]	Time 0.150 (0.154)	Data 0.009 (0.020)	Loss 0.4516 (0.5058)	Prec@1 95.312 (91.637)	Prec@5 99.609 (99.705)
2025-05-20 11:53:57 - INFO - TRAINING - Epoch: [50][70/196]	Time 0.134 (0.151)	Data 0.000 (0.018)	Loss 0.4854 (0.5049)	Prec@1 91.797 (91.643)	Prec@5 99.219 (99.697)
2025-05-20 11:53:59 - INFO - TRAINING - Epoch: [50][80/196]	Time 0.134 (0.149)	Data 0.001 (0.016)	Loss 0.4630 (0.5066)	Prec@1 94.141 (91.614)	Prec@5 100.000 (99.706)
2025-05-20 11:54:00 - INFO - TRAINING - Epoch: [50][90/196]	Time 0.131 (0.147)	Data 0.000 (0.014)	Loss 0.4811 (0.5064)	Prec@1 93.750 (91.574)	Prec@5 100.000 (99.721)
2025-05-20 11:54:01 - INFO - TRAINING - Epoch: [50][100/196]	Time 0.133 (0.146)	Data 0.000 (0.013)	Loss 0.4730 (0.5052)	Prec@1 92.969 (91.646)	Prec@5 99.609 (99.714)
2025-05-20 11:54:03 - INFO - TRAINING - Epoch: [50][110/196]	Time 0.133 (0.145)	Data 0.000 (0.012)	Loss 0.5674 (0.5052)	Prec@1 89.062 (91.621)	Prec@5 98.828 (99.718)
2025-05-20 11:54:04 - INFO - TRAINING - Epoch: [50][120/196]	Time 0.134 (0.144)	Data 0.000 (0.012)	Loss 0.5229 (0.5044)	Prec@1 91.406 (91.626)	Prec@5 98.828 (99.693)
2025-05-20 11:54:05 - INFO - TRAINING - Epoch: [50][130/196]	Time 0.134 (0.143)	Data 0.000 (0.011)	Loss 0.5232 (0.5047)	Prec@1 90.625 (91.588)	Prec@5 100.000 (99.705)
2025-05-20 11:54:07 - INFO - TRAINING - Epoch: [50][140/196]	Time 0.144 (0.143)	Data 0.017 (0.011)	Loss 0.4934 (0.5038)	Prec@1 94.531 (91.664)	Prec@5 100.000 (99.712)
2025-05-20 11:54:08 - INFO - TRAINING - Epoch: [50][150/196]	Time 0.149 (0.144)	Data 0.008 (0.011)	Loss 0.4881 (0.5058)	Prec@1 91.797 (91.587)	Prec@5 99.609 (99.703)
2025-05-20 11:54:10 - INFO - TRAINING - Epoch: [50][160/196]	Time 0.133 (0.143)	Data 0.000 (0.010)	Loss 0.5423 (0.5058)	Prec@1 87.891 (91.574)	Prec@5 99.609 (99.706)
2025-05-20 11:54:11 - INFO - TRAINING - Epoch: [50][170/196]	Time 0.143 (0.143)	Data 0.000 (0.010)	Loss 0.4901 (0.5068)	Prec@1 94.141 (91.523)	Prec@5 100.000 (99.689)
2025-05-20 11:54:12 - INFO - TRAINING - Epoch: [50][180/196]	Time 0.132 (0.142)	Data 0.000 (0.009)	Loss 0.5223 (0.5075)	Prec@1 91.016 (91.506)	Prec@5 99.609 (99.691)
2025-05-20 11:54:14 - INFO - TRAINING - Epoch: [50][190/196]	Time 0.132 (0.142)	Data 0.000 (0.009)	Loss 0.5791 (0.5085)	Prec@1 88.281 (91.443)	Prec@5 98.828 (99.683)
2025-05-20 11:54:15 - INFO - EVALUATING - Epoch: [50][0/40]	Time 0.753 (0.753)	Data 0.677 (0.677)	Loss 0.6169 (0.6169)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
2025-05-20 11:54:16 - INFO - EVALUATING - Epoch: [50][10/40]	Time 0.076 (0.140)	Data 0.000 (0.064)	Loss 0.6085 (0.6316)	Prec@1 86.328 (85.973)	Prec@5 98.828 (98.651)
2025-05-20 11:54:17 - INFO - EVALUATING - Epoch: [50][20/40]	Time 0.072 (0.111)	Data 0.002 (0.035)	Loss 0.6005 (0.6425)	Prec@1 87.500 (85.342)	Prec@5 98.828 (98.549)
2025-05-20 11:54:18 - INFO - EVALUATING - Epoch: [50][30/40]	Time 0.069 (0.099)	Data 0.000 (0.024)	Loss 0.6547 (0.6456)	Prec@1 82.422 (85.307)	Prec@5 98.828 (98.727)
2025-05-20 11:54:18 - INFO - 
 Epoch: 51	Training Loss 0.5086 	Training Prec@1 91.428 	Training Prec@5 99.680 	Validation Loss 0.6442 	Validation Prec@1 85.300 	Validation Prec@5 98.730 

2025-05-20 11:54:18 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:54:18 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:54:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:54:18 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:54:20 - INFO - TRAINING - Epoch: [51][0/196]	Time 1.168 (1.168)	Data 1.001 (1.001)	Loss 0.4649 (0.4649)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2025-05-20 11:54:21 - INFO - TRAINING - Epoch: [51][10/196]	Time 0.143 (0.257)	Data 0.000 (0.111)	Loss 0.4900 (0.5100)	Prec@1 93.750 (91.903)	Prec@5 100.000 (99.645)
2025-05-20 11:54:23 - INFO - TRAINING - Epoch: [51][20/196]	Time 0.144 (0.207)	Data 0.005 (0.060)	Loss 0.4917 (0.5054)	Prec@1 92.578 (91.871)	Prec@5 99.609 (99.665)
2025-05-20 11:54:24 - INFO - TRAINING - Epoch: [51][30/196]	Time 0.134 (0.185)	Data 0.007 (0.043)	Loss 0.5443 (0.5096)	Prec@1 89.062 (91.494)	Prec@5 100.000 (99.647)
2025-05-20 11:54:25 - INFO - TRAINING - Epoch: [51][40/196]	Time 0.137 (0.173)	Data 0.007 (0.034)	Loss 0.5299 (0.5095)	Prec@1 89.844 (91.406)	Prec@5 100.000 (99.657)
2025-05-20 11:54:27 - INFO - TRAINING - Epoch: [51][50/196]	Time 0.133 (0.165)	Data 0.000 (0.027)	Loss 0.5197 (0.5134)	Prec@1 91.406 (91.276)	Prec@5 100.000 (99.655)
2025-05-20 11:54:28 - INFO - TRAINING - Epoch: [51][60/196]	Time 0.134 (0.160)	Data 0.000 (0.023)	Loss 0.5101 (0.5140)	Prec@1 91.406 (91.259)	Prec@5 99.609 (99.635)
2025-05-20 11:54:29 - INFO - TRAINING - Epoch: [51][70/196]	Time 0.131 (0.156)	Data 0.000 (0.020)	Loss 0.5145 (0.5130)	Prec@1 90.234 (91.324)	Prec@5 100.000 (99.648)
2025-05-20 11:54:31 - INFO - TRAINING - Epoch: [51][80/196]	Time 0.134 (0.154)	Data 0.000 (0.018)	Loss 0.5708 (0.5131)	Prec@1 87.891 (91.252)	Prec@5 99.219 (99.662)
2025-05-20 11:54:32 - INFO - TRAINING - Epoch: [51][90/196]	Time 0.142 (0.151)	Data 0.000 (0.016)	Loss 0.4941 (0.5134)	Prec@1 91.797 (91.204)	Prec@5 99.609 (99.665)
2025-05-20 11:54:34 - INFO - TRAINING - Epoch: [51][100/196]	Time 0.148 (0.150)	Data 0.017 (0.016)	Loss 0.5295 (0.5132)	Prec@1 91.016 (91.217)	Prec@5 100.000 (99.660)
2025-05-20 11:54:35 - INFO - TRAINING - Epoch: [51][110/196]	Time 0.156 (0.150)	Data 0.013 (0.015)	Loss 0.4857 (0.5123)	Prec@1 94.531 (91.290)	Prec@5 99.609 (99.673)
2025-05-20 11:54:36 - INFO - TRAINING - Epoch: [51][120/196]	Time 0.134 (0.149)	Data 0.000 (0.014)	Loss 0.4937 (0.5107)	Prec@1 92.969 (91.374)	Prec@5 99.609 (99.687)
2025-05-20 11:54:38 - INFO - TRAINING - Epoch: [51][130/196]	Time 0.134 (0.148)	Data 0.000 (0.013)	Loss 0.4477 (0.5111)	Prec@1 93.750 (91.341)	Prec@5 100.000 (99.684)
2025-05-20 11:54:39 - INFO - TRAINING - Epoch: [51][140/196]	Time 0.131 (0.147)	Data 0.009 (0.013)	Loss 0.5501 (0.5119)	Prec@1 89.844 (91.279)	Prec@5 99.219 (99.684)
2025-05-20 11:54:40 - INFO - TRAINING - Epoch: [51][150/196]	Time 0.133 (0.146)	Data 0.000 (0.012)	Loss 0.4887 (0.5118)	Prec@1 93.359 (91.311)	Prec@5 98.828 (99.674)
2025-05-20 11:54:42 - INFO - TRAINING - Epoch: [51][160/196]	Time 0.134 (0.145)	Data 0.000 (0.011)	Loss 0.5097 (0.5123)	Prec@1 89.844 (91.278)	Prec@5 99.609 (99.677)
2025-05-20 11:54:43 - INFO - TRAINING - Epoch: [51][170/196]	Time 0.133 (0.145)	Data 0.004 (0.011)	Loss 0.4634 (0.5117)	Prec@1 93.359 (91.315)	Prec@5 100.000 (99.682)
2025-05-20 11:54:44 - INFO - TRAINING - Epoch: [51][180/196]	Time 0.136 (0.144)	Data 0.000 (0.010)	Loss 0.5211 (0.5126)	Prec@1 91.406 (91.303)	Prec@5 100.000 (99.681)
2025-05-20 11:54:46 - INFO - TRAINING - Epoch: [51][190/196]	Time 0.133 (0.144)	Data 0.000 (0.010)	Loss 0.4646 (0.5119)	Prec@1 92.578 (91.312)	Prec@5 99.609 (99.679)
2025-05-20 11:54:48 - INFO - EVALUATING - Epoch: [51][0/40]	Time 1.171 (1.171)	Data 1.101 (1.101)	Loss 0.5851 (0.5851)	Prec@1 88.281 (88.281)	Prec@5 98.828 (98.828)
2025-05-20 11:54:49 - INFO - EVALUATING - Epoch: [51][10/40]	Time 0.078 (0.176)	Data 0.000 (0.103)	Loss 0.6589 (0.6273)	Prec@1 85.547 (86.328)	Prec@5 98.047 (98.580)
2025-05-20 11:54:49 - INFO - EVALUATING - Epoch: [51][20/40]	Time 0.071 (0.128)	Data 0.000 (0.055)	Loss 0.6050 (0.6315)	Prec@1 88.672 (86.179)	Prec@5 99.609 (98.531)
2025-05-20 11:54:50 - INFO - EVALUATING - Epoch: [51][30/40]	Time 0.069 (0.110)	Data 0.000 (0.038)	Loss 0.6593 (0.6377)	Prec@1 83.984 (85.774)	Prec@5 99.219 (98.614)
2025-05-20 11:54:51 - INFO - 
 Epoch: 52	Training Loss 0.5125 	Training Prec@1 91.282 	Training Prec@5 99.678 	Validation Loss 0.6371 	Validation Prec@1 85.720 	Validation Prec@5 98.660 

2025-05-20 11:54:51 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:54:51 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:54:51 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:54:51 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:54:52 - INFO - TRAINING - Epoch: [52][0/196]	Time 0.799 (0.799)	Data 0.689 (0.689)	Loss 0.5090 (0.5090)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2025-05-20 11:54:53 - INFO - TRAINING - Epoch: [52][10/196]	Time 0.148 (0.220)	Data 0.004 (0.089)	Loss 0.5115 (0.5151)	Prec@1 92.188 (91.229)	Prec@5 99.219 (99.716)
2025-05-20 11:54:55 - INFO - TRAINING - Epoch: [52][20/196]	Time 0.133 (0.180)	Data 0.000 (0.048)	Loss 0.4657 (0.5137)	Prec@1 94.141 (91.090)	Prec@5 100.000 (99.740)
2025-05-20 11:54:56 - INFO - TRAINING - Epoch: [52][30/196]	Time 0.137 (0.165)	Data 0.000 (0.033)	Loss 0.5439 (0.5197)	Prec@1 89.844 (90.927)	Prec@5 100.000 (99.698)
2025-05-20 11:54:57 - INFO - TRAINING - Epoch: [52][40/196]	Time 0.134 (0.158)	Data 0.004 (0.025)	Loss 0.5347 (0.5184)	Prec@1 90.625 (90.939)	Prec@5 98.828 (99.676)
2025-05-20 11:54:59 - INFO - TRAINING - Epoch: [52][50/196]	Time 0.120 (0.154)	Data 0.000 (0.021)	Loss 0.5246 (0.5191)	Prec@1 91.406 (90.924)	Prec@5 99.609 (99.686)
2025-05-20 11:55:00 - INFO - TRAINING - Epoch: [52][60/196]	Time 0.150 (0.153)	Data 0.020 (0.018)	Loss 0.5474 (0.5203)	Prec@1 90.625 (90.926)	Prec@5 100.000 (99.712)
2025-05-20 11:55:02 - INFO - TRAINING - Epoch: [52][70/196]	Time 0.141 (0.152)	Data 0.000 (0.017)	Loss 0.4734 (0.5187)	Prec@1 92.578 (90.977)	Prec@5 100.000 (99.719)
2025-05-20 11:55:03 - INFO - TRAINING - Epoch: [52][80/196]	Time 0.133 (0.149)	Data 0.000 (0.015)	Loss 0.5547 (0.5180)	Prec@1 90.625 (91.020)	Prec@5 99.609 (99.711)
2025-05-20 11:55:04 - INFO - TRAINING - Epoch: [52][90/196]	Time 0.134 (0.148)	Data 0.000 (0.013)	Loss 0.4923 (0.5160)	Prec@1 92.188 (91.110)	Prec@5 99.609 (99.695)
2025-05-20 11:55:06 - INFO - TRAINING - Epoch: [52][100/196]	Time 0.133 (0.146)	Data 0.000 (0.012)	Loss 0.5704 (0.5149)	Prec@1 87.891 (91.101)	Prec@5 100.000 (99.706)
2025-05-20 11:55:07 - INFO - TRAINING - Epoch: [52][110/196]	Time 0.134 (0.145)	Data 0.000 (0.011)	Loss 0.5130 (0.5144)	Prec@1 91.797 (91.160)	Prec@5 100.000 (99.701)
2025-05-20 11:55:08 - INFO - TRAINING - Epoch: [52][120/196]	Time 0.137 (0.144)	Data 0.000 (0.010)	Loss 0.4868 (0.5127)	Prec@1 90.625 (91.203)	Prec@5 100.000 (99.713)
2025-05-20 11:55:10 - INFO - TRAINING - Epoch: [52][130/196]	Time 0.130 (0.143)	Data 0.001 (0.010)	Loss 0.4610 (0.5103)	Prec@1 92.188 (91.308)	Prec@5 100.000 (99.729)
2025-05-20 11:55:11 - INFO - TRAINING - Epoch: [52][140/196]	Time 0.143 (0.143)	Data 0.000 (0.009)	Loss 0.5498 (0.5092)	Prec@1 89.453 (91.362)	Prec@5 99.609 (99.723)
2025-05-20 11:55:12 - INFO - TRAINING - Epoch: [52][150/196]	Time 0.147 (0.143)	Data 0.014 (0.009)	Loss 0.5157 (0.5096)	Prec@1 91.016 (91.336)	Prec@5 99.609 (99.723)
2025-05-20 11:55:14 - INFO - TRAINING - Epoch: [52][160/196]	Time 0.152 (0.143)	Data 0.015 (0.009)	Loss 0.5326 (0.5084)	Prec@1 91.406 (91.418)	Prec@5 99.609 (99.728)
2025-05-20 11:55:15 - INFO - TRAINING - Epoch: [52][170/196]	Time 0.132 (0.143)	Data 0.000 (0.009)	Loss 0.4802 (0.5083)	Prec@1 93.359 (91.413)	Prec@5 100.000 (99.733)
2025-05-20 11:55:17 - INFO - TRAINING - Epoch: [52][180/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.4975 (0.5079)	Prec@1 92.188 (91.447)	Prec@5 99.609 (99.728)
2025-05-20 11:55:18 - INFO - TRAINING - Epoch: [52][190/196]	Time 0.134 (0.142)	Data 0.000 (0.009)	Loss 0.4891 (0.5074)	Prec@1 91.797 (91.466)	Prec@5 100.000 (99.730)
2025-05-20 11:55:19 - INFO - EVALUATING - Epoch: [52][0/40]	Time 0.681 (0.681)	Data 0.609 (0.609)	Loss 0.6326 (0.6326)	Prec@1 85.938 (85.938)	Prec@5 99.609 (99.609)
2025-05-20 11:55:20 - INFO - EVALUATING - Epoch: [52][10/40]	Time 0.068 (0.139)	Data 0.000 (0.065)	Loss 0.5726 (0.6304)	Prec@1 88.281 (86.186)	Prec@5 99.609 (98.757)
2025-05-20 11:55:21 - INFO - EVALUATING - Epoch: [52][20/40]	Time 0.069 (0.109)	Data 0.000 (0.035)	Loss 0.6458 (0.6405)	Prec@1 84.375 (85.677)	Prec@5 98.828 (98.419)
2025-05-20 11:55:22 - INFO - EVALUATING - Epoch: [52][30/40]	Time 0.070 (0.098)	Data 0.000 (0.024)	Loss 0.6858 (0.6403)	Prec@1 82.422 (85.547)	Prec@5 98.047 (98.551)
2025-05-20 11:55:22 - INFO - 
 Epoch: 53	Training Loss 0.5081 	Training Prec@1 91.434 	Training Prec@5 99.722 	Validation Loss 0.6383 	Validation Prec@1 85.660 	Validation Prec@5 98.620 

2025-05-20 11:55:22 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:55:22 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:55:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:55:22 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:55:23 - INFO - TRAINING - Epoch: [53][0/196]	Time 1.033 (1.033)	Data 0.928 (0.928)	Loss 0.4700 (0.4700)	Prec@1 92.188 (92.188)	Prec@5 99.609 (99.609)
2025-05-20 11:55:25 - INFO - TRAINING - Epoch: [53][10/196]	Time 0.135 (0.226)	Data 0.007 (0.090)	Loss 0.5807 (0.5198)	Prec@1 87.500 (90.874)	Prec@5 99.219 (99.574)
2025-05-20 11:55:26 - INFO - TRAINING - Epoch: [53][20/196]	Time 0.143 (0.190)	Data 0.006 (0.049)	Loss 0.5353 (0.5152)	Prec@1 90.625 (91.239)	Prec@5 99.219 (99.535)
2025-05-20 11:55:28 - INFO - TRAINING - Epoch: [53][30/196]	Time 0.161 (0.180)	Data 0.014 (0.036)	Loss 0.5368 (0.5099)	Prec@1 88.281 (91.356)	Prec@5 99.609 (99.559)
2025-05-20 11:55:29 - INFO - TRAINING - Epoch: [53][40/196]	Time 0.135 (0.169)	Data 0.000 (0.028)	Loss 0.4643 (0.5119)	Prec@1 93.359 (91.359)	Prec@5 99.609 (99.581)
2025-05-20 11:55:31 - INFO - TRAINING - Epoch: [53][50/196]	Time 0.136 (0.162)	Data 0.007 (0.023)	Loss 0.4890 (0.5095)	Prec@1 91.016 (91.399)	Prec@5 100.000 (99.625)
2025-05-20 11:55:32 - INFO - TRAINING - Epoch: [53][60/196]	Time 0.133 (0.157)	Data 0.000 (0.020)	Loss 0.5490 (0.5091)	Prec@1 89.453 (91.489)	Prec@5 100.000 (99.648)
2025-05-20 11:55:33 - INFO - TRAINING - Epoch: [53][70/196]	Time 0.133 (0.154)	Data 0.000 (0.018)	Loss 0.5485 (0.5096)	Prec@1 89.844 (91.483)	Prec@5 100.000 (99.648)
2025-05-20 11:55:35 - INFO - TRAINING - Epoch: [53][80/196]	Time 0.134 (0.152)	Data 0.000 (0.016)	Loss 0.4338 (0.5081)	Prec@1 95.703 (91.517)	Prec@5 100.000 (99.653)
2025-05-20 11:55:36 - INFO - TRAINING - Epoch: [53][90/196]	Time 0.132 (0.150)	Data 0.001 (0.014)	Loss 0.5012 (0.5089)	Prec@1 89.844 (91.398)	Prec@5 99.609 (99.657)
2025-05-20 11:55:37 - INFO - TRAINING - Epoch: [53][100/196]	Time 0.133 (0.148)	Data 0.004 (0.013)	Loss 0.5138 (0.5107)	Prec@1 91.016 (91.344)	Prec@5 98.828 (99.633)
2025-05-20 11:55:39 - INFO - TRAINING - Epoch: [53][110/196]	Time 0.141 (0.147)	Data 0.000 (0.012)	Loss 0.5403 (0.5102)	Prec@1 90.234 (91.396)	Prec@5 99.609 (99.616)
2025-05-20 11:55:40 - INFO - TRAINING - Epoch: [53][120/196]	Time 0.141 (0.147)	Data 0.012 (0.012)	Loss 0.5229 (0.5103)	Prec@1 91.016 (91.384)	Prec@5 100.000 (99.626)
2025-05-20 11:55:42 - INFO - TRAINING - Epoch: [53][130/196]	Time 0.137 (0.147)	Data 0.000 (0.012)	Loss 0.4907 (0.5098)	Prec@1 93.750 (91.403)	Prec@5 100.000 (99.618)
2025-05-20 11:55:43 - INFO - TRAINING - Epoch: [53][140/196]	Time 0.135 (0.146)	Data 0.000 (0.011)	Loss 0.4867 (0.5111)	Prec@1 93.359 (91.345)	Prec@5 100.000 (99.618)
2025-05-20 11:55:44 - INFO - TRAINING - Epoch: [53][150/196]	Time 0.134 (0.146)	Data 0.000 (0.010)	Loss 0.4625 (0.5103)	Prec@1 93.750 (91.380)	Prec@5 99.609 (99.620)
2025-05-20 11:55:46 - INFO - TRAINING - Epoch: [53][160/196]	Time 0.133 (0.145)	Data 0.000 (0.010)	Loss 0.4944 (0.5098)	Prec@1 91.406 (91.406)	Prec@5 100.000 (99.636)
2025-05-20 11:55:47 - INFO - TRAINING - Epoch: [53][170/196]	Time 0.135 (0.144)	Data 0.000 (0.009)	Loss 0.4794 (0.5097)	Prec@1 92.578 (91.420)	Prec@5 100.000 (99.646)
2025-05-20 11:55:48 - INFO - TRAINING - Epoch: [53][180/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.5192 (0.5096)	Prec@1 91.016 (91.434)	Prec@5 99.609 (99.648)
2025-05-20 11:55:50 - INFO - TRAINING - Epoch: [53][190/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.5285 (0.5093)	Prec@1 89.062 (91.445)	Prec@5 100.000 (99.652)
2025-05-20 11:55:51 - INFO - EVALUATING - Epoch: [53][0/40]	Time 0.868 (0.868)	Data 0.789 (0.789)	Loss 0.5833 (0.5833)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
2025-05-20 11:55:52 - INFO - EVALUATING - Epoch: [53][10/40]	Time 0.077 (0.168)	Data 0.000 (0.091)	Loss 0.6135 (0.6262)	Prec@1 85.156 (86.115)	Prec@5 99.219 (98.899)
2025-05-20 11:55:53 - INFO - EVALUATING - Epoch: [53][20/40]	Time 0.073 (0.135)	Data 0.000 (0.059)	Loss 0.5973 (0.6265)	Prec@1 87.500 (86.458)	Prec@5 99.219 (98.586)
2025-05-20 11:55:54 - INFO - EVALUATING - Epoch: [53][30/40]	Time 0.072 (0.125)	Data 0.000 (0.048)	Loss 0.6907 (0.6325)	Prec@1 83.594 (86.177)	Prec@5 98.047 (98.715)
2025-05-20 11:55:55 - INFO - 
 Epoch: 54	Training Loss 0.5094 	Training Prec@1 91.450 	Training Prec@5 99.652 	Validation Loss 0.6317 	Validation Prec@1 86.050 	Validation Prec@5 98.730 

2025-05-20 11:55:55 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:55:55 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:55:55 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:55:55 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:55:56 - INFO - TRAINING - Epoch: [54][0/196]	Time 1.072 (1.072)	Data 0.955 (0.955)	Loss 0.4498 (0.4498)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2025-05-20 11:55:58 - INFO - TRAINING - Epoch: [54][10/196]	Time 0.141 (0.227)	Data 0.011 (0.092)	Loss 0.5320 (0.5018)	Prec@1 91.406 (91.726)	Prec@5 100.000 (99.822)
2025-05-20 11:55:59 - INFO - TRAINING - Epoch: [54][20/196]	Time 0.133 (0.185)	Data 0.000 (0.050)	Loss 0.4914 (0.5033)	Prec@1 91.797 (91.685)	Prec@5 100.000 (99.758)
2025-05-20 11:56:00 - INFO - TRAINING - Epoch: [54][30/196]	Time 0.135 (0.169)	Data 0.006 (0.035)	Loss 0.4801 (0.5011)	Prec@1 93.359 (91.797)	Prec@5 100.000 (99.735)
2025-05-20 11:56:02 - INFO - TRAINING - Epoch: [54][40/196]	Time 0.134 (0.160)	Data 0.000 (0.027)	Loss 0.4905 (0.4982)	Prec@1 92.578 (91.968)	Prec@5 99.609 (99.752)
2025-05-20 11:56:03 - INFO - TRAINING - Epoch: [54][50/196]	Time 0.133 (0.155)	Data 0.000 (0.022)	Loss 0.5201 (0.5016)	Prec@1 90.625 (91.743)	Prec@5 98.828 (99.694)
2025-05-20 11:56:04 - INFO - TRAINING - Epoch: [54][60/196]	Time 0.146 (0.152)	Data 0.000 (0.019)	Loss 0.5011 (0.5023)	Prec@1 92.578 (91.707)	Prec@5 100.000 (99.667)
2025-05-20 11:56:06 - INFO - TRAINING - Epoch: [54][70/196]	Time 0.157 (0.151)	Data 0.000 (0.017)	Loss 0.5215 (0.5020)	Prec@1 90.625 (91.698)	Prec@5 100.000 (99.664)
2025-05-20 11:56:07 - INFO - TRAINING - Epoch: [54][80/196]	Time 0.137 (0.151)	Data 0.000 (0.016)	Loss 0.5283 (0.5028)	Prec@1 90.625 (91.696)	Prec@5 99.219 (99.658)
2025-05-20 11:56:09 - INFO - TRAINING - Epoch: [54][90/196]	Time 0.133 (0.150)	Data 0.000 (0.014)	Loss 0.4872 (0.5030)	Prec@1 92.188 (91.711)	Prec@5 99.609 (99.652)
2025-05-20 11:56:10 - INFO - TRAINING - Epoch: [54][100/196]	Time 0.134 (0.149)	Data 0.007 (0.013)	Loss 0.5262 (0.5048)	Prec@1 91.406 (91.592)	Prec@5 100.000 (99.648)
2025-05-20 11:56:12 - INFO - TRAINING - Epoch: [54][110/196]	Time 0.131 (0.147)	Data 0.000 (0.012)	Loss 0.5098 (0.5042)	Prec@1 90.625 (91.579)	Prec@5 99.609 (99.662)
2025-05-20 11:56:13 - INFO - TRAINING - Epoch: [54][120/196]	Time 0.133 (0.146)	Data 0.000 (0.011)	Loss 0.5276 (0.5044)	Prec@1 92.188 (91.568)	Prec@5 100.000 (99.661)
2025-05-20 11:56:14 - INFO - TRAINING - Epoch: [54][130/196]	Time 0.136 (0.146)	Data 0.002 (0.011)	Loss 0.5253 (0.5050)	Prec@1 89.844 (91.534)	Prec@5 100.000 (99.657)
2025-05-20 11:56:16 - INFO - TRAINING - Epoch: [54][140/196]	Time 0.133 (0.145)	Data 0.000 (0.010)	Loss 0.5372 (0.5064)	Prec@1 90.234 (91.462)	Prec@5 100.000 (99.654)
2025-05-20 11:56:17 - INFO - TRAINING - Epoch: [54][150/196]	Time 0.133 (0.144)	Data 0.001 (0.010)	Loss 0.5165 (0.5060)	Prec@1 91.797 (91.528)	Prec@5 100.000 (99.656)
2025-05-20 11:56:18 - INFO - TRAINING - Epoch: [54][160/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.4627 (0.5050)	Prec@1 91.797 (91.566)	Prec@5 99.609 (99.653)
2025-05-20 11:56:20 - INFO - TRAINING - Epoch: [54][170/196]	Time 0.136 (0.144)	Data 0.000 (0.009)	Loss 0.4711 (0.5055)	Prec@1 92.969 (91.555)	Prec@5 100.000 (99.662)
2025-05-20 11:56:21 - INFO - TRAINING - Epoch: [54][180/196]	Time 0.132 (0.144)	Data 0.000 (0.009)	Loss 0.5056 (0.5050)	Prec@1 89.844 (91.568)	Prec@5 100.000 (99.668)
2025-05-20 11:56:23 - INFO - TRAINING - Epoch: [54][190/196]	Time 0.132 (0.144)	Data 0.000 (0.009)	Loss 0.5595 (0.5059)	Prec@1 88.281 (91.511)	Prec@5 100.000 (99.661)
2025-05-20 11:56:24 - INFO - EVALUATING - Epoch: [54][0/40]	Time 0.886 (0.886)	Data 0.817 (0.817)	Loss 0.5985 (0.5985)	Prec@1 89.453 (89.453)	Prec@5 99.219 (99.219)
2025-05-20 11:56:25 - INFO - EVALUATING - Epoch: [54][10/40]	Time 0.082 (0.151)	Data 0.008 (0.079)	Loss 0.5634 (0.6247)	Prec@1 89.062 (87.038)	Prec@5 99.219 (99.183)
2025-05-20 11:56:26 - INFO - EVALUATING - Epoch: [54][20/40]	Time 0.076 (0.115)	Data 0.007 (0.043)	Loss 0.6183 (0.6335)	Prec@1 86.328 (86.514)	Prec@5 98.828 (98.717)
2025-05-20 11:56:26 - INFO - EVALUATING - Epoch: [54][30/40]	Time 0.070 (0.102)	Data 0.000 (0.030)	Loss 0.7064 (0.6387)	Prec@1 80.859 (86.101)	Prec@5 99.609 (98.753)
2025-05-20 11:56:27 - INFO - 
 Epoch: 55	Training Loss 0.5054 	Training Prec@1 91.552 	Training Prec@5 99.660 	Validation Loss 0.6378 	Validation Prec@1 86.140 	Validation Prec@5 98.840 

2025-05-20 11:56:27 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:56:27 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:56:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:56:27 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:56:28 - INFO - TRAINING - Epoch: [55][0/196]	Time 1.062 (1.062)	Data 0.947 (0.947)	Loss 0.4829 (0.4829)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2025-05-20 11:56:30 - INFO - TRAINING - Epoch: [55][10/196]	Time 0.148 (0.230)	Data 0.009 (0.092)	Loss 0.4836 (0.4876)	Prec@1 92.578 (92.685)	Prec@5 100.000 (99.680)
2025-05-20 11:56:31 - INFO - TRAINING - Epoch: [55][20/196]	Time 0.146 (0.186)	Data 0.006 (0.050)	Loss 0.5326 (0.4908)	Prec@1 89.453 (92.355)	Prec@5 99.609 (99.702)
2025-05-20 11:56:33 - INFO - TRAINING - Epoch: [55][30/196]	Time 0.142 (0.172)	Data 0.007 (0.035)	Loss 0.4927 (0.4957)	Prec@1 92.188 (92.074)	Prec@5 99.609 (99.710)
2025-05-20 11:56:34 - INFO - TRAINING - Epoch: [55][40/196]	Time 0.155 (0.166)	Data 0.000 (0.027)	Loss 0.4958 (0.4992)	Prec@1 90.234 (91.854)	Prec@5 99.609 (99.733)
2025-05-20 11:56:36 - INFO - TRAINING - Epoch: [55][50/196]	Time 0.131 (0.162)	Data 0.007 (0.023)	Loss 0.5041 (0.4989)	Prec@1 91.797 (91.927)	Prec@5 99.609 (99.701)
2025-05-20 11:56:37 - INFO - TRAINING - Epoch: [55][60/196]	Time 0.135 (0.157)	Data 0.000 (0.020)	Loss 0.6076 (0.5034)	Prec@1 88.672 (91.707)	Prec@5 100.000 (99.705)
2025-05-20 11:56:38 - INFO - TRAINING - Epoch: [55][70/196]	Time 0.133 (0.154)	Data 0.007 (0.018)	Loss 0.5355 (0.5056)	Prec@1 89.062 (91.511)	Prec@5 100.000 (99.714)
2025-05-20 11:56:40 - INFO - TRAINING - Epoch: [55][80/196]	Time 0.134 (0.152)	Data 0.007 (0.016)	Loss 0.4610 (0.5044)	Prec@1 93.750 (91.570)	Prec@5 100.000 (99.720)
2025-05-20 11:56:41 - INFO - TRAINING - Epoch: [55][90/196]	Time 0.136 (0.150)	Data 0.000 (0.014)	Loss 0.5018 (0.5054)	Prec@1 92.578 (91.514)	Prec@5 100.000 (99.695)
2025-05-20 11:56:42 - INFO - TRAINING - Epoch: [55][100/196]	Time 0.147 (0.148)	Data 0.000 (0.013)	Loss 0.5298 (0.5071)	Prec@1 91.406 (91.472)	Prec@5 98.828 (99.671)
2025-05-20 11:56:44 - INFO - TRAINING - Epoch: [55][110/196]	Time 0.134 (0.147)	Data 0.000 (0.012)	Loss 0.5504 (0.5073)	Prec@1 89.062 (91.463)	Prec@5 100.000 (99.676)
2025-05-20 11:56:45 - INFO - TRAINING - Epoch: [55][120/196]	Time 0.146 (0.146)	Data 0.000 (0.012)	Loss 0.5154 (0.5063)	Prec@1 91.797 (91.535)	Prec@5 100.000 (99.690)
2025-05-20 11:56:46 - INFO - TRAINING - Epoch: [55][130/196]	Time 0.135 (0.146)	Data 0.000 (0.011)	Loss 0.5034 (0.5055)	Prec@1 94.531 (91.606)	Prec@5 100.000 (99.684)
2025-05-20 11:56:48 - INFO - TRAINING - Epoch: [55][140/196]	Time 0.161 (0.146)	Data 0.010 (0.011)	Loss 0.4912 (0.5069)	Prec@1 93.359 (91.572)	Prec@5 100.000 (99.692)
2025-05-20 11:56:49 - INFO - TRAINING - Epoch: [55][150/196]	Time 0.137 (0.146)	Data 0.000 (0.011)	Loss 0.5355 (0.5076)	Prec@1 89.453 (91.546)	Prec@5 99.219 (99.692)
2025-05-20 11:56:51 - INFO - TRAINING - Epoch: [55][160/196]	Time 0.133 (0.145)	Data 0.001 (0.010)	Loss 0.4632 (0.5072)	Prec@1 94.141 (91.571)	Prec@5 99.609 (99.692)
2025-05-20 11:56:52 - INFO - TRAINING - Epoch: [55][170/196]	Time 0.132 (0.144)	Data 0.007 (0.010)	Loss 0.4887 (0.5063)	Prec@1 92.578 (91.616)	Prec@5 100.000 (99.692)
2025-05-20 11:56:53 - INFO - TRAINING - Epoch: [55][180/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.5341 (0.5064)	Prec@1 89.062 (91.611)	Prec@5 100.000 (99.691)
2025-05-20 11:56:55 - INFO - TRAINING - Epoch: [55][190/196]	Time 0.132 (0.143)	Data 0.000 (0.009)	Loss 0.5080 (0.5068)	Prec@1 90.234 (91.580)	Prec@5 100.000 (99.691)
2025-05-20 11:56:56 - INFO - EVALUATING - Epoch: [55][0/40]	Time 0.656 (0.656)	Data 0.584 (0.584)	Loss 0.6129 (0.6129)	Prec@1 86.328 (86.328)	Prec@5 98.828 (98.828)
2025-05-20 11:56:57 - INFO - EVALUATING - Epoch: [55][10/40]	Time 0.076 (0.139)	Data 0.000 (0.064)	Loss 0.6281 (0.6452)	Prec@1 86.719 (85.369)	Prec@5 97.656 (98.224)
2025-05-20 11:56:58 - INFO - EVALUATING - Epoch: [55][20/40]	Time 0.071 (0.110)	Data 0.001 (0.035)	Loss 0.6247 (0.6384)	Prec@1 87.891 (85.770)	Prec@5 98.828 (98.196)
2025-05-20 11:56:58 - INFO - EVALUATING - Epoch: [55][30/40]	Time 0.070 (0.098)	Data 0.000 (0.024)	Loss 0.6761 (0.6428)	Prec@1 82.812 (85.534)	Prec@5 97.266 (98.185)
2025-05-20 11:56:59 - INFO - 
 Epoch: 56	Training Loss 0.5071 	Training Prec@1 91.582 	Training Prec@5 99.694 	Validation Loss 0.6435 	Validation Prec@1 85.540 	Validation Prec@5 98.250 

2025-05-20 11:56:59 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:56:59 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:56:59 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:56:59 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:57:01 - INFO - TRAINING - Epoch: [56][0/196]	Time 1.688 (1.688)	Data 1.473 (1.473)	Loss 0.5108 (0.5108)	Prec@1 91.797 (91.797)	Prec@5 99.609 (99.609)
2025-05-20 11:57:03 - INFO - TRAINING - Epoch: [56][10/196]	Time 0.149 (0.282)	Data 0.007 (0.140)	Loss 0.4940 (0.5163)	Prec@1 92.578 (90.803)	Prec@5 99.609 (99.645)
2025-05-20 11:57:04 - INFO - TRAINING - Epoch: [56][20/196]	Time 0.135 (0.213)	Data 0.000 (0.074)	Loss 0.4444 (0.5060)	Prec@1 94.531 (91.332)	Prec@5 100.000 (99.740)
2025-05-20 11:57:05 - INFO - TRAINING - Epoch: [56][30/196]	Time 0.134 (0.188)	Data 0.004 (0.051)	Loss 0.5307 (0.5022)	Prec@1 91.406 (91.557)	Prec@5 99.219 (99.773)
2025-05-20 11:57:07 - INFO - TRAINING - Epoch: [56][40/196]	Time 0.132 (0.175)	Data 0.000 (0.038)	Loss 0.4732 (0.4989)	Prec@1 92.578 (91.616)	Prec@5 100.000 (99.771)
2025-05-20 11:57:08 - INFO - TRAINING - Epoch: [56][50/196]	Time 0.132 (0.167)	Data 0.006 (0.032)	Loss 0.5043 (0.5015)	Prec@1 92.188 (91.521)	Prec@5 99.609 (99.732)
2025-05-20 11:57:09 - INFO - TRAINING - Epoch: [56][60/196]	Time 0.134 (0.161)	Data 0.000 (0.027)	Loss 0.4269 (0.5011)	Prec@1 97.266 (91.650)	Prec@5 100.000 (99.763)
2025-05-20 11:57:11 - INFO - TRAINING - Epoch: [56][70/196]	Time 0.134 (0.158)	Data 0.000 (0.023)	Loss 0.4535 (0.4990)	Prec@1 92.969 (91.703)	Prec@5 100.000 (99.774)
2025-05-20 11:57:12 - INFO - TRAINING - Epoch: [56][80/196]	Time 0.135 (0.156)	Data 0.000 (0.021)	Loss 0.5323 (0.4996)	Prec@1 91.797 (91.696)	Prec@5 98.828 (99.773)
2025-05-20 11:57:14 - INFO - TRAINING - Epoch: [56][90/196]	Time 0.162 (0.155)	Data 0.000 (0.019)	Loss 0.5278 (0.5027)	Prec@1 89.453 (91.604)	Prec@5 99.609 (99.760)
2025-05-20 11:57:15 - INFO - TRAINING - Epoch: [56][100/196]	Time 0.155 (0.157)	Data 0.020 (0.018)	Loss 0.5136 (0.5034)	Prec@1 91.406 (91.623)	Prec@5 99.609 (99.745)
2025-05-20 11:57:17 - INFO - TRAINING - Epoch: [56][110/196]	Time 0.182 (0.157)	Data 0.000 (0.018)	Loss 0.5366 (0.5042)	Prec@1 90.625 (91.589)	Prec@5 100.000 (99.740)
2025-05-20 11:57:18 - INFO - TRAINING - Epoch: [56][120/196]	Time 0.133 (0.156)	Data 0.000 (0.017)	Loss 0.5300 (0.5045)	Prec@1 91.016 (91.587)	Prec@5 100.000 (99.739)
2025-05-20 11:57:20 - INFO - TRAINING - Epoch: [56][130/196]	Time 0.133 (0.154)	Data 0.000 (0.015)	Loss 0.5064 (0.5045)	Prec@1 91.797 (91.567)	Prec@5 100.000 (99.738)
2025-05-20 11:57:21 - INFO - TRAINING - Epoch: [56][140/196]	Time 0.134 (0.153)	Data 0.000 (0.015)	Loss 0.4798 (0.5037)	Prec@1 92.188 (91.589)	Prec@5 100.000 (99.737)
2025-05-20 11:57:22 - INFO - TRAINING - Epoch: [56][150/196]	Time 0.133 (0.152)	Data 0.003 (0.014)	Loss 0.5468 (0.5040)	Prec@1 90.625 (91.554)	Prec@5 99.219 (99.723)
2025-05-20 11:57:24 - INFO - TRAINING - Epoch: [56][160/196]	Time 0.134 (0.150)	Data 0.000 (0.013)	Loss 0.4470 (0.5038)	Prec@1 93.750 (91.574)	Prec@5 99.609 (99.711)
2025-05-20 11:57:25 - INFO - TRAINING - Epoch: [56][170/196]	Time 0.134 (0.149)	Data 0.000 (0.012)	Loss 0.5073 (0.5036)	Prec@1 91.797 (91.587)	Prec@5 99.609 (99.719)
2025-05-20 11:57:26 - INFO - TRAINING - Epoch: [56][180/196]	Time 0.133 (0.149)	Data 0.000 (0.012)	Loss 0.4862 (0.5032)	Prec@1 91.406 (91.594)	Prec@5 100.000 (99.713)
2025-05-20 11:57:28 - INFO - TRAINING - Epoch: [56][190/196]	Time 0.134 (0.148)	Data 0.000 (0.011)	Loss 0.5402 (0.5039)	Prec@1 88.281 (91.529)	Prec@5 100.000 (99.718)
2025-05-20 11:57:30 - INFO - EVALUATING - Epoch: [56][0/40]	Time 1.071 (1.071)	Data 1.002 (1.002)	Loss 0.5896 (0.5896)	Prec@1 89.453 (89.453)	Prec@5 99.609 (99.609)
2025-05-20 11:57:30 - INFO - EVALUATING - Epoch: [56][10/40]	Time 0.073 (0.174)	Data 0.005 (0.101)	Loss 0.5944 (0.6277)	Prec@1 85.938 (85.973)	Prec@5 98.828 (98.864)
2025-05-20 11:57:31 - INFO - EVALUATING - Epoch: [56][20/40]	Time 0.084 (0.128)	Data 0.010 (0.054)	Loss 0.5804 (0.6278)	Prec@1 89.062 (86.254)	Prec@5 98.438 (98.531)
2025-05-20 11:57:32 - INFO - EVALUATING - Epoch: [56][30/40]	Time 0.070 (0.110)	Data 0.000 (0.037)	Loss 0.6709 (0.6316)	Prec@1 83.203 (86.038)	Prec@5 98.828 (98.564)
2025-05-20 11:57:33 - INFO - 
 Epoch: 57	Training Loss 0.5044 	Training Prec@1 91.508 	Training Prec@5 99.712 	Validation Loss 0.6298 	Validation Prec@1 86.210 	Validation Prec@5 98.680 

2025-05-20 11:57:33 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:57:33 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:57:33 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:57:33 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:57:34 - INFO - TRAINING - Epoch: [57][0/196]	Time 0.900 (0.900)	Data 0.782 (0.782)	Loss 0.4778 (0.4778)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2025-05-20 11:57:35 - INFO - TRAINING - Epoch: [57][10/196]	Time 0.145 (0.218)	Data 0.000 (0.085)	Loss 0.5186 (0.5102)	Prec@1 90.625 (91.619)	Prec@5 99.219 (99.432)
2025-05-20 11:57:36 - INFO - TRAINING - Epoch: [57][20/196]	Time 0.134 (0.179)	Data 0.012 (0.048)	Loss 0.4917 (0.4967)	Prec@1 92.188 (92.076)	Prec@5 99.219 (99.554)
2025-05-20 11:57:38 - INFO - TRAINING - Epoch: [57][30/196]	Time 0.134 (0.165)	Data 0.007 (0.034)	Loss 0.5150 (0.4982)	Prec@1 90.625 (91.998)	Prec@5 99.609 (99.597)
2025-05-20 11:57:39 - INFO - TRAINING - Epoch: [57][40/196]	Time 0.132 (0.157)	Data 0.002 (0.026)	Loss 0.5389 (0.5015)	Prec@1 89.844 (91.816)	Prec@5 100.000 (99.657)
2025-05-20 11:57:41 - INFO - TRAINING - Epoch: [57][50/196]	Time 0.138 (0.153)	Data 0.007 (0.021)	Loss 0.5127 (0.5014)	Prec@1 90.625 (91.736)	Prec@5 100.000 (99.625)
2025-05-20 11:57:42 - INFO - TRAINING - Epoch: [57][60/196]	Time 0.143 (0.152)	Data 0.015 (0.019)	Loss 0.4997 (0.5014)	Prec@1 93.359 (91.822)	Prec@5 99.609 (99.641)
2025-05-20 11:57:43 - INFO - TRAINING - Epoch: [57][70/196]	Time 0.132 (0.151)	Data 0.010 (0.017)	Loss 0.5088 (0.5015)	Prec@1 91.797 (91.797)	Prec@5 99.609 (99.648)
2025-05-20 11:57:45 - INFO - TRAINING - Epoch: [57][80/196]	Time 0.132 (0.149)	Data 0.007 (0.016)	Loss 0.4596 (0.5008)	Prec@1 93.359 (91.816)	Prec@5 99.609 (99.658)
2025-05-20 11:57:46 - INFO - TRAINING - Epoch: [57][90/196]	Time 0.132 (0.147)	Data 0.000 (0.014)	Loss 0.5028 (0.4999)	Prec@1 91.797 (91.861)	Prec@5 99.609 (99.674)
2025-05-20 11:57:47 - INFO - TRAINING - Epoch: [57][100/196]	Time 0.141 (0.146)	Data 0.009 (0.013)	Loss 0.4592 (0.5002)	Prec@1 92.969 (91.859)	Prec@5 100.000 (99.664)
2025-05-20 11:57:49 - INFO - TRAINING - Epoch: [57][110/196]	Time 0.135 (0.145)	Data 0.000 (0.012)	Loss 0.4940 (0.4980)	Prec@1 92.578 (91.987)	Prec@5 99.609 (99.669)
2025-05-20 11:57:50 - INFO - TRAINING - Epoch: [57][120/196]	Time 0.134 (0.144)	Data 0.000 (0.012)	Loss 0.5169 (0.4987)	Prec@1 91.016 (91.991)	Prec@5 99.609 (99.680)
2025-05-20 11:57:51 - INFO - TRAINING - Epoch: [57][130/196]	Time 0.133 (0.143)	Data 0.000 (0.011)	Loss 0.5490 (0.4996)	Prec@1 90.234 (91.946)	Prec@5 99.609 (99.684)
2025-05-20 11:57:53 - INFO - TRAINING - Epoch: [57][140/196]	Time 0.146 (0.143)	Data 0.000 (0.010)	Loss 0.5467 (0.4997)	Prec@1 89.844 (91.949)	Prec@5 99.609 (99.687)
2025-05-20 11:57:54 - INFO - TRAINING - Epoch: [57][150/196]	Time 0.142 (0.143)	Data 0.000 (0.010)	Loss 0.5288 (0.5005)	Prec@1 90.625 (91.903)	Prec@5 100.000 (99.687)
2025-05-20 11:57:56 - INFO - TRAINING - Epoch: [57][160/196]	Time 0.138 (0.143)	Data 0.000 (0.010)	Loss 0.5536 (0.5010)	Prec@1 89.844 (91.853)	Prec@5 99.609 (99.675)
2025-05-20 11:57:57 - INFO - TRAINING - Epoch: [57][170/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.4878 (0.5014)	Prec@1 92.188 (91.822)	Prec@5 100.000 (99.682)
2025-05-20 11:57:58 - INFO - TRAINING - Epoch: [57][180/196]	Time 0.133 (0.142)	Data 0.000 (0.009)	Loss 0.5235 (0.5009)	Prec@1 91.016 (91.855)	Prec@5 99.219 (99.691)
2025-05-20 11:58:00 - INFO - TRAINING - Epoch: [57][190/196]	Time 0.133 (0.142)	Data 0.000 (0.009)	Loss 0.5318 (0.5011)	Prec@1 91.016 (91.834)	Prec@5 98.828 (99.687)
2025-05-20 11:58:01 - INFO - EVALUATING - Epoch: [57][0/40]	Time 0.693 (0.693)	Data 0.615 (0.615)	Loss 0.5900 (0.5900)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
2025-05-20 11:58:02 - INFO - EVALUATING - Epoch: [57][10/40]	Time 0.082 (0.137)	Data 0.004 (0.062)	Loss 0.6038 (0.6347)	Prec@1 87.891 (85.973)	Prec@5 98.047 (98.473)
2025-05-20 11:58:03 - INFO - EVALUATING - Epoch: [57][20/40]	Time 0.089 (0.109)	Data 0.001 (0.033)	Loss 0.5996 (0.6388)	Prec@1 87.109 (86.161)	Prec@5 99.219 (98.233)
2025-05-20 11:58:04 - INFO - EVALUATING - Epoch: [57][30/40]	Time 0.069 (0.098)	Data 0.000 (0.023)	Loss 0.6995 (0.6446)	Prec@1 82.422 (85.837)	Prec@5 98.047 (98.299)
2025-05-20 11:58:04 - INFO - 
 Epoch: 58	Training Loss 0.5012 	Training Prec@1 91.830 	Training Prec@5 99.688 	Validation Loss 0.6444 	Validation Prec@1 85.710 	Validation Prec@5 98.420 

2025-05-20 11:58:04 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:58:04 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:58:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:58:04 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:58:05 - INFO - TRAINING - Epoch: [58][0/196]	Time 0.874 (0.874)	Data 0.739 (0.739)	Loss 0.5264 (0.5264)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2025-05-20 11:58:07 - INFO - TRAINING - Epoch: [58][10/196]	Time 0.192 (0.232)	Data 0.000 (0.086)	Loss 0.5164 (0.5074)	Prec@1 90.625 (91.584)	Prec@5 99.609 (99.787)
2025-05-20 11:58:09 - INFO - TRAINING - Epoch: [58][20/196]	Time 0.146 (0.199)	Data 0.000 (0.046)	Loss 0.4980 (0.5014)	Prec@1 91.016 (91.722)	Prec@5 100.000 (99.814)
2025-05-20 11:58:10 - INFO - TRAINING - Epoch: [58][30/196]	Time 0.132 (0.183)	Data 0.018 (0.034)	Loss 0.4877 (0.5018)	Prec@1 91.797 (91.696)	Prec@5 99.609 (99.761)
2025-05-20 11:58:11 - INFO - TRAINING - Epoch: [58][40/196]	Time 0.134 (0.172)	Data 0.000 (0.026)	Loss 0.5061 (0.5026)	Prec@1 89.062 (91.606)	Prec@5 100.000 (99.752)
2025-05-20 11:58:13 - INFO - TRAINING - Epoch: [58][50/196]	Time 0.134 (0.164)	Data 0.000 (0.021)	Loss 0.4780 (0.5005)	Prec@1 93.359 (91.659)	Prec@5 100.000 (99.755)
2025-05-20 11:58:14 - INFO - TRAINING - Epoch: [58][60/196]	Time 0.134 (0.159)	Data 0.000 (0.018)	Loss 0.5505 (0.4993)	Prec@1 89.844 (91.688)	Prec@5 99.609 (99.757)
2025-05-20 11:58:15 - INFO - TRAINING - Epoch: [58][70/196]	Time 0.131 (0.156)	Data 0.000 (0.016)	Loss 0.5068 (0.4987)	Prec@1 91.797 (91.670)	Prec@5 99.609 (99.758)
2025-05-20 11:58:17 - INFO - TRAINING - Epoch: [58][80/196]	Time 0.134 (0.153)	Data 0.000 (0.015)	Loss 0.4987 (0.4984)	Prec@1 91.016 (91.657)	Prec@5 100.000 (99.759)
2025-05-20 11:58:18 - INFO - TRAINING - Epoch: [58][90/196]	Time 0.134 (0.151)	Data 0.011 (0.013)	Loss 0.5534 (0.4998)	Prec@1 91.016 (91.642)	Prec@5 99.609 (99.742)
2025-05-20 11:58:19 - INFO - TRAINING - Epoch: [58][100/196]	Time 0.142 (0.150)	Data 0.000 (0.012)	Loss 0.5372 (0.5017)	Prec@1 91.016 (91.588)	Prec@5 99.609 (99.733)
2025-05-20 11:58:21 - INFO - TRAINING - Epoch: [58][110/196]	Time 0.149 (0.149)	Data 0.008 (0.012)	Loss 0.4468 (0.5027)	Prec@1 94.922 (91.519)	Prec@5 99.609 (99.740)
2025-05-20 11:58:22 - INFO - TRAINING - Epoch: [58][120/196]	Time 0.147 (0.149)	Data 0.000 (0.012)	Loss 0.4990 (0.5024)	Prec@1 92.969 (91.564)	Prec@5 100.000 (99.739)
2025-05-20 11:58:24 - INFO - TRAINING - Epoch: [58][130/196]	Time 0.135 (0.148)	Data 0.007 (0.011)	Loss 0.5347 (0.5019)	Prec@1 89.844 (91.618)	Prec@5 99.609 (99.723)
2025-05-20 11:58:25 - INFO - TRAINING - Epoch: [58][140/196]	Time 0.133 (0.147)	Data 0.000 (0.010)	Loss 0.4719 (0.5023)	Prec@1 94.141 (91.661)	Prec@5 100.000 (99.715)
2025-05-20 11:58:26 - INFO - TRAINING - Epoch: [58][150/196]	Time 0.133 (0.146)	Data 0.000 (0.010)	Loss 0.4851 (0.5022)	Prec@1 92.969 (91.665)	Prec@5 99.609 (99.713)
2025-05-20 11:58:28 - INFO - TRAINING - Epoch: [58][160/196]	Time 0.134 (0.146)	Data 0.007 (0.009)	Loss 0.4901 (0.5030)	Prec@1 91.406 (91.639)	Prec@5 100.000 (99.709)
2025-05-20 11:58:29 - INFO - TRAINING - Epoch: [58][170/196]	Time 0.132 (0.145)	Data 0.002 (0.009)	Loss 0.5583 (0.5037)	Prec@1 88.281 (91.610)	Prec@5 98.828 (99.705)
2025-05-20 11:58:30 - INFO - TRAINING - Epoch: [58][180/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.4647 (0.5028)	Prec@1 92.578 (91.641)	Prec@5 100.000 (99.713)
2025-05-20 11:58:32 - INFO - TRAINING - Epoch: [58][190/196]	Time 0.134 (0.144)	Data 0.000 (0.008)	Loss 0.5333 (0.5028)	Prec@1 90.234 (91.652)	Prec@5 100.000 (99.708)
2025-05-20 11:58:34 - INFO - EVALUATING - Epoch: [58][0/40]	Time 1.162 (1.162)	Data 1.085 (1.085)	Loss 0.6229 (0.6229)	Prec@1 86.328 (86.328)	Prec@5 98.438 (98.438)
2025-05-20 11:58:35 - INFO - EVALUATING - Epoch: [58][10/40]	Time 0.085 (0.202)	Data 0.002 (0.124)	Loss 0.6150 (0.6330)	Prec@1 86.719 (86.009)	Prec@5 98.438 (98.651)
2025-05-20 11:58:36 - INFO - EVALUATING - Epoch: [58][20/40]	Time 0.116 (0.156)	Data 0.021 (0.077)	Loss 0.5977 (0.6368)	Prec@1 88.281 (86.161)	Prec@5 99.609 (98.344)
2025-05-20 11:58:37 - INFO - EVALUATING - Epoch: [58][30/40]	Time 0.069 (0.133)	Data 0.000 (0.055)	Loss 0.6243 (0.6374)	Prec@1 84.766 (85.963)	Prec@5 99.219 (98.488)
2025-05-20 11:58:37 - INFO - 
 Epoch: 59	Training Loss 0.5025 	Training Prec@1 91.660 	Training Prec@5 99.706 	Validation Loss 0.6360 	Validation Prec@1 85.890 	Validation Prec@5 98.570 

2025-05-20 11:58:37 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:58:37 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:58:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:58:37 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:58:38 - INFO - TRAINING - Epoch: [59][0/196]	Time 1.065 (1.065)	Data 0.944 (0.944)	Loss 0.4376 (0.4376)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2025-05-20 11:58:40 - INFO - TRAINING - Epoch: [59][10/196]	Time 0.138 (0.226)	Data 0.007 (0.090)	Loss 0.4816 (0.4879)	Prec@1 92.969 (92.791)	Prec@5 99.609 (99.787)
2025-05-20 11:58:41 - INFO - TRAINING - Epoch: [59][20/196]	Time 0.133 (0.182)	Data 0.000 (0.048)	Loss 0.4737 (0.4901)	Prec@1 92.578 (92.597)	Prec@5 100.000 (99.758)
2025-05-20 11:58:43 - INFO - TRAINING - Epoch: [59][30/196]	Time 0.133 (0.167)	Data 0.000 (0.033)	Loss 0.4800 (0.4892)	Prec@1 91.797 (92.591)	Prec@5 100.000 (99.773)
2025-05-20 11:58:44 - INFO - TRAINING - Epoch: [59][40/196]	Time 0.132 (0.159)	Data 0.000 (0.026)	Loss 0.4687 (0.4934)	Prec@1 93.359 (92.359)	Prec@5 100.000 (99.733)
2025-05-20 11:58:45 - INFO - TRAINING - Epoch: [59][50/196]	Time 0.131 (0.154)	Data 0.000 (0.021)	Loss 0.5158 (0.4963)	Prec@1 90.625 (92.134)	Prec@5 100.000 (99.717)
2025-05-20 11:58:47 - INFO - TRAINING - Epoch: [59][60/196]	Time 0.135 (0.151)	Data 0.000 (0.018)	Loss 0.4382 (0.4937)	Prec@1 96.094 (92.213)	Prec@5 99.219 (99.705)
2025-05-20 11:58:48 - INFO - TRAINING - Epoch: [59][70/196]	Time 0.143 (0.150)	Data 0.009 (0.016)	Loss 0.5351 (0.4965)	Prec@1 90.625 (92.072)	Prec@5 98.828 (99.703)
2025-05-20 11:58:50 - INFO - TRAINING - Epoch: [59][80/196]	Time 0.164 (0.150)	Data 0.004 (0.015)	Loss 0.4724 (0.4969)	Prec@1 92.969 (92.033)	Prec@5 100.000 (99.720)
2025-05-20 11:58:51 - INFO - TRAINING - Epoch: [59][90/196]	Time 0.133 (0.149)	Data 0.000 (0.014)	Loss 0.5324 (0.4965)	Prec@1 89.062 (92.024)	Prec@5 99.609 (99.738)
2025-05-20 11:58:52 - INFO - TRAINING - Epoch: [59][100/196]	Time 0.134 (0.147)	Data 0.000 (0.013)	Loss 0.4746 (0.4967)	Prec@1 92.969 (92.010)	Prec@5 100.000 (99.737)
2025-05-20 11:58:54 - INFO - TRAINING - Epoch: [59][110/196]	Time 0.134 (0.146)	Data 0.000 (0.012)	Loss 0.5326 (0.4990)	Prec@1 91.016 (91.927)	Prec@5 99.609 (99.733)
2025-05-20 11:58:55 - INFO - TRAINING - Epoch: [59][120/196]	Time 0.135 (0.145)	Data 0.006 (0.011)	Loss 0.4736 (0.4992)	Prec@1 94.141 (91.939)	Prec@5 100.000 (99.732)
2025-05-20 11:58:56 - INFO - TRAINING - Epoch: [59][130/196]	Time 0.133 (0.144)	Data 0.001 (0.010)	Loss 0.4750 (0.4984)	Prec@1 91.797 (91.970)	Prec@5 100.000 (99.720)
2025-05-20 11:58:58 - INFO - TRAINING - Epoch: [59][140/196]	Time 0.133 (0.143)	Data 0.000 (0.010)	Loss 0.4802 (0.4973)	Prec@1 92.188 (91.996)	Prec@5 100.000 (99.720)
2025-05-20 11:58:59 - INFO - TRAINING - Epoch: [59][150/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.5204 (0.4981)	Prec@1 92.578 (91.965)	Prec@5 100.000 (99.715)
2025-05-20 11:59:00 - INFO - TRAINING - Epoch: [59][160/196]	Time 0.141 (0.143)	Data 0.010 (0.009)	Loss 0.5344 (0.4981)	Prec@1 89.844 (91.938)	Prec@5 99.609 (99.723)
2025-05-20 11:59:02 - INFO - TRAINING - Epoch: [59][170/196]	Time 0.147 (0.143)	Data 0.000 (0.009)	Loss 0.5505 (0.4991)	Prec@1 89.453 (91.891)	Prec@5 100.000 (99.726)
2025-05-20 11:59:03 - INFO - TRAINING - Epoch: [59][180/196]	Time 0.129 (0.143)	Data 0.000 (0.009)	Loss 0.4968 (0.4995)	Prec@1 92.578 (91.870)	Prec@5 99.219 (99.722)
2025-05-20 11:59:05 - INFO - TRAINING - Epoch: [59][190/196]	Time 0.134 (0.142)	Data 0.000 (0.008)	Loss 0.4717 (0.5004)	Prec@1 93.750 (91.826)	Prec@5 99.609 (99.728)
2025-05-20 11:59:06 - INFO - EVALUATING - Epoch: [59][0/40]	Time 0.726 (0.726)	Data 0.649 (0.649)	Loss 0.6094 (0.6094)	Prec@1 87.891 (87.891)	Prec@5 99.219 (99.219)
2025-05-20 11:59:07 - INFO - EVALUATING - Epoch: [59][10/40]	Time 0.083 (0.136)	Data 0.000 (0.061)	Loss 0.5886 (0.6266)	Prec@1 88.281 (86.151)	Prec@5 99.609 (98.793)
2025-05-20 11:59:08 - INFO - EVALUATING - Epoch: [59][20/40]	Time 0.071 (0.108)	Data 0.001 (0.032)	Loss 0.6193 (0.6284)	Prec@1 85.938 (86.124)	Prec@5 99.219 (98.438)
2025-05-20 11:59:08 - INFO - EVALUATING - Epoch: [59][30/40]	Time 0.070 (0.096)	Data 0.000 (0.022)	Loss 0.6982 (0.6350)	Prec@1 82.031 (85.811)	Prec@5 98.438 (98.526)
2025-05-20 11:59:09 - INFO - 
 Epoch: 60	Training Loss 0.5002 	Training Prec@1 91.822 	Training Prec@5 99.732 	Validation Loss 0.6336 	Validation Prec@1 85.930 	Validation Prec@5 98.630 

2025-05-20 11:59:09 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:59:09 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:59:09 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:59:09 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:59:10 - INFO - TRAINING - Epoch: [60][0/196]	Time 0.941 (0.941)	Data 0.792 (0.792)	Loss 0.4962 (0.4962)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
2025-05-20 11:59:11 - INFO - TRAINING - Epoch: [60][10/196]	Time 0.141 (0.218)	Data 0.005 (0.077)	Loss 0.4925 (0.5108)	Prec@1 91.797 (91.158)	Prec@5 99.609 (99.787)
2025-05-20 11:59:13 - INFO - TRAINING - Epoch: [60][20/196]	Time 0.128 (0.180)	Data 0.000 (0.043)	Loss 0.5015 (0.5116)	Prec@1 91.406 (91.034)	Prec@5 99.609 (99.684)
2025-05-20 11:59:14 - INFO - TRAINING - Epoch: [60][30/196]	Time 0.149 (0.168)	Data 0.000 (0.031)	Loss 0.4823 (0.5076)	Prec@1 92.969 (91.242)	Prec@5 100.000 (99.710)
2025-05-20 11:59:16 - INFO - TRAINING - Epoch: [60][40/196]	Time 0.150 (0.163)	Data 0.011 (0.025)	Loss 0.4833 (0.5032)	Prec@1 91.406 (91.549)	Prec@5 100.000 (99.743)
2025-05-20 11:59:17 - INFO - TRAINING - Epoch: [60][50/196]	Time 0.134 (0.158)	Data 0.000 (0.021)	Loss 0.5168 (0.5035)	Prec@1 91.406 (91.536)	Prec@5 100.000 (99.724)
2025-05-20 11:59:18 - INFO - TRAINING - Epoch: [60][60/196]	Time 0.134 (0.154)	Data 0.002 (0.018)	Loss 0.5068 (0.5021)	Prec@1 91.406 (91.630)	Prec@5 99.609 (99.725)
2025-05-20 11:59:20 - INFO - TRAINING - Epoch: [60][70/196]	Time 0.145 (0.152)	Data 0.000 (0.016)	Loss 0.4945 (0.5011)	Prec@1 91.016 (91.643)	Prec@5 100.000 (99.730)
2025-05-20 11:59:21 - INFO - TRAINING - Epoch: [60][80/196]	Time 0.134 (0.150)	Data 0.000 (0.014)	Loss 0.5622 (0.5025)	Prec@1 87.891 (91.594)	Prec@5 98.828 (99.720)
2025-05-20 11:59:22 - INFO - TRAINING - Epoch: [60][90/196]	Time 0.131 (0.148)	Data 0.011 (0.013)	Loss 0.5180 (0.5022)	Prec@1 91.016 (91.599)	Prec@5 98.828 (99.708)
2025-05-20 11:59:24 - INFO - TRAINING - Epoch: [60][100/196]	Time 0.132 (0.147)	Data 0.000 (0.012)	Loss 0.5000 (0.5015)	Prec@1 91.797 (91.689)	Prec@5 98.828 (99.691)
2025-05-20 11:59:25 - INFO - TRAINING - Epoch: [60][110/196]	Time 0.134 (0.145)	Data 0.007 (0.011)	Loss 0.4952 (0.5021)	Prec@1 91.406 (91.702)	Prec@5 100.000 (99.701)
2025-05-20 11:59:27 - INFO - TRAINING - Epoch: [60][120/196]	Time 0.140 (0.145)	Data 0.007 (0.010)	Loss 0.4949 (0.5009)	Prec@1 91.797 (91.755)	Prec@5 99.219 (99.709)
2025-05-20 11:59:28 - INFO - TRAINING - Epoch: [60][130/196]	Time 0.149 (0.145)	Data 0.014 (0.010)	Loss 0.5037 (0.5012)	Prec@1 92.578 (91.710)	Prec@5 99.609 (99.711)
2025-05-20 11:59:29 - INFO - TRAINING - Epoch: [60][140/196]	Time 0.143 (0.145)	Data 0.007 (0.010)	Loss 0.5089 (0.5019)	Prec@1 93.750 (91.686)	Prec@5 100.000 (99.723)
2025-05-20 11:59:31 - INFO - TRAINING - Epoch: [60][150/196]	Time 0.134 (0.144)	Data 0.000 (0.010)	Loss 0.5022 (0.5020)	Prec@1 91.797 (91.706)	Prec@5 99.609 (99.728)
2025-05-20 11:59:32 - INFO - TRAINING - Epoch: [60][160/196]	Time 0.134 (0.144)	Data 0.000 (0.009)	Loss 0.4596 (0.5006)	Prec@1 93.750 (91.758)	Prec@5 100.000 (99.738)
2025-05-20 11:59:34 - INFO - TRAINING - Epoch: [60][170/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.4884 (0.5008)	Prec@1 91.406 (91.747)	Prec@5 100.000 (99.744)
2025-05-20 11:59:35 - INFO - TRAINING - Epoch: [60][180/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.4541 (0.5015)	Prec@1 94.141 (91.711)	Prec@5 100.000 (99.722)
2025-05-20 11:59:36 - INFO - TRAINING - Epoch: [60][190/196]	Time 0.133 (0.142)	Data 0.000 (0.008)	Loss 0.5055 (0.5019)	Prec@1 90.234 (91.674)	Prec@5 99.609 (99.722)
2025-05-20 11:59:38 - INFO - EVALUATING - Epoch: [60][0/40]	Time 0.646 (0.646)	Data 0.577 (0.577)	Loss 0.6438 (0.6438)	Prec@1 85.547 (85.547)	Prec@5 98.828 (98.828)
2025-05-20 11:59:38 - INFO - EVALUATING - Epoch: [60][10/40]	Time 0.071 (0.138)	Data 0.000 (0.065)	Loss 0.5435 (0.6326)	Prec@1 89.453 (85.902)	Prec@5 99.609 (98.615)
2025-05-20 11:59:39 - INFO - EVALUATING - Epoch: [60][20/40]	Time 0.080 (0.110)	Data 0.002 (0.035)	Loss 0.6213 (0.6341)	Prec@1 86.328 (86.142)	Prec@5 98.438 (98.475)
2025-05-20 11:59:40 - INFO - EVALUATING - Epoch: [60][30/40]	Time 0.071 (0.100)	Data 0.000 (0.025)	Loss 0.6911 (0.6341)	Prec@1 81.641 (85.849)	Prec@5 98.438 (98.576)
2025-05-20 11:59:41 - INFO - 
 Epoch: 61	Training Loss 0.5018 	Training Prec@1 91.690 	Training Prec@5 99.714 	Validation Loss 0.6288 	Validation Prec@1 86.200 	Validation Prec@5 98.710 

2025-05-20 11:59:41 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 11:59:41 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 11:59:41 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 11:59:41 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 11:59:42 - INFO - TRAINING - Epoch: [61][0/196]	Time 1.590 (1.590)	Data 1.462 (1.462)	Loss 0.4797 (0.4797)	Prec@1 92.969 (92.969)	Prec@5 99.219 (99.219)
2025-05-20 11:59:44 - INFO - TRAINING - Epoch: [61][10/196]	Time 0.142 (0.274)	Data 0.004 (0.138)	Loss 0.4665 (0.4955)	Prec@1 93.750 (92.223)	Prec@5 100.000 (99.680)
2025-05-20 11:59:45 - INFO - TRAINING - Epoch: [61][20/196]	Time 0.133 (0.207)	Data 0.000 (0.074)	Loss 0.5978 (0.5043)	Prec@1 87.891 (91.908)	Prec@5 99.219 (99.647)
2025-05-20 11:59:47 - INFO - TRAINING - Epoch: [61][30/196]	Time 0.133 (0.184)	Data 0.006 (0.051)	Loss 0.4527 (0.4961)	Prec@1 93.750 (92.074)	Prec@5 99.609 (99.609)
2025-05-20 11:59:48 - INFO - TRAINING - Epoch: [61][40/196]	Time 0.134 (0.172)	Data 0.010 (0.039)	Loss 0.4963 (0.4969)	Prec@1 91.797 (92.226)	Prec@5 100.000 (99.647)
2025-05-20 11:59:49 - INFO - TRAINING - Epoch: [61][50/196]	Time 0.135 (0.164)	Data 0.007 (0.032)	Loss 0.5272 (0.4973)	Prec@1 91.406 (92.134)	Prec@5 99.219 (99.648)
2025-05-20 11:59:51 - INFO - TRAINING - Epoch: [61][60/196]	Time 0.133 (0.159)	Data 0.007 (0.028)	Loss 0.5105 (0.4944)	Prec@1 90.625 (92.181)	Prec@5 100.000 (99.686)
2025-05-20 11:59:52 - INFO - TRAINING - Epoch: [61][70/196]	Time 0.134 (0.156)	Data 0.000 (0.024)	Loss 0.4653 (0.4964)	Prec@1 92.969 (92.138)	Prec@5 99.219 (99.675)
2025-05-20 11:59:53 - INFO - TRAINING - Epoch: [61][80/196]	Time 0.139 (0.154)	Data 0.000 (0.021)	Loss 0.5323 (0.4990)	Prec@1 91.797 (92.052)	Prec@5 100.000 (99.691)
2025-05-20 11:59:55 - INFO - TRAINING - Epoch: [61][90/196]	Time 0.157 (0.154)	Data 0.010 (0.019)	Loss 0.5375 (0.4984)	Prec@1 89.453 (92.054)	Prec@5 99.219 (99.708)
2025-05-20 11:59:56 - INFO - TRAINING - Epoch: [61][100/196]	Time 0.138 (0.153)	Data 0.007 (0.018)	Loss 0.4758 (0.4980)	Prec@1 92.188 (92.044)	Prec@5 99.609 (99.718)
2025-05-20 11:59:58 - INFO - TRAINING - Epoch: [61][110/196]	Time 0.132 (0.151)	Data 0.000 (0.017)	Loss 0.5780 (0.4982)	Prec@1 86.328 (92.043)	Prec@5 99.219 (99.715)
2025-05-20 11:59:59 - INFO - TRAINING - Epoch: [61][120/196]	Time 0.138 (0.150)	Data 0.000 (0.016)	Loss 0.5271 (0.4985)	Prec@1 90.234 (92.062)	Prec@5 99.219 (99.703)
2025-05-20 12:00:00 - INFO - TRAINING - Epoch: [61][130/196]	Time 0.133 (0.149)	Data 0.000 (0.015)	Loss 0.4934 (0.4990)	Prec@1 90.234 (92.035)	Prec@5 100.000 (99.699)
2025-05-20 12:00:02 - INFO - TRAINING - Epoch: [61][140/196]	Time 0.135 (0.147)	Data 0.000 (0.014)	Loss 0.5326 (0.4993)	Prec@1 89.844 (91.999)	Prec@5 100.000 (99.695)
2025-05-20 12:00:03 - INFO - TRAINING - Epoch: [61][150/196]	Time 0.138 (0.147)	Data 0.000 (0.013)	Loss 0.5736 (0.5002)	Prec@1 90.234 (91.970)	Prec@5 98.828 (99.692)
2025-05-20 12:00:04 - INFO - TRAINING - Epoch: [61][160/196]	Time 0.135 (0.146)	Data 0.000 (0.013)	Loss 0.5004 (0.4994)	Prec@1 92.188 (92.003)	Prec@5 99.219 (99.689)
2025-05-20 12:00:06 - INFO - TRAINING - Epoch: [61][170/196]	Time 0.136 (0.145)	Data 0.000 (0.012)	Loss 0.5012 (0.4998)	Prec@1 94.141 (91.989)	Prec@5 99.609 (99.692)
2025-05-20 12:00:07 - INFO - TRAINING - Epoch: [61][180/196]	Time 0.151 (0.145)	Data 0.000 (0.012)	Loss 0.5082 (0.5002)	Prec@1 92.188 (91.976)	Prec@5 100.000 (99.687)
2025-05-20 12:00:08 - INFO - TRAINING - Epoch: [61][190/196]	Time 0.132 (0.144)	Data 0.000 (0.011)	Loss 0.4719 (0.4999)	Prec@1 92.188 (91.963)	Prec@5 99.609 (99.693)
2025-05-20 12:00:10 - INFO - EVALUATING - Epoch: [61][0/40]	Time 0.702 (0.702)	Data 0.632 (0.632)	Loss 0.6590 (0.6590)	Prec@1 85.547 (85.547)	Prec@5 97.656 (97.656)
2025-05-20 12:00:11 - INFO - EVALUATING - Epoch: [61][10/40]	Time 0.076 (0.148)	Data 0.006 (0.076)	Loss 0.6123 (0.6247)	Prec@1 84.766 (86.151)	Prec@5 99.219 (98.828)
2025-05-20 12:00:12 - INFO - EVALUATING - Epoch: [61][20/40]	Time 0.074 (0.114)	Data 0.004 (0.041)	Loss 0.5858 (0.6293)	Prec@1 87.891 (86.086)	Prec@5 98.438 (98.493)
2025-05-20 12:00:12 - INFO - EVALUATING - Epoch: [61][30/40]	Time 0.070 (0.101)	Data 0.000 (0.028)	Loss 0.6766 (0.6325)	Prec@1 83.203 (85.925)	Prec@5 99.219 (98.627)
2025-05-20 12:00:13 - INFO - 
 Epoch: 62	Training Loss 0.4999 	Training Prec@1 91.970 	Training Prec@5 99.692 	Validation Loss 0.6321 	Validation Prec@1 86.020 	Validation Prec@5 98.610 

2025-05-20 12:00:13 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:00:13 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:00:13 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:00:13 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:00:14 - INFO - TRAINING - Epoch: [62][0/196]	Time 0.958 (0.958)	Data 0.861 (0.861)	Loss 0.5072 (0.5072)	Prec@1 91.797 (91.797)	Prec@5 99.219 (99.219)
2025-05-20 12:00:16 - INFO - TRAINING - Epoch: [62][10/196]	Time 0.138 (0.217)	Data 0.005 (0.083)	Loss 0.5718 (0.5021)	Prec@1 89.062 (91.868)	Prec@5 100.000 (99.751)
2025-05-20 12:00:17 - INFO - TRAINING - Epoch: [62][20/196]	Time 0.134 (0.179)	Data 0.000 (0.046)	Loss 0.4607 (0.5006)	Prec@1 93.359 (91.741)	Prec@5 100.000 (99.740)
2025-05-20 12:00:18 - INFO - TRAINING - Epoch: [62][30/196]	Time 0.134 (0.165)	Data 0.007 (0.032)	Loss 0.4780 (0.4994)	Prec@1 95.312 (91.935)	Prec@5 99.219 (99.685)
2025-05-20 12:00:20 - INFO - TRAINING - Epoch: [62][40/196]	Time 0.136 (0.160)	Data 0.003 (0.025)	Loss 0.5505 (0.4980)	Prec@1 90.625 (92.083)	Prec@5 100.000 (99.733)
2025-05-20 12:00:21 - INFO - TRAINING - Epoch: [62][50/196]	Time 0.160 (0.157)	Data 0.000 (0.022)	Loss 0.4668 (0.4953)	Prec@1 92.969 (92.256)	Prec@5 100.000 (99.763)
2025-05-20 12:00:23 - INFO - TRAINING - Epoch: [62][60/196]	Time 0.142 (0.155)	Data 0.012 (0.019)	Loss 0.4499 (0.4949)	Prec@1 94.922 (92.239)	Prec@5 100.000 (99.744)
2025-05-20 12:00:24 - INFO - TRAINING - Epoch: [62][70/196]	Time 0.134 (0.152)	Data 0.001 (0.017)	Loss 0.5146 (0.4963)	Prec@1 92.578 (92.193)	Prec@5 100.000 (99.747)
2025-05-20 12:00:25 - INFO - TRAINING - Epoch: [62][80/196]	Time 0.134 (0.150)	Data 0.007 (0.015)	Loss 0.5047 (0.4970)	Prec@1 92.188 (92.125)	Prec@5 99.609 (99.730)
2025-05-20 12:00:27 - INFO - TRAINING - Epoch: [62][90/196]	Time 0.131 (0.148)	Data 0.008 (0.014)	Loss 0.5337 (0.4978)	Prec@1 89.453 (92.076)	Prec@5 99.219 (99.730)
2025-05-20 12:00:28 - INFO - TRAINING - Epoch: [62][100/196]	Time 0.136 (0.147)	Data 0.006 (0.013)	Loss 0.5155 (0.4978)	Prec@1 91.016 (92.048)	Prec@5 98.828 (99.725)
2025-05-20 12:00:29 - INFO - TRAINING - Epoch: [62][110/196]	Time 0.133 (0.146)	Data 0.000 (0.012)	Loss 0.5010 (0.4973)	Prec@1 90.234 (92.064)	Prec@5 100.000 (99.736)
2025-05-20 12:00:31 - INFO - TRAINING - Epoch: [62][120/196]	Time 0.134 (0.145)	Data 0.000 (0.011)	Loss 0.5720 (0.4978)	Prec@1 88.672 (92.045)	Prec@5 98.828 (99.726)
2025-05-20 12:00:32 - INFO - TRAINING - Epoch: [62][130/196]	Time 0.146 (0.144)	Data 0.011 (0.011)	Loss 0.4704 (0.4987)	Prec@1 94.141 (92.003)	Prec@5 100.000 (99.735)
2025-05-20 12:00:33 - INFO - TRAINING - Epoch: [62][140/196]	Time 0.158 (0.144)	Data 0.000 (0.010)	Loss 0.4958 (0.4971)	Prec@1 92.969 (92.093)	Prec@5 99.609 (99.742)
2025-05-20 12:00:35 - INFO - TRAINING - Epoch: [62][150/196]	Time 0.151 (0.144)	Data 0.007 (0.010)	Loss 0.5358 (0.4969)	Prec@1 89.844 (92.071)	Prec@5 100.000 (99.731)
2025-05-20 12:00:36 - INFO - TRAINING - Epoch: [62][160/196]	Time 0.133 (0.144)	Data 0.007 (0.010)	Loss 0.5078 (0.4976)	Prec@1 92.188 (92.015)	Prec@5 99.219 (99.723)
2025-05-20 12:00:38 - INFO - TRAINING - Epoch: [62][170/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.5348 (0.4978)	Prec@1 89.062 (92.016)	Prec@5 99.609 (99.717)
2025-05-20 12:00:39 - INFO - TRAINING - Epoch: [62][180/196]	Time 0.132 (0.143)	Data 0.000 (0.009)	Loss 0.4551 (0.4976)	Prec@1 94.922 (92.045)	Prec@5 100.000 (99.717)
2025-05-20 12:00:40 - INFO - TRAINING - Epoch: [62][190/196]	Time 0.133 (0.142)	Data 0.000 (0.008)	Loss 0.4769 (0.4971)	Prec@1 92.188 (92.087)	Prec@5 100.000 (99.720)
2025-05-20 12:00:42 - INFO - EVALUATING - Epoch: [62][0/40]	Time 0.629 (0.629)	Data 0.549 (0.549)	Loss 0.6097 (0.6097)	Prec@1 86.719 (86.719)	Prec@5 98.828 (98.828)
2025-05-20 12:00:43 - INFO - EVALUATING - Epoch: [62][10/40]	Time 0.074 (0.144)	Data 0.000 (0.068)	Loss 0.6011 (0.6314)	Prec@1 86.719 (85.440)	Prec@5 98.438 (98.722)
2025-05-20 12:00:43 - INFO - EVALUATING - Epoch: [62][20/40]	Time 0.079 (0.113)	Data 0.000 (0.038)	Loss 0.6576 (0.6350)	Prec@1 82.812 (85.547)	Prec@5 98.438 (98.438)
2025-05-20 12:00:44 - INFO - EVALUATING - Epoch: [62][30/40]	Time 0.070 (0.100)	Data 0.000 (0.026)	Loss 0.7029 (0.6366)	Prec@1 82.812 (85.622)	Prec@5 97.656 (98.450)
2025-05-20 12:00:45 - INFO - 
 Epoch: 63	Training Loss 0.4976 	Training Prec@1 92.062 	Training Prec@5 99.714 	Validation Loss 0.6357 	Validation Prec@1 85.570 	Validation Prec@5 98.460 

2025-05-20 12:00:45 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:00:45 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:00:45 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:00:45 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:00:46 - INFO - TRAINING - Epoch: [63][0/196]	Time 1.133 (1.133)	Data 0.973 (0.973)	Loss 0.5229 (0.5229)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
2025-05-20 12:00:48 - INFO - TRAINING - Epoch: [63][10/196]	Time 0.155 (0.257)	Data 0.000 (0.110)	Loss 0.5079 (0.5077)	Prec@1 91.016 (91.264)	Prec@5 99.609 (99.645)
2025-05-20 12:00:49 - INFO - TRAINING - Epoch: [63][20/196]	Time 0.147 (0.208)	Data 0.009 (0.060)	Loss 0.4531 (0.5010)	Prec@1 94.922 (91.890)	Prec@5 99.609 (99.721)
2025-05-20 12:00:51 - INFO - TRAINING - Epoch: [63][30/196]	Time 0.142 (0.186)	Data 0.000 (0.043)	Loss 0.5755 (0.5027)	Prec@1 87.891 (91.759)	Prec@5 99.609 (99.672)
2025-05-20 12:00:52 - INFO - TRAINING - Epoch: [63][40/196]	Time 0.133 (0.173)	Data 0.000 (0.034)	Loss 0.5159 (0.5023)	Prec@1 91.016 (91.864)	Prec@5 100.000 (99.676)
2025-05-20 12:00:53 - INFO - TRAINING - Epoch: [63][50/196]	Time 0.118 (0.166)	Data 0.000 (0.028)	Loss 0.4957 (0.5019)	Prec@1 94.141 (91.904)	Prec@5 99.609 (99.671)
2025-05-20 12:00:55 - INFO - TRAINING - Epoch: [63][60/196]	Time 0.134 (0.161)	Data 0.000 (0.023)	Loss 0.4939 (0.5007)	Prec@1 92.188 (91.995)	Prec@5 99.609 (99.641)
2025-05-20 12:00:56 - INFO - TRAINING - Epoch: [63][70/196]	Time 0.133 (0.157)	Data 0.001 (0.021)	Loss 0.5443 (0.5008)	Prec@1 90.234 (91.951)	Prec@5 98.828 (99.642)
2025-05-20 12:00:57 - INFO - TRAINING - Epoch: [63][80/196]	Time 0.133 (0.155)	Data 0.000 (0.019)	Loss 0.4585 (0.4987)	Prec@1 93.750 (92.081)	Prec@5 100.000 (99.653)
2025-05-20 12:00:59 - INFO - TRAINING - Epoch: [63][90/196]	Time 0.134 (0.152)	Data 0.000 (0.017)	Loss 0.5137 (0.4998)	Prec@1 89.844 (92.012)	Prec@5 100.000 (99.657)
2025-05-20 12:01:00 - INFO - TRAINING - Epoch: [63][100/196]	Time 0.153 (0.151)	Data 0.007 (0.016)	Loss 0.4711 (0.4996)	Prec@1 93.359 (92.002)	Prec@5 99.609 (99.656)
2025-05-20 12:01:02 - INFO - TRAINING - Epoch: [63][110/196]	Time 0.142 (0.151)	Data 0.004 (0.015)	Loss 0.4853 (0.4998)	Prec@1 94.531 (91.955)	Prec@5 100.000 (99.669)
2025-05-20 12:01:03 - INFO - TRAINING - Epoch: [63][120/196]	Time 0.133 (0.150)	Data 0.000 (0.014)	Loss 0.4878 (0.5006)	Prec@1 92.188 (91.884)	Prec@5 99.219 (99.674)
2025-05-20 12:01:04 - INFO - TRAINING - Epoch: [63][130/196]	Time 0.135 (0.149)	Data 0.000 (0.013)	Loss 0.4600 (0.5000)	Prec@1 93.750 (91.928)	Prec@5 99.609 (99.681)
2025-05-20 12:01:06 - INFO - TRAINING - Epoch: [63][140/196]	Time 0.134 (0.148)	Data 0.000 (0.012)	Loss 0.5264 (0.4998)	Prec@1 91.016 (91.938)	Prec@5 100.000 (99.681)
2025-05-20 12:01:07 - INFO - TRAINING - Epoch: [63][150/196]	Time 0.134 (0.147)	Data 0.000 (0.012)	Loss 0.4689 (0.4987)	Prec@1 92.578 (91.983)	Prec@5 100.000 (99.697)
2025-05-20 12:01:08 - INFO - TRAINING - Epoch: [63][160/196]	Time 0.133 (0.146)	Data 0.000 (0.011)	Loss 0.5022 (0.4991)	Prec@1 92.188 (91.969)	Prec@5 100.000 (99.697)
2025-05-20 12:01:10 - INFO - TRAINING - Epoch: [63][170/196]	Time 0.132 (0.145)	Data 0.000 (0.011)	Loss 0.4737 (0.4995)	Prec@1 92.188 (91.952)	Prec@5 100.000 (99.708)
2025-05-20 12:01:11 - INFO - TRAINING - Epoch: [63][180/196]	Time 0.133 (0.145)	Data 0.000 (0.010)	Loss 0.5420 (0.4996)	Prec@1 89.062 (91.965)	Prec@5 98.828 (99.709)
2025-05-20 12:01:12 - INFO - TRAINING - Epoch: [63][190/196]	Time 0.134 (0.144)	Data 0.000 (0.010)	Loss 0.4873 (0.4986)	Prec@1 92.969 (92.014)	Prec@5 100.000 (99.705)
2025-05-20 12:01:15 - INFO - EVALUATING - Epoch: [63][0/40]	Time 1.249 (1.249)	Data 1.174 (1.174)	Loss 0.6303 (0.6303)	Prec@1 84.766 (84.766)	Prec@5 98.828 (98.828)
2025-05-20 12:01:15 - INFO - EVALUATING - Epoch: [63][10/40]	Time 0.074 (0.183)	Data 0.006 (0.109)	Loss 0.5832 (0.6313)	Prec@1 89.453 (85.582)	Prec@5 98.828 (98.651)
2025-05-20 12:01:16 - INFO - EVALUATING - Epoch: [63][20/40]	Time 0.077 (0.134)	Data 0.009 (0.060)	Loss 0.6292 (0.6376)	Prec@1 87.500 (85.677)	Prec@5 98.438 (98.326)
2025-05-20 12:01:17 - INFO - EVALUATING - Epoch: [63][30/40]	Time 0.069 (0.115)	Data 0.000 (0.041)	Loss 0.6602 (0.6396)	Prec@1 85.156 (85.837)	Prec@5 98.438 (98.463)
2025-05-20 12:01:18 - INFO - 
 Epoch: 64	Training Loss 0.4985 	Training Prec@1 92.020 	Training Prec@5 99.706 	Validation Loss 0.6370 	Validation Prec@1 85.960 	Validation Prec@5 98.540 

2025-05-20 12:01:18 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:01:18 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:01:18 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:01:18 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:01:18 - INFO - TRAINING - Epoch: [64][0/196]	Time 0.814 (0.814)	Data 0.709 (0.709)	Loss 0.5127 (0.5127)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
2025-05-20 12:01:20 - INFO - TRAINING - Epoch: [64][10/196]	Time 0.136 (0.223)	Data 0.005 (0.091)	Loss 0.5241 (0.4949)	Prec@1 91.797 (92.045)	Prec@5 98.828 (99.645)
2025-05-20 12:01:21 - INFO - TRAINING - Epoch: [64][20/196]	Time 0.134 (0.184)	Data 0.000 (0.049)	Loss 0.5338 (0.4902)	Prec@1 90.234 (92.206)	Prec@5 99.609 (99.740)
2025-05-20 12:01:23 - INFO - TRAINING - Epoch: [64][30/196]	Time 0.134 (0.168)	Data 0.007 (0.034)	Loss 0.4608 (0.4877)	Prec@1 94.141 (92.377)	Prec@5 99.219 (99.735)
2025-05-20 12:01:24 - INFO - TRAINING - Epoch: [64][40/196]	Time 0.144 (0.160)	Data 0.006 (0.026)	Loss 0.4877 (0.4882)	Prec@1 92.188 (92.454)	Prec@5 100.000 (99.743)
2025-05-20 12:01:26 - INFO - TRAINING - Epoch: [64][50/196]	Time 0.138 (0.157)	Data 0.000 (0.023)	Loss 0.5102 (0.4905)	Prec@1 90.234 (92.371)	Prec@5 100.000 (99.770)
2025-05-20 12:01:27 - INFO - TRAINING - Epoch: [64][60/196]	Time 0.150 (0.155)	Data 0.000 (0.020)	Loss 0.4958 (0.4899)	Prec@1 93.750 (92.392)	Prec@5 100.000 (99.769)
2025-05-20 12:01:29 - INFO - TRAINING - Epoch: [64][70/196]	Time 0.134 (0.154)	Data 0.000 (0.018)	Loss 0.4553 (0.4909)	Prec@1 92.578 (92.320)	Prec@5 99.609 (99.763)
2025-05-20 12:01:30 - INFO - TRAINING - Epoch: [64][80/196]	Time 0.134 (0.151)	Data 0.007 (0.016)	Loss 0.4656 (0.4912)	Prec@1 92.969 (92.347)	Prec@5 100.000 (99.778)
2025-05-20 12:01:31 - INFO - TRAINING - Epoch: [64][90/196]	Time 0.138 (0.149)	Data 0.007 (0.015)	Loss 0.4883 (0.4914)	Prec@1 92.188 (92.295)	Prec@5 99.609 (99.785)
2025-05-20 12:01:33 - INFO - TRAINING - Epoch: [64][100/196]	Time 0.134 (0.148)	Data 0.000 (0.014)	Loss 0.4710 (0.4910)	Prec@1 92.188 (92.276)	Prec@5 100.000 (99.783)
2025-05-20 12:01:34 - INFO - TRAINING - Epoch: [64][110/196]	Time 0.134 (0.146)	Data 0.007 (0.013)	Loss 0.4622 (0.4908)	Prec@1 93.750 (92.272)	Prec@5 100.000 (99.799)
2025-05-20 12:01:35 - INFO - TRAINING - Epoch: [64][120/196]	Time 0.134 (0.146)	Data 0.006 (0.012)	Loss 0.5066 (0.4914)	Prec@1 91.406 (92.213)	Prec@5 100.000 (99.800)
2025-05-20 12:01:37 - INFO - TRAINING - Epoch: [64][130/196]	Time 0.134 (0.145)	Data 0.002 (0.011)	Loss 0.5310 (0.4920)	Prec@1 90.234 (92.158)	Prec@5 99.609 (99.797)
2025-05-20 12:01:38 - INFO - TRAINING - Epoch: [64][140/196]	Time 0.137 (0.144)	Data 0.017 (0.010)	Loss 0.5103 (0.4915)	Prec@1 90.234 (92.199)	Prec@5 100.000 (99.789)
2025-05-20 12:01:39 - INFO - TRAINING - Epoch: [64][150/196]	Time 0.147 (0.144)	Data 0.012 (0.010)	Loss 0.5019 (0.4920)	Prec@1 90.234 (92.149)	Prec@5 100.000 (99.778)
2025-05-20 12:01:41 - INFO - TRAINING - Epoch: [64][160/196]	Time 0.138 (0.144)	Data 0.015 (0.010)	Loss 0.5031 (0.4918)	Prec@1 90.234 (92.161)	Prec@5 99.609 (99.767)
2025-05-20 12:01:42 - INFO - TRAINING - Epoch: [64][170/196]	Time 0.135 (0.144)	Data 0.000 (0.010)	Loss 0.5093 (0.4917)	Prec@1 91.016 (92.178)	Prec@5 99.609 (99.769)
2025-05-20 12:01:44 - INFO - TRAINING - Epoch: [64][180/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.4667 (0.4914)	Prec@1 95.312 (92.209)	Prec@5 99.609 (99.769)
2025-05-20 12:01:45 - INFO - TRAINING - Epoch: [64][190/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.4479 (0.4917)	Prec@1 94.922 (92.181)	Prec@5 100.000 (99.763)
2025-05-20 12:01:46 - INFO - EVALUATING - Epoch: [64][0/40]	Time 0.690 (0.690)	Data 0.619 (0.619)	Loss 0.6000 (0.6000)	Prec@1 87.891 (87.891)	Prec@5 99.219 (99.219)
2025-05-20 12:01:47 - INFO - EVALUATING - Epoch: [64][10/40]	Time 0.083 (0.138)	Data 0.010 (0.066)	Loss 0.5765 (0.6407)	Prec@1 89.062 (86.009)	Prec@5 99.609 (98.722)
2025-05-20 12:01:48 - INFO - EVALUATING - Epoch: [64][20/40]	Time 0.072 (0.110)	Data 0.002 (0.036)	Loss 0.6044 (0.6424)	Prec@1 85.938 (85.975)	Prec@5 99.609 (98.512)
2025-05-20 12:01:49 - INFO - EVALUATING - Epoch: [64][30/40]	Time 0.070 (0.099)	Data 0.000 (0.025)	Loss 0.7028 (0.6443)	Prec@1 82.031 (85.912)	Prec@5 98.047 (98.601)
2025-05-20 12:01:49 - INFO - 
 Epoch: 65	Training Loss 0.4922 	Training Prec@1 92.154 	Training Prec@5 99.760 	Validation Loss 0.6423 	Validation Prec@1 85.920 	Validation Prec@5 98.670 

2025-05-20 12:01:49 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:01:49 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:01:49 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:01:49 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:01:50 - INFO - TRAINING - Epoch: [65][0/196]	Time 0.883 (0.883)	Data 0.747 (0.747)	Loss 0.4806 (0.4806)	Prec@1 92.578 (92.578)	Prec@5 99.609 (99.609)
2025-05-20 12:01:52 - INFO - TRAINING - Epoch: [65][10/196]	Time 0.154 (0.223)	Data 0.028 (0.076)	Loss 0.4666 (0.4884)	Prec@1 94.141 (92.472)	Prec@5 100.000 (99.680)
2025-05-20 12:01:53 - INFO - TRAINING - Epoch: [65][20/196]	Time 0.143 (0.190)	Data 0.000 (0.043)	Loss 0.4846 (0.4908)	Prec@1 92.969 (92.392)	Prec@5 99.609 (99.740)
2025-05-20 12:01:55 - INFO - TRAINING - Epoch: [65][30/196]	Time 0.146 (0.181)	Data 0.011 (0.033)	Loss 0.5112 (0.4937)	Prec@1 90.625 (92.162)	Prec@5 100.000 (99.761)
2025-05-20 12:01:56 - INFO - TRAINING - Epoch: [65][40/196]	Time 0.133 (0.172)	Data 0.000 (0.026)	Loss 0.4781 (0.4968)	Prec@1 94.141 (92.168)	Prec@5 99.219 (99.705)
2025-05-20 12:01:58 - INFO - TRAINING - Epoch: [65][50/196]	Time 0.137 (0.164)	Data 0.000 (0.022)	Loss 0.4993 (0.4951)	Prec@1 92.578 (92.195)	Prec@5 99.609 (99.732)
2025-05-20 12:01:59 - INFO - TRAINING - Epoch: [65][60/196]	Time 0.134 (0.159)	Data 0.004 (0.018)	Loss 0.5470 (0.4977)	Prec@1 89.844 (92.066)	Prec@5 99.609 (99.731)
2025-05-20 12:02:00 - INFO - TRAINING - Epoch: [65][70/196]	Time 0.133 (0.156)	Data 0.004 (0.016)	Loss 0.4866 (0.4983)	Prec@1 91.406 (91.945)	Prec@5 99.219 (99.708)
2025-05-20 12:02:02 - INFO - TRAINING - Epoch: [65][80/196]	Time 0.135 (0.153)	Data 0.000 (0.015)	Loss 0.5268 (0.4982)	Prec@1 89.453 (91.956)	Prec@5 99.609 (99.720)
2025-05-20 12:02:03 - INFO - TRAINING - Epoch: [65][90/196]	Time 0.133 (0.151)	Data 0.007 (0.013)	Loss 0.5444 (0.4983)	Prec@1 88.672 (91.956)	Prec@5 99.219 (99.717)
2025-05-20 12:02:05 - INFO - TRAINING - Epoch: [65][100/196]	Time 0.149 (0.150)	Data 0.000 (0.012)	Loss 0.5001 (0.4966)	Prec@1 91.406 (92.033)	Prec@5 99.609 (99.722)
2025-05-20 12:02:06 - INFO - TRAINING - Epoch: [65][110/196]	Time 0.156 (0.149)	Data 0.014 (0.012)	Loss 0.4986 (0.4965)	Prec@1 92.578 (92.057)	Prec@5 99.609 (99.729)
2025-05-20 12:02:07 - INFO - TRAINING - Epoch: [65][120/196]	Time 0.135 (0.149)	Data 0.005 (0.011)	Loss 0.4714 (0.4959)	Prec@1 93.750 (92.110)	Prec@5 100.000 (99.726)
2025-05-20 12:02:09 - INFO - TRAINING - Epoch: [65][130/196]	Time 0.135 (0.148)	Data 0.008 (0.011)	Loss 0.4886 (0.4949)	Prec@1 91.406 (92.140)	Prec@5 100.000 (99.729)
2025-05-20 12:02:10 - INFO - TRAINING - Epoch: [65][140/196]	Time 0.135 (0.147)	Data 0.008 (0.010)	Loss 0.5202 (0.4946)	Prec@1 91.016 (92.138)	Prec@5 100.000 (99.737)
2025-05-20 12:02:12 - INFO - TRAINING - Epoch: [65][150/196]	Time 0.135 (0.146)	Data 0.000 (0.010)	Loss 0.4747 (0.4948)	Prec@1 93.750 (92.123)	Prec@5 99.609 (99.736)
2025-05-20 12:02:13 - INFO - TRAINING - Epoch: [65][160/196]	Time 0.133 (0.145)	Data 0.012 (0.009)	Loss 0.4809 (0.4954)	Prec@1 92.188 (92.078)	Prec@5 99.609 (99.733)
2025-05-20 12:02:14 - INFO - TRAINING - Epoch: [65][170/196]	Time 0.134 (0.145)	Data 0.000 (0.009)	Loss 0.4909 (0.4956)	Prec@1 91.406 (92.060)	Prec@5 99.609 (99.730)
2025-05-20 12:02:16 - INFO - TRAINING - Epoch: [65][180/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.4991 (0.4950)	Prec@1 91.406 (92.064)	Prec@5 99.219 (99.730)
2025-05-20 12:02:17 - INFO - TRAINING - Epoch: [65][190/196]	Time 0.133 (0.144)	Data 0.000 (0.008)	Loss 0.5480 (0.4960)	Prec@1 89.062 (92.008)	Prec@5 98.828 (99.724)
2025-05-20 12:02:19 - INFO - EVALUATING - Epoch: [65][0/40]	Time 1.342 (1.342)	Data 1.226 (1.226)	Loss 0.6103 (0.6103)	Prec@1 87.109 (87.109)	Prec@5 98.438 (98.438)
2025-05-20 12:02:20 - INFO - EVALUATING - Epoch: [65][10/40]	Time 0.095 (0.203)	Data 0.012 (0.121)	Loss 0.5801 (0.6457)	Prec@1 89.062 (85.689)	Prec@5 98.828 (98.580)
2025-05-20 12:02:21 - INFO - EVALUATING - Epoch: [65][20/40]	Time 0.073 (0.144)	Data 0.000 (0.065)	Loss 0.6421 (0.6502)	Prec@1 87.109 (85.733)	Prec@5 98.828 (98.382)
2025-05-20 12:02:21 - INFO - EVALUATING - Epoch: [65][30/40]	Time 0.080 (0.122)	Data 0.000 (0.044)	Loss 0.6436 (0.6531)	Prec@1 86.719 (85.446)	Prec@5 99.219 (98.551)
2025-05-20 12:02:22 - INFO - 
 Epoch: 66	Training Loss 0.4963 	Training Prec@1 92.008 	Training Prec@5 99.722 	Validation Loss 0.6486 	Validation Prec@1 85.710 	Validation Prec@5 98.630 

2025-05-20 12:02:22 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:02:22 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:02:22 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:02:22 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:02:23 - INFO - TRAINING - Epoch: [66][0/196]	Time 0.958 (0.958)	Data 0.847 (0.847)	Loss 0.4961 (0.4961)	Prec@1 91.797 (91.797)	Prec@5 99.219 (99.219)
2025-05-20 12:02:25 - INFO - TRAINING - Epoch: [66][10/196]	Time 0.146 (0.216)	Data 0.008 (0.083)	Loss 0.5042 (0.4778)	Prec@1 91.406 (93.146)	Prec@5 100.000 (99.822)
2025-05-20 12:02:26 - INFO - TRAINING - Epoch: [66][20/196]	Time 0.140 (0.181)	Data 0.005 (0.046)	Loss 0.4618 (0.4798)	Prec@1 92.969 (92.950)	Prec@5 99.609 (99.777)
2025-05-20 12:02:27 - INFO - TRAINING - Epoch: [66][30/196]	Time 0.133 (0.166)	Data 0.007 (0.032)	Loss 0.4794 (0.4822)	Prec@1 92.578 (92.931)	Prec@5 100.000 (99.786)
2025-05-20 12:02:29 - INFO - TRAINING - Epoch: [66][40/196]	Time 0.132 (0.159)	Data 0.002 (0.025)	Loss 0.5001 (0.4846)	Prec@1 90.625 (92.607)	Prec@5 99.609 (99.762)
2025-05-20 12:02:30 - INFO - TRAINING - Epoch: [66][50/196]	Time 0.136 (0.154)	Data 0.008 (0.020)	Loss 0.4804 (0.4876)	Prec@1 91.797 (92.502)	Prec@5 100.000 (99.732)
2025-05-20 12:02:32 - INFO - TRAINING - Epoch: [66][60/196]	Time 0.136 (0.153)	Data 0.011 (0.017)	Loss 0.5301 (0.4874)	Prec@1 89.844 (92.469)	Prec@5 100.000 (99.744)
2025-05-20 12:02:33 - INFO - TRAINING - Epoch: [66][70/196]	Time 0.149 (0.152)	Data 0.022 (0.017)	Loss 0.4776 (0.4880)	Prec@1 92.578 (92.452)	Prec@5 100.000 (99.747)
2025-05-20 12:02:34 - INFO - TRAINING - Epoch: [66][80/196]	Time 0.135 (0.150)	Data 0.000 (0.015)	Loss 0.4943 (0.4896)	Prec@1 91.406 (92.361)	Prec@5 99.609 (99.730)
2025-05-20 12:02:36 - INFO - TRAINING - Epoch: [66][90/196]	Time 0.133 (0.148)	Data 0.000 (0.014)	Loss 0.4893 (0.4911)	Prec@1 94.141 (92.325)	Prec@5 99.609 (99.717)
2025-05-20 12:02:37 - INFO - TRAINING - Epoch: [66][100/196]	Time 0.134 (0.147)	Data 0.001 (0.012)	Loss 0.4941 (0.4931)	Prec@1 92.188 (92.207)	Prec@5 99.609 (99.729)
2025-05-20 12:02:38 - INFO - TRAINING - Epoch: [66][110/196]	Time 0.134 (0.146)	Data 0.000 (0.011)	Loss 0.4980 (0.4912)	Prec@1 92.969 (92.311)	Prec@5 99.219 (99.729)
2025-05-20 12:02:40 - INFO - TRAINING - Epoch: [66][120/196]	Time 0.134 (0.145)	Data 0.000 (0.011)	Loss 0.4929 (0.4908)	Prec@1 91.406 (92.342)	Prec@5 99.609 (99.745)
2025-05-20 12:02:41 - INFO - TRAINING - Epoch: [66][130/196]	Time 0.133 (0.144)	Data 0.008 (0.010)	Loss 0.5100 (0.4906)	Prec@1 91.406 (92.343)	Prec@5 99.609 (99.741)
2025-05-20 12:02:42 - INFO - TRAINING - Epoch: [66][140/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.5473 (0.4914)	Prec@1 88.672 (92.298)	Prec@5 99.219 (99.740)
2025-05-20 12:02:44 - INFO - TRAINING - Epoch: [66][150/196]	Time 0.145 (0.143)	Data 0.003 (0.009)	Loss 0.5179 (0.4923)	Prec@1 91.406 (92.224)	Prec@5 99.219 (99.723)
2025-05-20 12:02:45 - INFO - TRAINING - Epoch: [66][160/196]	Time 0.155 (0.143)	Data 0.019 (0.009)	Loss 0.5074 (0.4925)	Prec@1 91.797 (92.204)	Prec@5 99.609 (99.721)
2025-05-20 12:02:47 - INFO - TRAINING - Epoch: [66][170/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.4984 (0.4931)	Prec@1 92.188 (92.165)	Prec@5 100.000 (99.724)
2025-05-20 12:02:48 - INFO - TRAINING - Epoch: [66][180/196]	Time 0.132 (0.143)	Data 0.000 (0.008)	Loss 0.4788 (0.4935)	Prec@1 92.578 (92.162)	Prec@5 99.609 (99.719)
2025-05-20 12:02:49 - INFO - TRAINING - Epoch: [66][190/196]	Time 0.132 (0.142)	Data 0.000 (0.008)	Loss 0.4700 (0.4939)	Prec@1 93.750 (92.153)	Prec@5 100.000 (99.720)
2025-05-20 12:02:51 - INFO - EVALUATING - Epoch: [66][0/40]	Time 0.634 (0.634)	Data 0.561 (0.561)	Loss 0.6097 (0.6097)	Prec@1 87.500 (87.500)	Prec@5 98.828 (98.828)
2025-05-20 12:02:52 - INFO - EVALUATING - Epoch: [66][10/40]	Time 0.074 (0.145)	Data 0.000 (0.072)	Loss 0.6382 (0.6215)	Prec@1 85.156 (85.938)	Prec@5 98.828 (98.686)
2025-05-20 12:02:52 - INFO - EVALUATING - Epoch: [66][20/40]	Time 0.074 (0.113)	Data 0.000 (0.040)	Loss 0.6123 (0.6286)	Prec@1 87.109 (86.031)	Prec@5 99.609 (98.661)
2025-05-20 12:02:53 - INFO - EVALUATING - Epoch: [66][30/40]	Time 0.070 (0.100)	Data 0.000 (0.027)	Loss 0.6300 (0.6305)	Prec@1 86.719 (86.127)	Prec@5 99.609 (98.778)
2025-05-20 12:02:54 - INFO - 
 Epoch: 67	Training Loss 0.4936 	Training Prec@1 92.170 	Training Prec@5 99.722 	Validation Loss 0.6278 	Validation Prec@1 86.260 	Validation Prec@5 98.800 

2025-05-20 12:02:54 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:02:54 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:02:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:02:54 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:02:55 - INFO - TRAINING - Epoch: [67][0/196]	Time 1.018 (1.018)	Data 0.896 (0.896)	Loss 0.4876 (0.4876)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
2025-05-20 12:02:57 - INFO - TRAINING - Epoch: [67][10/196]	Time 0.171 (0.224)	Data 0.000 (0.083)	Loss 0.4730 (0.4978)	Prec@1 93.750 (91.832)	Prec@5 100.000 (99.822)
2025-05-20 12:02:58 - INFO - TRAINING - Epoch: [67][20/196]	Time 0.151 (0.192)	Data 0.003 (0.046)	Loss 0.5156 (0.4970)	Prec@1 90.625 (91.927)	Prec@5 99.609 (99.740)
2025-05-20 12:03:00 - INFO - TRAINING - Epoch: [67][30/196]	Time 0.159 (0.181)	Data 0.012 (0.035)	Loss 0.4669 (0.4939)	Prec@1 92.578 (91.973)	Prec@5 100.000 (99.748)
2025-05-20 12:03:01 - INFO - TRAINING - Epoch: [67][40/196]	Time 0.134 (0.171)	Data 0.000 (0.028)	Loss 0.4892 (0.4921)	Prec@1 91.016 (91.968)	Prec@5 99.609 (99.762)
2025-05-20 12:03:02 - INFO - TRAINING - Epoch: [67][50/196]	Time 0.133 (0.164)	Data 0.000 (0.023)	Loss 0.4846 (0.4895)	Prec@1 92.188 (92.203)	Prec@5 100.000 (99.778)
2025-05-20 12:03:04 - INFO - TRAINING - Epoch: [67][60/196]	Time 0.133 (0.159)	Data 0.000 (0.020)	Loss 0.4933 (0.4872)	Prec@1 91.797 (92.360)	Prec@5 99.609 (99.776)
2025-05-20 12:03:05 - INFO - TRAINING - Epoch: [67][70/196]	Time 0.134 (0.155)	Data 0.000 (0.017)	Loss 0.4341 (0.4863)	Prec@1 94.531 (92.391)	Prec@5 100.000 (99.780)
2025-05-20 12:03:06 - INFO - TRAINING - Epoch: [67][80/196]	Time 0.133 (0.153)	Data 0.007 (0.015)	Loss 0.4678 (0.4869)	Prec@1 94.141 (92.409)	Prec@5 100.000 (99.773)
2025-05-20 12:03:08 - INFO - TRAINING - Epoch: [67][90/196]	Time 0.139 (0.151)	Data 0.000 (0.014)	Loss 0.5178 (0.4901)	Prec@1 91.797 (92.235)	Prec@5 99.609 (99.777)
2025-05-20 12:03:09 - INFO - TRAINING - Epoch: [67][100/196]	Time 0.133 (0.149)	Data 0.000 (0.013)	Loss 0.4774 (0.4910)	Prec@1 92.969 (92.265)	Prec@5 100.000 (99.780)
2025-05-20 12:03:11 - INFO - TRAINING - Epoch: [67][110/196]	Time 0.153 (0.148)	Data 0.000 (0.012)	Loss 0.4878 (0.4920)	Prec@1 92.188 (92.195)	Prec@5 100.000 (99.775)
2025-05-20 12:03:12 - INFO - TRAINING - Epoch: [67][120/196]	Time 0.160 (0.148)	Data 0.005 (0.011)	Loss 0.4700 (0.4922)	Prec@1 92.578 (92.175)	Prec@5 100.000 (99.777)
2025-05-20 12:03:13 - INFO - TRAINING - Epoch: [67][130/196]	Time 0.146 (0.147)	Data 0.000 (0.011)	Loss 0.5419 (0.4927)	Prec@1 87.891 (92.208)	Prec@5 100.000 (99.767)
2025-05-20 12:03:15 - INFO - TRAINING - Epoch: [67][140/196]	Time 0.134 (0.147)	Data 0.013 (0.011)	Loss 0.4801 (0.4926)	Prec@1 91.406 (92.212)	Prec@5 100.000 (99.759)
2025-05-20 12:03:16 - INFO - TRAINING - Epoch: [67][150/196]	Time 0.133 (0.146)	Data 0.002 (0.010)	Loss 0.4795 (0.4926)	Prec@1 93.359 (92.213)	Prec@5 100.000 (99.759)
2025-05-20 12:03:17 - INFO - TRAINING - Epoch: [67][160/196]	Time 0.134 (0.145)	Data 0.000 (0.010)	Loss 0.5171 (0.4924)	Prec@1 91.797 (92.241)	Prec@5 99.609 (99.748)
2025-05-20 12:03:19 - INFO - TRAINING - Epoch: [67][170/196]	Time 0.134 (0.144)	Data 0.000 (0.009)	Loss 0.4755 (0.4920)	Prec@1 93.359 (92.272)	Prec@5 100.000 (99.751)
2025-05-20 12:03:20 - INFO - TRAINING - Epoch: [67][180/196]	Time 0.132 (0.144)	Data 0.000 (0.009)	Loss 0.4787 (0.4921)	Prec@1 92.578 (92.252)	Prec@5 99.609 (99.745)
2025-05-20 12:03:21 - INFO - TRAINING - Epoch: [67][190/196]	Time 0.134 (0.143)	Data 0.000 (0.008)	Loss 0.5571 (0.4923)	Prec@1 90.234 (92.251)	Prec@5 99.219 (99.746)
2025-05-20 12:03:23 - INFO - EVALUATING - Epoch: [67][0/40]	Time 0.529 (0.529)	Data 0.457 (0.457)	Loss 0.5977 (0.5977)	Prec@1 88.281 (88.281)	Prec@5 98.828 (98.828)
2025-05-20 12:03:24 - INFO - EVALUATING - Epoch: [67][10/40]	Time 0.188 (0.158)	Data 0.105 (0.080)	Loss 0.6065 (0.6190)	Prec@1 87.500 (86.896)	Prec@5 99.219 (98.722)
2025-05-20 12:03:25 - INFO - EVALUATING - Epoch: [67][20/40]	Time 0.083 (0.136)	Data 0.000 (0.057)	Loss 0.6218 (0.6274)	Prec@1 85.547 (86.310)	Prec@5 98.047 (98.438)
2025-05-20 12:03:26 - INFO - EVALUATING - Epoch: [67][30/40]	Time 0.100 (0.125)	Data 0.000 (0.044)	Loss 0.6573 (0.6314)	Prec@1 83.984 (85.988)	Prec@5 99.219 (98.652)
2025-05-20 12:03:27 - INFO - 
 Epoch: 68	Training Loss 0.4924 	Training Prec@1 92.254 	Training Prec@5 99.746 	Validation Loss 0.6306 	Validation Prec@1 86.120 	Validation Prec@5 98.690 

2025-05-20 12:03:27 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:03:27 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:03:27 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:03:27 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:03:29 - INFO - TRAINING - Epoch: [68][0/196]	Time 1.647 (1.647)	Data 1.454 (1.454)	Loss 0.4742 (0.4742)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2025-05-20 12:03:30 - INFO - TRAINING - Epoch: [68][10/196]	Time 0.158 (0.290)	Data 0.001 (0.134)	Loss 0.4790 (0.4963)	Prec@1 93.750 (92.365)	Prec@5 98.438 (99.503)
2025-05-20 12:03:32 - INFO - TRAINING - Epoch: [68][20/196]	Time 0.132 (0.219)	Data 0.000 (0.073)	Loss 0.4970 (0.4983)	Prec@1 92.188 (92.281)	Prec@5 99.609 (99.572)
2025-05-20 12:03:33 - INFO - TRAINING - Epoch: [68][30/196]	Time 0.134 (0.191)	Data 0.000 (0.051)	Loss 0.5331 (0.4917)	Prec@1 90.234 (92.440)	Prec@5 100.000 (99.672)
2025-05-20 12:03:34 - INFO - TRAINING - Epoch: [68][40/196]	Time 0.134 (0.177)	Data 0.000 (0.039)	Loss 0.5076 (0.4898)	Prec@1 90.625 (92.473)	Prec@5 100.000 (99.733)
2025-05-20 12:03:36 - INFO - TRAINING - Epoch: [68][50/196]	Time 0.134 (0.169)	Data 0.000 (0.032)	Loss 0.4433 (0.4888)	Prec@1 93.750 (92.463)	Prec@5 100.000 (99.755)
2025-05-20 12:03:37 - INFO - TRAINING - Epoch: [68][60/196]	Time 0.141 (0.164)	Data 0.000 (0.027)	Loss 0.4624 (0.4881)	Prec@1 93.359 (92.527)	Prec@5 100.000 (99.769)
2025-05-20 12:03:38 - INFO - TRAINING - Epoch: [68][70/196]	Time 0.157 (0.161)	Data 0.012 (0.024)	Loss 0.5142 (0.4889)	Prec@1 91.797 (92.540)	Prec@5 99.219 (99.736)
2025-05-20 12:03:40 - INFO - TRAINING - Epoch: [68][80/196]	Time 0.138 (0.160)	Data 0.004 (0.022)	Loss 0.4838 (0.4876)	Prec@1 91.406 (92.511)	Prec@5 100.000 (99.759)
2025-05-20 12:03:41 - INFO - TRAINING - Epoch: [68][90/196]	Time 0.134 (0.157)	Data 0.007 (0.020)	Loss 0.4496 (0.4881)	Prec@1 93.750 (92.475)	Prec@5 100.000 (99.760)
2025-05-20 12:03:43 - INFO - TRAINING - Epoch: [68][100/196]	Time 0.135 (0.155)	Data 0.000 (0.019)	Loss 0.5056 (0.4898)	Prec@1 92.578 (92.412)	Prec@5 99.219 (99.752)
2025-05-20 12:03:44 - INFO - TRAINING - Epoch: [68][110/196]	Time 0.134 (0.153)	Data 0.000 (0.017)	Loss 0.5027 (0.4908)	Prec@1 92.188 (92.360)	Prec@5 99.609 (99.733)
2025-05-20 12:03:45 - INFO - TRAINING - Epoch: [68][120/196]	Time 0.134 (0.151)	Data 0.007 (0.016)	Loss 0.4959 (0.4913)	Prec@1 91.016 (92.326)	Prec@5 99.609 (99.716)
2025-05-20 12:03:47 - INFO - TRAINING - Epoch: [68][130/196]	Time 0.133 (0.150)	Data 0.007 (0.015)	Loss 0.4648 (0.4922)	Prec@1 94.531 (92.331)	Prec@5 99.609 (99.711)
2025-05-20 12:03:48 - INFO - TRAINING - Epoch: [68][140/196]	Time 0.134 (0.149)	Data 0.000 (0.014)	Loss 0.4434 (0.4918)	Prec@1 93.750 (92.323)	Prec@5 99.609 (99.704)
2025-05-20 12:03:49 - INFO - TRAINING - Epoch: [68][150/196]	Time 0.129 (0.148)	Data 0.000 (0.013)	Loss 0.5705 (0.4928)	Prec@1 89.062 (92.314)	Prec@5 99.219 (99.710)
2025-05-20 12:03:51 - INFO - TRAINING - Epoch: [68][160/196]	Time 0.142 (0.147)	Data 0.016 (0.013)	Loss 0.4586 (0.4937)	Prec@1 94.141 (92.277)	Prec@5 100.000 (99.697)
2025-05-20 12:03:52 - INFO - TRAINING - Epoch: [68][170/196]	Time 0.146 (0.147)	Data 0.018 (0.013)	Loss 0.5212 (0.4936)	Prec@1 90.625 (92.279)	Prec@5 100.000 (99.710)
2025-05-20 12:03:54 - INFO - TRAINING - Epoch: [68][180/196]	Time 0.130 (0.147)	Data 0.000 (0.013)	Loss 0.5177 (0.4941)	Prec@1 91.016 (92.250)	Prec@5 99.609 (99.713)
2025-05-20 12:03:55 - INFO - TRAINING - Epoch: [68][190/196]	Time 0.134 (0.146)	Data 0.000 (0.012)	Loss 0.4540 (0.4945)	Prec@1 93.750 (92.220)	Prec@5 99.219 (99.708)
2025-05-20 12:03:56 - INFO - EVALUATING - Epoch: [68][0/40]	Time 0.512 (0.512)	Data 0.429 (0.429)	Loss 0.5947 (0.5947)	Prec@1 89.062 (89.062)	Prec@5 98.828 (98.828)
2025-05-20 12:03:57 - INFO - EVALUATING - Epoch: [68][10/40]	Time 0.082 (0.141)	Data 0.006 (0.066)	Loss 0.6112 (0.6295)	Prec@1 86.719 (85.973)	Prec@5 98.438 (98.438)
2025-05-20 12:03:58 - INFO - EVALUATING - Epoch: [68][20/40]	Time 0.087 (0.111)	Data 0.002 (0.036)	Loss 0.6393 (0.6332)	Prec@1 85.938 (86.086)	Prec@5 100.000 (98.475)
2025-05-20 12:03:59 - INFO - EVALUATING - Epoch: [68][30/40]	Time 0.070 (0.102)	Data 0.000 (0.026)	Loss 0.6791 (0.6341)	Prec@1 83.984 (86.026)	Prec@5 99.219 (98.753)
2025-05-20 12:04:00 - INFO - 
 Epoch: 69	Training Loss 0.4942 	Training Prec@1 92.242 	Training Prec@5 99.704 	Validation Loss 0.6337 	Validation Prec@1 85.950 	Validation Prec@5 98.710 

2025-05-20 12:04:00 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:04:00 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:04:00 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:04:00 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:04:01 - INFO - TRAINING - Epoch: [69][0/196]	Time 1.138 (1.138)	Data 1.030 (1.030)	Loss 0.4988 (0.4988)	Prec@1 92.969 (92.969)	Prec@5 98.828 (98.828)
2025-05-20 12:04:02 - INFO - TRAINING - Epoch: [69][10/196]	Time 0.133 (0.233)	Data 0.011 (0.100)	Loss 0.4564 (0.4840)	Prec@1 94.922 (93.075)	Prec@5 99.609 (99.751)
2025-05-20 12:04:04 - INFO - TRAINING - Epoch: [69][20/196]	Time 0.130 (0.187)	Data 0.000 (0.054)	Loss 0.5165 (0.4888)	Prec@1 90.234 (92.969)	Prec@5 99.609 (99.740)
2025-05-20 12:04:05 - INFO - TRAINING - Epoch: [69][30/196]	Time 0.155 (0.174)	Data 0.012 (0.040)	Loss 0.4510 (0.4919)	Prec@1 92.578 (92.553)	Prec@5 100.000 (99.824)
2025-05-20 12:04:06 - INFO - TRAINING - Epoch: [69][40/196]	Time 0.135 (0.167)	Data 0.017 (0.032)	Loss 0.5247 (0.4926)	Prec@1 90.625 (92.435)	Prec@5 100.000 (99.800)
2025-05-20 12:04:08 - INFO - TRAINING - Epoch: [69][50/196]	Time 0.132 (0.161)	Data 0.000 (0.026)	Loss 0.4850 (0.4883)	Prec@1 92.578 (92.655)	Prec@5 100.000 (99.801)
2025-05-20 12:04:09 - INFO - TRAINING - Epoch: [69][60/196]	Time 0.133 (0.157)	Data 0.000 (0.022)	Loss 0.4609 (0.4860)	Prec@1 94.141 (92.783)	Prec@5 100.000 (99.782)
2025-05-20 12:04:11 - INFO - TRAINING - Epoch: [69][70/196]	Time 0.136 (0.153)	Data 0.000 (0.019)	Loss 0.4783 (0.4870)	Prec@1 94.141 (92.732)	Prec@5 100.000 (99.752)
2025-05-20 12:04:12 - INFO - TRAINING - Epoch: [69][80/196]	Time 0.134 (0.151)	Data 0.007 (0.017)	Loss 0.4683 (0.4887)	Prec@1 94.531 (92.617)	Prec@5 99.609 (99.764)
2025-05-20 12:04:13 - INFO - TRAINING - Epoch: [69][90/196]	Time 0.134 (0.149)	Data 0.000 (0.015)	Loss 0.5253 (0.4900)	Prec@1 90.234 (92.535)	Prec@5 100.000 (99.760)
2025-05-20 12:04:15 - INFO - TRAINING - Epoch: [69][100/196]	Time 0.136 (0.147)	Data 0.007 (0.014)	Loss 0.4575 (0.4912)	Prec@1 94.141 (92.489)	Prec@5 100.000 (99.768)
2025-05-20 12:04:16 - INFO - TRAINING - Epoch: [69][110/196]	Time 0.134 (0.146)	Data 0.000 (0.013)	Loss 0.4986 (0.4914)	Prec@1 91.406 (92.441)	Prec@5 99.609 (99.771)
2025-05-20 12:04:17 - INFO - TRAINING - Epoch: [69][120/196]	Time 0.142 (0.146)	Data 0.007 (0.012)	Loss 0.4840 (0.4909)	Prec@1 92.188 (92.478)	Prec@5 100.000 (99.774)
2025-05-20 12:04:19 - INFO - TRAINING - Epoch: [69][130/196]	Time 0.151 (0.145)	Data 0.000 (0.012)	Loss 0.5206 (0.4910)	Prec@1 90.234 (92.471)	Prec@5 100.000 (99.761)
2025-05-20 12:04:20 - INFO - TRAINING - Epoch: [69][140/196]	Time 0.133 (0.145)	Data 0.015 (0.012)	Loss 0.4651 (0.4915)	Prec@1 92.969 (92.437)	Prec@5 100.000 (99.770)
2025-05-20 12:04:21 - INFO - TRAINING - Epoch: [69][150/196]	Time 0.133 (0.145)	Data 0.007 (0.011)	Loss 0.4594 (0.4917)	Prec@1 92.969 (92.410)	Prec@5 100.000 (99.759)
2025-05-20 12:04:23 - INFO - TRAINING - Epoch: [69][160/196]	Time 0.133 (0.144)	Data 0.004 (0.011)	Loss 0.4745 (0.4912)	Prec@1 92.969 (92.433)	Prec@5 100.000 (99.760)
2025-05-20 12:04:24 - INFO - TRAINING - Epoch: [69][170/196]	Time 0.131 (0.143)	Data 0.000 (0.010)	Loss 0.5002 (0.4918)	Prec@1 91.797 (92.389)	Prec@5 99.609 (99.767)
2025-05-20 12:04:25 - INFO - TRAINING - Epoch: [69][180/196]	Time 0.133 (0.143)	Data 0.000 (0.010)	Loss 0.5176 (0.4919)	Prec@1 89.844 (92.373)	Prec@5 99.219 (99.763)
2025-05-20 12:04:27 - INFO - TRAINING - Epoch: [69][190/196]	Time 0.133 (0.142)	Data 0.000 (0.009)	Loss 0.5282 (0.4924)	Prec@1 91.016 (92.343)	Prec@5 99.219 (99.755)
2025-05-20 12:04:28 - INFO - EVALUATING - Epoch: [69][0/40]	Time 0.573 (0.573)	Data 0.502 (0.502)	Loss 0.5834 (0.5834)	Prec@1 88.281 (88.281)	Prec@5 98.828 (98.828)
2025-05-20 12:04:29 - INFO - EVALUATING - Epoch: [69][10/40]	Time 0.095 (0.135)	Data 0.017 (0.059)	Loss 0.6055 (0.6435)	Prec@1 87.109 (85.760)	Prec@5 99.609 (98.580)
2025-05-20 12:04:30 - INFO - EVALUATING - Epoch: [69][20/40]	Time 0.119 (0.115)	Data 0.048 (0.040)	Loss 0.6365 (0.6440)	Prec@1 86.328 (85.919)	Prec@5 98.047 (98.438)
2025-05-20 12:04:31 - INFO - EVALUATING - Epoch: [69][30/40]	Time 0.071 (0.109)	Data 0.000 (0.034)	Loss 0.6847 (0.6429)	Prec@1 83.594 (85.748)	Prec@5 97.656 (98.564)
2025-05-20 12:04:32 - INFO - 
 Epoch: 70	Training Loss 0.4926 	Training Prec@1 92.334 	Training Prec@5 99.756 	Validation Loss 0.6456 	Validation Prec@1 85.510 	Validation Prec@5 98.630 

2025-05-20 12:04:32 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:04:32 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:04:32 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:04:32 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:04:33 - INFO - TRAINING - Epoch: [70][0/196]	Time 1.168 (1.168)	Data 1.038 (1.038)	Loss 0.4862 (0.4862)	Prec@1 94.531 (94.531)	Prec@5 99.219 (99.219)
2025-05-20 12:04:34 - INFO - TRAINING - Epoch: [70][10/196]	Time 0.136 (0.235)	Data 0.013 (0.099)	Loss 0.4808 (0.4976)	Prec@1 92.969 (92.365)	Prec@5 99.609 (99.645)
2025-05-20 12:04:36 - INFO - TRAINING - Epoch: [70][20/196]	Time 0.134 (0.189)	Data 0.000 (0.055)	Loss 0.4817 (0.4914)	Prec@1 92.969 (92.429)	Prec@5 99.609 (99.777)
2025-05-20 12:04:37 - INFO - TRAINING - Epoch: [70][30/196]	Time 0.134 (0.171)	Data 0.007 (0.038)	Loss 0.5240 (0.4951)	Prec@1 89.062 (92.213)	Prec@5 100.000 (99.761)
2025-05-20 12:04:38 - INFO - TRAINING - Epoch: [70][40/196]	Time 0.133 (0.162)	Data 0.000 (0.029)	Loss 0.5169 (0.4946)	Prec@1 90.234 (92.073)	Prec@5 98.828 (99.771)
2025-05-20 12:04:40 - INFO - TRAINING - Epoch: [70][50/196]	Time 0.133 (0.156)	Data 0.000 (0.024)	Loss 0.4445 (0.4925)	Prec@1 94.922 (92.080)	Prec@5 100.000 (99.786)
2025-05-20 12:04:41 - INFO - TRAINING - Epoch: [70][60/196]	Time 0.133 (0.153)	Data 0.000 (0.020)	Loss 0.4995 (0.4917)	Prec@1 91.797 (92.136)	Prec@5 99.609 (99.769)
2025-05-20 12:04:42 - INFO - TRAINING - Epoch: [70][70/196]	Time 0.136 (0.150)	Data 0.017 (0.019)	Loss 0.5079 (0.4889)	Prec@1 91.406 (92.265)	Prec@5 99.609 (99.747)
2025-05-20 12:04:44 - INFO - TRAINING - Epoch: [70][80/196]	Time 0.146 (0.149)	Data 0.015 (0.017)	Loss 0.4968 (0.4897)	Prec@1 92.188 (92.274)	Prec@5 99.609 (99.735)
2025-05-20 12:04:45 - INFO - TRAINING - Epoch: [70][90/196]	Time 0.160 (0.149)	Data 0.005 (0.015)	Loss 0.5266 (0.4910)	Prec@1 90.234 (92.226)	Prec@5 99.609 (99.712)
2025-05-20 12:04:47 - INFO - TRAINING - Epoch: [70][100/196]	Time 0.133 (0.148)	Data 0.000 (0.014)	Loss 0.5530 (0.4905)	Prec@1 88.281 (92.226)	Prec@5 99.609 (99.706)
2025-05-20 12:04:48 - INFO - TRAINING - Epoch: [70][110/196]	Time 0.133 (0.147)	Data 0.007 (0.013)	Loss 0.4561 (0.4899)	Prec@1 94.141 (92.233)	Prec@5 100.000 (99.711)
2025-05-20 12:04:49 - INFO - TRAINING - Epoch: [70][120/196]	Time 0.134 (0.146)	Data 0.000 (0.012)	Loss 0.5016 (0.4901)	Prec@1 89.844 (92.233)	Prec@5 99.609 (99.706)
2025-05-20 12:04:51 - INFO - TRAINING - Epoch: [70][130/196]	Time 0.134 (0.145)	Data 0.000 (0.011)	Loss 0.4934 (0.4891)	Prec@1 92.188 (92.247)	Prec@5 100.000 (99.717)
2025-05-20 12:04:52 - INFO - TRAINING - Epoch: [70][140/196]	Time 0.134 (0.144)	Data 0.001 (0.011)	Loss 0.4742 (0.4884)	Prec@1 94.531 (92.282)	Prec@5 99.609 (99.726)
2025-05-20 12:04:54 - INFO - TRAINING - Epoch: [70][150/196]	Time 0.134 (0.144)	Data 0.009 (0.010)	Loss 0.4595 (0.4885)	Prec@1 93.750 (92.283)	Prec@5 99.609 (99.731)
2025-05-20 12:04:55 - INFO - TRAINING - Epoch: [70][160/196]	Time 0.137 (0.143)	Data 0.000 (0.010)	Loss 0.5118 (0.4883)	Prec@1 92.578 (92.299)	Prec@5 99.219 (99.738)
2025-05-20 12:04:56 - INFO - TRAINING - Epoch: [70][170/196]	Time 0.141 (0.143)	Data 0.000 (0.009)	Loss 0.5025 (0.4891)	Prec@1 92.188 (92.274)	Prec@5 99.609 (99.740)
2025-05-20 12:04:58 - INFO - TRAINING - Epoch: [70][180/196]	Time 0.152 (0.143)	Data 0.000 (0.009)	Loss 0.4886 (0.4890)	Prec@1 92.578 (92.295)	Prec@5 99.609 (99.743)
2025-05-20 12:04:59 - INFO - TRAINING - Epoch: [70][190/196]	Time 0.133 (0.142)	Data 0.000 (0.009)	Loss 0.5102 (0.4895)	Prec@1 92.969 (92.294)	Prec@5 100.000 (99.740)
2025-05-20 12:05:00 - INFO - EVALUATING - Epoch: [70][0/40]	Time 0.525 (0.525)	Data 0.443 (0.443)	Loss 0.6272 (0.6272)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)
2025-05-20 12:05:01 - INFO - EVALUATING - Epoch: [70][10/40]	Time 0.074 (0.147)	Data 0.000 (0.073)	Loss 0.5947 (0.6386)	Prec@1 87.109 (85.369)	Prec@5 100.000 (98.793)
2025-05-20 12:05:02 - INFO - EVALUATING - Epoch: [70][20/40]	Time 0.078 (0.114)	Data 0.000 (0.040)	Loss 0.6372 (0.6398)	Prec@1 86.328 (85.640)	Prec@5 98.828 (98.363)
2025-05-20 12:05:03 - INFO - EVALUATING - Epoch: [70][30/40]	Time 0.070 (0.101)	Data 0.000 (0.027)	Loss 0.6786 (0.6410)	Prec@1 82.812 (85.383)	Prec@5 99.219 (98.538)
2025-05-20 12:05:04 - INFO - 
 Epoch: 71	Training Loss 0.4900 	Training Prec@1 92.272 	Training Prec@5 99.738 	Validation Loss 0.6399 	Validation Prec@1 85.540 	Validation Prec@5 98.580 

2025-05-20 12:05:04 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:05:04 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:05:04 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:05:04 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:05:04 - INFO - TRAINING - Epoch: [71][0/196]	Time 0.836 (0.836)	Data 0.728 (0.728)	Loss 0.5218 (0.5218)	Prec@1 92.188 (92.188)	Prec@5 98.828 (98.828)
2025-05-20 12:05:06 - INFO - TRAINING - Epoch: [71][10/196]	Time 0.140 (0.215)	Data 0.004 (0.089)	Loss 0.5436 (0.4905)	Prec@1 88.672 (92.543)	Prec@5 100.000 (99.751)
2025-05-20 12:05:07 - INFO - TRAINING - Epoch: [71][20/196]	Time 0.134 (0.179)	Data 0.000 (0.049)	Loss 0.4577 (0.4860)	Prec@1 92.969 (92.708)	Prec@5 100.000 (99.758)
2025-05-20 12:05:09 - INFO - TRAINING - Epoch: [71][30/196]	Time 0.129 (0.165)	Data 0.000 (0.033)	Loss 0.5120 (0.4914)	Prec@1 90.234 (92.339)	Prec@5 100.000 (99.710)
2025-05-20 12:05:10 - INFO - TRAINING - Epoch: [71][40/196]	Time 0.147 (0.160)	Data 0.000 (0.025)	Loss 0.5045 (0.4899)	Prec@1 92.578 (92.349)	Prec@5 99.609 (99.686)
2025-05-20 12:05:12 - INFO - TRAINING - Epoch: [71][50/196]	Time 0.139 (0.158)	Data 0.000 (0.021)	Loss 0.4730 (0.4860)	Prec@1 94.141 (92.479)	Prec@5 99.609 (99.694)
2025-05-20 12:05:13 - INFO - TRAINING - Epoch: [71][60/196]	Time 0.134 (0.154)	Data 0.007 (0.019)	Loss 0.5189 (0.4875)	Prec@1 91.797 (92.469)	Prec@5 99.609 (99.699)
2025-05-20 12:05:14 - INFO - TRAINING - Epoch: [71][70/196]	Time 0.135 (0.152)	Data 0.000 (0.017)	Loss 0.4826 (0.4883)	Prec@1 91.797 (92.375)	Prec@5 99.609 (99.714)
2025-05-20 12:05:16 - INFO - TRAINING - Epoch: [71][80/196]	Time 0.135 (0.149)	Data 0.000 (0.015)	Loss 0.4549 (0.4868)	Prec@1 93.359 (92.472)	Prec@5 99.219 (99.711)
2025-05-20 12:05:17 - INFO - TRAINING - Epoch: [71][90/196]	Time 0.133 (0.148)	Data 0.000 (0.014)	Loss 0.4463 (0.4870)	Prec@1 93.750 (92.479)	Prec@5 100.000 (99.717)
2025-05-20 12:05:18 - INFO - TRAINING - Epoch: [71][100/196]	Time 0.134 (0.146)	Data 0.000 (0.012)	Loss 0.4842 (0.4877)	Prec@1 92.578 (92.458)	Prec@5 99.609 (99.718)
2025-05-20 12:05:20 - INFO - TRAINING - Epoch: [71][110/196]	Time 0.134 (0.145)	Data 0.001 (0.012)	Loss 0.4682 (0.4889)	Prec@1 94.141 (92.370)	Prec@5 100.000 (99.736)
2025-05-20 12:05:21 - INFO - TRAINING - Epoch: [71][120/196]	Time 0.134 (0.144)	Data 0.004 (0.011)	Loss 0.4525 (0.4891)	Prec@1 93.359 (92.320)	Prec@5 100.000 (99.742)
2025-05-20 12:05:23 - INFO - TRAINING - Epoch: [71][130/196]	Time 0.164 (0.144)	Data 0.009 (0.010)	Loss 0.4432 (0.4895)	Prec@1 96.094 (92.322)	Prec@5 99.609 (99.744)
2025-05-20 12:05:24 - INFO - TRAINING - Epoch: [71][140/196]	Time 0.139 (0.144)	Data 0.019 (0.010)	Loss 0.4293 (0.4898)	Prec@1 94.141 (92.318)	Prec@5 99.219 (99.729)
2025-05-20 12:05:25 - INFO - TRAINING - Epoch: [71][150/196]	Time 0.151 (0.144)	Data 0.003 (0.010)	Loss 0.4199 (0.4897)	Prec@1 95.703 (92.356)	Prec@5 99.609 (99.723)
2025-05-20 12:05:27 - INFO - TRAINING - Epoch: [71][160/196]	Time 0.136 (0.144)	Data 0.008 (0.009)	Loss 0.4584 (0.4894)	Prec@1 93.359 (92.374)	Prec@5 100.000 (99.733)
2025-05-20 12:05:28 - INFO - TRAINING - Epoch: [71][170/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.5083 (0.4894)	Prec@1 92.188 (92.345)	Prec@5 98.828 (99.730)
2025-05-20 12:05:29 - INFO - TRAINING - Epoch: [71][180/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.4577 (0.4897)	Prec@1 94.922 (92.334)	Prec@5 99.609 (99.741)
2025-05-20 12:05:31 - INFO - TRAINING - Epoch: [71][190/196]	Time 0.133 (0.142)	Data 0.000 (0.008)	Loss 0.4768 (0.4895)	Prec@1 92.969 (92.320)	Prec@5 100.000 (99.726)
2025-05-20 12:05:32 - INFO - EVALUATING - Epoch: [71][0/40]	Time 0.653 (0.653)	Data 0.580 (0.580)	Loss 0.5657 (0.5657)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
2025-05-20 12:05:33 - INFO - EVALUATING - Epoch: [71][10/40]	Time 0.084 (0.145)	Data 0.003 (0.070)	Loss 0.5769 (0.6132)	Prec@1 87.500 (85.689)	Prec@5 98.047 (98.828)
2025-05-20 12:05:34 - INFO - EVALUATING - Epoch: [71][20/40]	Time 0.081 (0.113)	Data 0.003 (0.038)	Loss 0.6149 (0.6167)	Prec@1 85.547 (86.105)	Prec@5 97.656 (98.493)
2025-05-20 12:05:35 - INFO - EVALUATING - Epoch: [71][30/40]	Time 0.070 (0.100)	Data 0.000 (0.026)	Loss 0.6575 (0.6233)	Prec@1 82.812 (86.076)	Prec@5 99.219 (98.727)
2025-05-20 12:05:36 - INFO - 
 Epoch: 72	Training Loss 0.4903 	Training Prec@1 92.278 	Training Prec@5 99.724 	Validation Loss 0.6236 	Validation Prec@1 86.050 	Validation Prec@5 98.720 

2025-05-20 12:05:36 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:05:36 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:05:36 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:05:36 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:05:37 - INFO - TRAINING - Epoch: [72][0/196]	Time 1.618 (1.618)	Data 1.463 (1.463)	Loss 0.4503 (0.4503)	Prec@1 94.141 (94.141)	Prec@5 99.609 (99.609)
2025-05-20 12:05:39 - INFO - TRAINING - Epoch: [72][10/196]	Time 0.139 (0.281)	Data 0.000 (0.136)	Loss 0.4651 (0.4822)	Prec@1 92.969 (92.898)	Prec@5 100.000 (99.751)
2025-05-20 12:05:40 - INFO - TRAINING - Epoch: [72][20/196]	Time 0.129 (0.215)	Data 0.008 (0.074)	Loss 0.5205 (0.4822)	Prec@1 90.625 (92.857)	Prec@5 100.000 (99.665)
2025-05-20 12:05:41 - INFO - TRAINING - Epoch: [72][30/196]	Time 0.131 (0.189)	Data 0.001 (0.051)	Loss 0.4750 (0.4832)	Prec@1 91.797 (92.780)	Prec@5 100.000 (99.698)
2025-05-20 12:05:43 - INFO - TRAINING - Epoch: [72][40/196]	Time 0.133 (0.175)	Data 0.002 (0.039)	Loss 0.5620 (0.4848)	Prec@1 88.281 (92.569)	Prec@5 99.219 (99.733)
2025-05-20 12:05:44 - INFO - TRAINING - Epoch: [72][50/196]	Time 0.132 (0.167)	Data 0.009 (0.032)	Loss 0.4390 (0.4841)	Prec@1 96.094 (92.662)	Prec@5 99.609 (99.701)
2025-05-20 12:05:45 - INFO - TRAINING - Epoch: [72][60/196]	Time 0.132 (0.162)	Data 0.002 (0.027)	Loss 0.5114 (0.4863)	Prec@1 90.625 (92.565)	Prec@5 100.000 (99.705)
2025-05-20 12:05:47 - INFO - TRAINING - Epoch: [72][70/196]	Time 0.134 (0.158)	Data 0.000 (0.024)	Loss 0.5032 (0.4868)	Prec@1 91.406 (92.551)	Prec@5 99.609 (99.703)
2025-05-20 12:05:48 - INFO - TRAINING - Epoch: [72][80/196]	Time 0.142 (0.155)	Data 0.016 (0.022)	Loss 0.5038 (0.4876)	Prec@1 92.578 (92.496)	Prec@5 99.609 (99.701)
2025-05-20 12:05:50 - INFO - TRAINING - Epoch: [72][90/196]	Time 0.146 (0.154)	Data 0.012 (0.020)	Loss 0.4893 (0.4880)	Prec@1 92.578 (92.488)	Prec@5 100.000 (99.695)
2025-05-20 12:05:51 - INFO - TRAINING - Epoch: [72][100/196]	Time 0.144 (0.153)	Data 0.003 (0.019)	Loss 0.5196 (0.4884)	Prec@1 89.453 (92.462)	Prec@5 99.219 (99.710)
2025-05-20 12:05:52 - INFO - TRAINING - Epoch: [72][110/196]	Time 0.136 (0.152)	Data 0.000 (0.017)	Loss 0.4632 (0.4892)	Prec@1 92.969 (92.374)	Prec@5 100.000 (99.722)
2025-05-20 12:05:54 - INFO - TRAINING - Epoch: [72][120/196]	Time 0.134 (0.150)	Data 0.000 (0.016)	Loss 0.4601 (0.4890)	Prec@1 93.750 (92.397)	Prec@5 99.219 (99.732)
2025-05-20 12:05:55 - INFO - TRAINING - Epoch: [72][130/196]	Time 0.132 (0.149)	Data 0.000 (0.015)	Loss 0.5365 (0.4893)	Prec@1 89.844 (92.387)	Prec@5 100.000 (99.741)
2025-05-20 12:05:56 - INFO - TRAINING - Epoch: [72][140/196]	Time 0.135 (0.148)	Data 0.000 (0.014)	Loss 0.4518 (0.4900)	Prec@1 94.141 (92.354)	Prec@5 99.609 (99.729)
2025-05-20 12:05:58 - INFO - TRAINING - Epoch: [72][150/196]	Time 0.135 (0.147)	Data 0.000 (0.013)	Loss 0.4374 (0.4897)	Prec@1 96.094 (92.387)	Prec@5 99.609 (99.728)
2025-05-20 12:05:59 - INFO - TRAINING - Epoch: [72][160/196]	Time 0.132 (0.146)	Data 0.000 (0.013)	Loss 0.4528 (0.4901)	Prec@1 93.359 (92.333)	Prec@5 100.000 (99.738)
2025-05-20 12:06:00 - INFO - TRAINING - Epoch: [72][170/196]	Time 0.133 (0.145)	Data 0.003 (0.012)	Loss 0.4488 (0.4897)	Prec@1 94.141 (92.359)	Prec@5 99.609 (99.742)
2025-05-20 12:06:02 - INFO - TRAINING - Epoch: [72][180/196]	Time 0.140 (0.145)	Data 0.000 (0.012)	Loss 0.5185 (0.4898)	Prec@1 90.625 (92.371)	Prec@5 99.609 (99.739)
2025-05-20 12:06:03 - INFO - TRAINING - Epoch: [72][190/196]	Time 0.130 (0.144)	Data 0.000 (0.011)	Loss 0.4207 (0.4895)	Prec@1 95.703 (92.400)	Prec@5 100.000 (99.740)
2025-05-20 12:06:05 - INFO - EVALUATING - Epoch: [72][0/40]	Time 0.690 (0.690)	Data 0.607 (0.607)	Loss 0.6193 (0.6193)	Prec@1 85.547 (85.547)	Prec@5 98.438 (98.438)
2025-05-20 12:06:05 - INFO - EVALUATING - Epoch: [72][10/40]	Time 0.079 (0.142)	Data 0.004 (0.065)	Loss 0.6103 (0.6527)	Prec@1 85.938 (85.121)	Prec@5 98.828 (98.509)
2025-05-20 12:06:06 - INFO - EVALUATING - Epoch: [72][20/40]	Time 0.068 (0.111)	Data 0.000 (0.036)	Loss 0.6541 (0.6556)	Prec@1 86.719 (85.100)	Prec@5 97.656 (98.307)
2025-05-20 12:06:07 - INFO - EVALUATING - Epoch: [72][30/40]	Time 0.069 (0.100)	Data 0.000 (0.025)	Loss 0.6647 (0.6563)	Prec@1 84.375 (85.156)	Prec@5 99.219 (98.463)
2025-05-20 12:06:08 - INFO - 
 Epoch: 73	Training Loss 0.4896 	Training Prec@1 92.390 	Training Prec@5 99.742 	Validation Loss 0.6559 	Validation Prec@1 85.300 	Validation Prec@5 98.450 

2025-05-20 12:06:08 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:06:08 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:06:08 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:06:08 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:06:09 - INFO - TRAINING - Epoch: [73][0/196]	Time 1.067 (1.067)	Data 0.957 (0.957)	Loss 0.4260 (0.4260)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
2025-05-20 12:06:10 - INFO - TRAINING - Epoch: [73][10/196]	Time 0.135 (0.228)	Data 0.008 (0.093)	Loss 0.5271 (0.4706)	Prec@1 91.016 (93.288)	Prec@5 100.000 (99.751)
2025-05-20 12:06:12 - INFO - TRAINING - Epoch: [73][20/196]	Time 0.135 (0.184)	Data 0.000 (0.051)	Loss 0.4699 (0.4793)	Prec@1 94.141 (92.894)	Prec@5 100.000 (99.758)
2025-05-20 12:06:13 - INFO - TRAINING - Epoch: [73][30/196]	Time 0.133 (0.168)	Data 0.000 (0.035)	Loss 0.4685 (0.4860)	Prec@1 93.359 (92.616)	Prec@5 99.609 (99.735)
2025-05-20 12:06:14 - INFO - TRAINING - Epoch: [73][40/196]	Time 0.140 (0.160)	Data 0.016 (0.027)	Loss 0.4946 (0.4853)	Prec@1 92.969 (92.578)	Prec@5 99.609 (99.705)
2025-05-20 12:06:16 - INFO - TRAINING - Epoch: [73][50/196]	Time 0.131 (0.157)	Data 0.000 (0.023)	Loss 0.4353 (0.4848)	Prec@1 94.531 (92.570)	Prec@5 100.000 (99.732)
2025-05-20 12:06:17 - INFO - TRAINING - Epoch: [73][60/196]	Time 0.139 (0.155)	Data 0.005 (0.020)	Loss 0.4663 (0.4834)	Prec@1 92.578 (92.649)	Prec@5 100.000 (99.769)
2025-05-20 12:06:19 - INFO - TRAINING - Epoch: [73][70/196]	Time 0.131 (0.152)	Data 0.001 (0.018)	Loss 0.5166 (0.4852)	Prec@1 91.016 (92.507)	Prec@5 99.609 (99.758)
2025-05-20 12:06:20 - INFO - TRAINING - Epoch: [73][80/196]	Time 0.126 (0.150)	Data 0.000 (0.016)	Loss 0.5004 (0.4862)	Prec@1 89.844 (92.467)	Prec@5 99.609 (99.773)
2025-05-20 12:06:21 - INFO - TRAINING - Epoch: [73][90/196]	Time 0.134 (0.148)	Data 0.007 (0.014)	Loss 0.5003 (0.4868)	Prec@1 91.016 (92.415)	Prec@5 99.219 (99.777)
2025-05-20 12:06:23 - INFO - TRAINING - Epoch: [73][100/196]	Time 0.131 (0.146)	Data 0.000 (0.013)	Loss 0.5179 (0.4863)	Prec@1 91.016 (92.454)	Prec@5 100.000 (99.780)
2025-05-20 12:06:24 - INFO - TRAINING - Epoch: [73][110/196]	Time 0.133 (0.145)	Data 0.000 (0.012)	Loss 0.5308 (0.4879)	Prec@1 91.797 (92.402)	Prec@5 99.609 (99.757)
2025-05-20 12:06:25 - INFO - TRAINING - Epoch: [73][120/196]	Time 0.134 (0.144)	Data 0.000 (0.011)	Loss 0.5044 (0.4883)	Prec@1 91.406 (92.375)	Prec@5 100.000 (99.742)
2025-05-20 12:06:27 - INFO - TRAINING - Epoch: [73][130/196]	Time 0.132 (0.144)	Data 0.000 (0.011)	Loss 0.5035 (0.4878)	Prec@1 91.016 (92.423)	Prec@5 98.828 (99.732)
2025-05-20 12:06:28 - INFO - TRAINING - Epoch: [73][140/196]	Time 0.142 (0.143)	Data 0.000 (0.010)	Loss 0.5182 (0.4876)	Prec@1 91.016 (92.440)	Prec@5 100.000 (99.734)
2025-05-20 12:06:29 - INFO - TRAINING - Epoch: [73][150/196]	Time 0.151 (0.144)	Data 0.003 (0.010)	Loss 0.4352 (0.4872)	Prec@1 96.094 (92.457)	Prec@5 100.000 (99.736)
2025-05-20 12:06:31 - INFO - TRAINING - Epoch: [73][160/196]	Time 0.133 (0.144)	Data 0.000 (0.010)	Loss 0.5036 (0.4874)	Prec@1 91.406 (92.447)	Prec@5 99.609 (99.745)
2025-05-20 12:06:32 - INFO - TRAINING - Epoch: [73][170/196]	Time 0.139 (0.143)	Data 0.000 (0.009)	Loss 0.5524 (0.4880)	Prec@1 89.844 (92.425)	Prec@5 100.000 (99.744)
2025-05-20 12:06:34 - INFO - TRAINING - Epoch: [73][180/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.5338 (0.4884)	Prec@1 91.406 (92.416)	Prec@5 99.219 (99.747)
2025-05-20 12:06:35 - INFO - TRAINING - Epoch: [73][190/196]	Time 0.134 (0.142)	Data 0.000 (0.008)	Loss 0.4802 (0.4882)	Prec@1 92.188 (92.425)	Prec@5 99.609 (99.744)
2025-05-20 12:06:36 - INFO - EVALUATING - Epoch: [73][0/40]	Time 0.738 (0.738)	Data 0.670 (0.670)	Loss 0.6218 (0.6218)	Prec@1 86.328 (86.328)	Prec@5 98.047 (98.047)
2025-05-20 12:06:37 - INFO - EVALUATING - Epoch: [73][10/40]	Time 0.070 (0.138)	Data 0.000 (0.064)	Loss 0.5801 (0.6156)	Prec@1 88.672 (87.003)	Prec@5 98.438 (98.509)
2025-05-20 12:06:38 - INFO - EVALUATING - Epoch: [73][20/40]	Time 0.070 (0.109)	Data 0.000 (0.035)	Loss 0.6154 (0.6205)	Prec@1 87.109 (86.682)	Prec@5 98.438 (98.140)
2025-05-20 12:06:39 - INFO - EVALUATING - Epoch: [73][30/40]	Time 0.069 (0.098)	Data 0.000 (0.024)	Loss 0.7019 (0.6274)	Prec@1 83.594 (86.379)	Prec@5 98.438 (98.261)
2025-05-20 12:06:40 - INFO - 
 Epoch: 74	Training Loss 0.4887 	Training Prec@1 92.420 	Training Prec@5 99.744 	Validation Loss 0.6253 	Validation Prec@1 86.450 	Validation Prec@5 98.340 

2025-05-20 12:06:40 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:06:40 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:06:40 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:06:40 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:06:41 - INFO - TRAINING - Epoch: [74][0/196]	Time 1.013 (1.013)	Data 0.882 (0.882)	Loss 0.4634 (0.4634)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
2025-05-20 12:06:42 - INFO - TRAINING - Epoch: [74][10/196]	Time 0.196 (0.253)	Data 0.099 (0.127)	Loss 0.5235 (0.4860)	Prec@1 92.188 (92.756)	Prec@5 99.609 (99.680)
2025-05-20 12:06:44 - INFO - TRAINING - Epoch: [74][20/196]	Time 0.138 (0.208)	Data 0.000 (0.069)	Loss 0.4737 (0.4849)	Prec@1 94.531 (92.820)	Prec@5 100.000 (99.795)
2025-05-20 12:06:45 - INFO - TRAINING - Epoch: [74][30/196]	Time 0.136 (0.186)	Data 0.008 (0.047)	Loss 0.4495 (0.4877)	Prec@1 94.141 (92.767)	Prec@5 100.000 (99.786)
2025-05-20 12:06:47 - INFO - TRAINING - Epoch: [74][40/196]	Time 0.135 (0.173)	Data 0.000 (0.036)	Loss 0.4598 (0.4882)	Prec@1 94.922 (92.692)	Prec@5 99.609 (99.790)
2025-05-20 12:06:48 - INFO - TRAINING - Epoch: [74][50/196]	Time 0.135 (0.166)	Data 0.000 (0.030)	Loss 0.4730 (0.4865)	Prec@1 91.797 (92.624)	Prec@5 100.000 (99.809)
2025-05-20 12:06:49 - INFO - TRAINING - Epoch: [74][60/196]	Time 0.135 (0.160)	Data 0.003 (0.025)	Loss 0.5208 (0.4904)	Prec@1 90.625 (92.456)	Prec@5 99.609 (99.776)
2025-05-20 12:06:51 - INFO - TRAINING - Epoch: [74][70/196]	Time 0.133 (0.157)	Data 0.007 (0.022)	Loss 0.5845 (0.4925)	Prec@1 86.328 (92.347)	Prec@5 99.219 (99.774)
2025-05-20 12:06:52 - INFO - TRAINING - Epoch: [74][80/196]	Time 0.135 (0.154)	Data 0.000 (0.020)	Loss 0.4538 (0.4914)	Prec@1 94.141 (92.376)	Prec@5 99.609 (99.759)
2025-05-20 12:06:53 - INFO - TRAINING - Epoch: [74][90/196]	Time 0.135 (0.152)	Data 0.000 (0.018)	Loss 0.4624 (0.4911)	Prec@1 94.141 (92.351)	Prec@5 99.219 (99.755)
2025-05-20 12:06:55 - INFO - TRAINING - Epoch: [74][100/196]	Time 0.148 (0.151)	Data 0.006 (0.016)	Loss 0.4481 (0.4901)	Prec@1 94.141 (92.369)	Prec@5 99.219 (99.729)
2025-05-20 12:06:56 - INFO - TRAINING - Epoch: [74][110/196]	Time 0.158 (0.151)	Data 0.008 (0.016)	Loss 0.4990 (0.4897)	Prec@1 93.750 (92.374)	Prec@5 99.609 (99.729)
2025-05-20 12:06:58 - INFO - TRAINING - Epoch: [74][120/196]	Time 0.133 (0.150)	Data 0.007 (0.015)	Loss 0.4914 (0.4888)	Prec@1 92.578 (92.401)	Prec@5 100.000 (99.735)
2025-05-20 12:06:59 - INFO - TRAINING - Epoch: [74][130/196]	Time 0.131 (0.149)	Data 0.007 (0.014)	Loss 0.4813 (0.4885)	Prec@1 92.578 (92.384)	Prec@5 99.609 (99.726)
2025-05-20 12:07:00 - INFO - TRAINING - Epoch: [74][140/196]	Time 0.133 (0.148)	Data 0.000 (0.013)	Loss 0.4621 (0.4887)	Prec@1 93.750 (92.373)	Prec@5 100.000 (99.742)
2025-05-20 12:07:02 - INFO - TRAINING - Epoch: [74][150/196]	Time 0.133 (0.147)	Data 0.000 (0.012)	Loss 0.4924 (0.4900)	Prec@1 92.969 (92.317)	Prec@5 99.219 (99.734)
2025-05-20 12:07:03 - INFO - TRAINING - Epoch: [74][160/196]	Time 0.136 (0.146)	Data 0.008 (0.012)	Loss 0.5094 (0.4892)	Prec@1 90.234 (92.340)	Prec@5 100.000 (99.736)
2025-05-20 12:07:04 - INFO - TRAINING - Epoch: [74][170/196]	Time 0.135 (0.145)	Data 0.000 (0.011)	Loss 0.5071 (0.4888)	Prec@1 91.016 (92.347)	Prec@5 99.609 (99.744)
2025-05-20 12:07:06 - INFO - TRAINING - Epoch: [74][180/196]	Time 0.134 (0.145)	Data 0.000 (0.011)	Loss 0.4863 (0.4884)	Prec@1 92.969 (92.408)	Prec@5 100.000 (99.737)
2025-05-20 12:07:07 - INFO - TRAINING - Epoch: [74][190/196]	Time 0.134 (0.144)	Data 0.000 (0.010)	Loss 0.4543 (0.4876)	Prec@1 94.531 (92.462)	Prec@5 100.000 (99.740)
2025-05-20 12:07:09 - INFO - EVALUATING - Epoch: [74][0/40]	Time 1.206 (1.206)	Data 1.135 (1.135)	Loss 0.5611 (0.5611)	Prec@1 92.188 (92.188)	Prec@5 98.828 (98.828)
2025-05-20 12:07:10 - INFO - EVALUATING - Epoch: [74][10/40]	Time 0.077 (0.181)	Data 0.003 (0.109)	Loss 0.6068 (0.6299)	Prec@1 87.109 (86.399)	Prec@5 97.656 (98.402)
2025-05-20 12:07:11 - INFO - EVALUATING - Epoch: [74][20/40]	Time 0.071 (0.133)	Data 0.000 (0.059)	Loss 0.6048 (0.6260)	Prec@1 87.500 (86.756)	Prec@5 98.828 (98.270)
2025-05-20 12:07:11 - INFO - EVALUATING - Epoch: [74][30/40]	Time 0.070 (0.114)	Data 0.000 (0.041)	Loss 0.6596 (0.6294)	Prec@1 83.203 (86.479)	Prec@5 98.438 (98.248)
2025-05-20 12:07:12 - INFO - 
 Epoch: 75	Training Loss 0.4877 	Training Prec@1 92.454 	Training Prec@5 99.740 	Validation Loss 0.6301 	Validation Prec@1 86.290 	Validation Prec@5 98.400 

2025-05-20 12:07:12 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:07:12 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:07:12 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:07:12 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:07:13 - INFO - TRAINING - Epoch: [75][0/196]	Time 0.749 (0.749)	Data 0.634 (0.634)	Loss 0.4553 (0.4553)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2025-05-20 12:07:15 - INFO - TRAINING - Epoch: [75][10/196]	Time 0.147 (0.218)	Data 0.007 (0.084)	Loss 0.4176 (0.4650)	Prec@1 96.094 (93.359)	Prec@5 100.000 (99.858)
2025-05-20 12:07:16 - INFO - TRAINING - Epoch: [75][20/196]	Time 0.136 (0.180)	Data 0.000 (0.047)	Loss 0.4775 (0.4666)	Prec@1 92.578 (93.211)	Prec@5 99.609 (99.870)
2025-05-20 12:07:17 - INFO - TRAINING - Epoch: [75][30/196]	Time 0.133 (0.165)	Data 0.007 (0.033)	Loss 0.5220 (0.4764)	Prec@1 90.625 (92.755)	Prec@5 99.609 (99.824)
2025-05-20 12:07:19 - INFO - TRAINING - Epoch: [75][40/196]	Time 0.133 (0.158)	Data 0.000 (0.025)	Loss 0.4604 (0.4726)	Prec@1 94.531 (92.988)	Prec@5 100.000 (99.857)
2025-05-20 12:07:20 - INFO - TRAINING - Epoch: [75][50/196]	Time 0.138 (0.154)	Data 0.013 (0.021)	Loss 0.4975 (0.4765)	Prec@1 90.625 (92.739)	Prec@5 100.000 (99.831)
2025-05-20 12:07:22 - INFO - TRAINING - Epoch: [75][60/196]	Time 0.156 (0.153)	Data 0.020 (0.019)	Loss 0.4898 (0.4794)	Prec@1 92.578 (92.642)	Prec@5 100.000 (99.814)
2025-05-20 12:07:23 - INFO - TRAINING - Epoch: [75][70/196]	Time 0.135 (0.151)	Data 0.000 (0.017)	Loss 0.4630 (0.4806)	Prec@1 94.531 (92.694)	Prec@5 100.000 (99.829)
2025-05-20 12:07:24 - INFO - TRAINING - Epoch: [75][80/196]	Time 0.134 (0.149)	Data 0.000 (0.015)	Loss 0.5106 (0.4822)	Prec@1 91.016 (92.631)	Prec@5 100.000 (99.826)
2025-05-20 12:07:26 - INFO - TRAINING - Epoch: [75][90/196]	Time 0.131 (0.147)	Data 0.002 (0.014)	Loss 0.4438 (0.4817)	Prec@1 94.531 (92.655)	Prec@5 100.000 (99.820)
2025-05-20 12:07:27 - INFO - TRAINING - Epoch: [75][100/196]	Time 0.133 (0.146)	Data 0.009 (0.013)	Loss 0.4669 (0.4816)	Prec@1 93.750 (92.613)	Prec@5 100.000 (99.830)
2025-05-20 12:07:28 - INFO - TRAINING - Epoch: [75][110/196]	Time 0.133 (0.145)	Data 0.000 (0.012)	Loss 0.5232 (0.4831)	Prec@1 92.578 (92.553)	Prec@5 99.219 (99.799)
2025-05-20 12:07:30 - INFO - TRAINING - Epoch: [75][120/196]	Time 0.126 (0.144)	Data 0.000 (0.011)	Loss 0.4705 (0.4827)	Prec@1 93.359 (92.597)	Prec@5 99.609 (99.784)
2025-05-20 12:07:31 - INFO - TRAINING - Epoch: [75][130/196]	Time 0.133 (0.143)	Data 0.000 (0.010)	Loss 0.4212 (0.4834)	Prec@1 96.094 (92.554)	Prec@5 99.609 (99.788)
2025-05-20 12:07:32 - INFO - TRAINING - Epoch: [75][140/196]	Time 0.146 (0.143)	Data 0.001 (0.010)	Loss 0.4789 (0.4835)	Prec@1 92.969 (92.503)	Prec@5 99.609 (99.795)
2025-05-20 12:07:34 - INFO - TRAINING - Epoch: [75][150/196]	Time 0.145 (0.143)	Data 0.032 (0.009)	Loss 0.5008 (0.4842)	Prec@1 92.969 (92.513)	Prec@5 99.609 (99.793)
2025-05-20 12:07:35 - INFO - TRAINING - Epoch: [75][160/196]	Time 0.149 (0.143)	Data 0.000 (0.009)	Loss 0.4870 (0.4848)	Prec@1 93.750 (92.513)	Prec@5 100.000 (99.784)
2025-05-20 12:07:37 - INFO - TRAINING - Epoch: [75][170/196]	Time 0.147 (0.143)	Data 0.005 (0.009)	Loss 0.5417 (0.4853)	Prec@1 90.625 (92.496)	Prec@5 99.609 (99.785)
2025-05-20 12:07:38 - INFO - TRAINING - Epoch: [75][180/196]	Time 0.134 (0.142)	Data 0.000 (0.008)	Loss 0.5044 (0.4852)	Prec@1 92.578 (92.507)	Prec@5 100.000 (99.786)
2025-05-20 12:07:39 - INFO - TRAINING - Epoch: [75][190/196]	Time 0.132 (0.142)	Data 0.000 (0.008)	Loss 0.4841 (0.4845)	Prec@1 91.797 (92.529)	Prec@5 100.000 (99.787)
2025-05-20 12:07:41 - INFO - EVALUATING - Epoch: [75][0/40]	Time 0.823 (0.823)	Data 0.747 (0.747)	Loss 0.6624 (0.6624)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
2025-05-20 12:07:42 - INFO - EVALUATING - Epoch: [75][10/40]	Time 0.085 (0.145)	Data 0.006 (0.071)	Loss 0.6118 (0.6387)	Prec@1 87.891 (86.222)	Prec@5 99.219 (98.722)
2025-05-20 12:07:42 - INFO - EVALUATING - Epoch: [75][20/40]	Time 0.093 (0.114)	Data 0.010 (0.040)	Loss 0.6218 (0.6411)	Prec@1 86.719 (86.031)	Prec@5 99.609 (98.531)
2025-05-20 12:07:43 - INFO - EVALUATING - Epoch: [75][30/40]	Time 0.069 (0.101)	Data 0.000 (0.028)	Loss 0.6483 (0.6444)	Prec@1 85.156 (85.849)	Prec@5 99.219 (98.513)
2025-05-20 12:07:44 - INFO - 
 Epoch: 76	Training Loss 0.4844 	Training Prec@1 92.530 	Training Prec@5 99.786 	Validation Loss 0.6433 	Validation Prec@1 85.820 	Validation Prec@5 98.540 

2025-05-20 12:07:44 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:07:44 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:07:44 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:07:44 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:07:45 - INFO - TRAINING - Epoch: [76][0/196]	Time 1.033 (1.033)	Data 0.926 (0.926)	Loss 0.4683 (0.4683)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2025-05-20 12:07:46 - INFO - TRAINING - Epoch: [76][10/196]	Time 0.162 (0.224)	Data 0.017 (0.090)	Loss 0.5470 (0.4934)	Prec@1 88.281 (91.406)	Prec@5 100.000 (100.000)
2025-05-20 12:07:48 - INFO - TRAINING - Epoch: [76][20/196]	Time 0.146 (0.184)	Data 0.022 (0.051)	Loss 0.5146 (0.4907)	Prec@1 92.969 (92.094)	Prec@5 98.828 (99.814)
2025-05-20 12:07:49 - INFO - TRAINING - Epoch: [76][30/196]	Time 0.161 (0.176)	Data 0.011 (0.038)	Loss 0.4517 (0.4880)	Prec@1 92.578 (92.162)	Prec@5 100.000 (99.836)
2025-05-20 12:07:51 - INFO - TRAINING - Epoch: [76][40/196]	Time 0.129 (0.166)	Data 0.000 (0.030)	Loss 0.4408 (0.4850)	Prec@1 94.922 (92.464)	Prec@5 100.000 (99.819)
2025-05-20 12:07:52 - INFO - TRAINING - Epoch: [76][50/196]	Time 0.135 (0.160)	Data 0.007 (0.025)	Loss 0.4546 (0.4820)	Prec@1 92.969 (92.624)	Prec@5 100.000 (99.809)
2025-05-20 12:07:53 - INFO - TRAINING - Epoch: [76][60/196]	Time 0.134 (0.155)	Data 0.000 (0.021)	Loss 0.4561 (0.4832)	Prec@1 95.312 (92.591)	Prec@5 99.609 (99.801)
2025-05-20 12:07:55 - INFO - TRAINING - Epoch: [76][70/196]	Time 0.134 (0.152)	Data 0.008 (0.018)	Loss 0.4777 (0.4839)	Prec@1 92.188 (92.545)	Prec@5 100.000 (99.813)
2025-05-20 12:07:56 - INFO - TRAINING - Epoch: [76][80/196]	Time 0.135 (0.150)	Data 0.000 (0.016)	Loss 0.5130 (0.4830)	Prec@1 91.016 (92.675)	Prec@5 99.609 (99.783)
2025-05-20 12:07:57 - INFO - TRAINING - Epoch: [76][90/196]	Time 0.133 (0.148)	Data 0.000 (0.015)	Loss 0.5433 (0.4843)	Prec@1 88.281 (92.557)	Prec@5 99.219 (99.777)
2025-05-20 12:07:59 - INFO - TRAINING - Epoch: [76][100/196]	Time 0.131 (0.147)	Data 0.000 (0.013)	Loss 0.4541 (0.4832)	Prec@1 94.531 (92.621)	Prec@5 99.219 (99.776)
2025-05-20 12:08:00 - INFO - TRAINING - Epoch: [76][110/196]	Time 0.144 (0.146)	Data 0.006 (0.012)	Loss 0.4842 (0.4825)	Prec@1 92.969 (92.631)	Prec@5 100.000 (99.771)
2025-05-20 12:08:02 - INFO - TRAINING - Epoch: [76][120/196]	Time 0.144 (0.146)	Data 0.017 (0.012)	Loss 0.4673 (0.4817)	Prec@1 93.750 (92.652)	Prec@5 100.000 (99.761)
2025-05-20 12:08:03 - INFO - TRAINING - Epoch: [76][130/196]	Time 0.137 (0.146)	Data 0.000 (0.012)	Loss 0.4961 (0.4815)	Prec@1 92.578 (92.703)	Prec@5 100.000 (99.773)
2025-05-20 12:08:04 - INFO - TRAINING - Epoch: [76][140/196]	Time 0.158 (0.145)	Data 0.000 (0.011)	Loss 0.4536 (0.4815)	Prec@1 93.750 (92.722)	Prec@5 100.000 (99.770)
2025-05-20 12:08:06 - INFO - TRAINING - Epoch: [76][150/196]	Time 0.133 (0.145)	Data 0.001 (0.010)	Loss 0.5023 (0.4817)	Prec@1 89.844 (92.718)	Prec@5 100.000 (99.775)
2025-05-20 12:08:07 - INFO - TRAINING - Epoch: [76][160/196]	Time 0.134 (0.144)	Data 0.007 (0.010)	Loss 0.5093 (0.4825)	Prec@1 91.016 (92.670)	Prec@5 98.828 (99.767)
2025-05-20 12:08:08 - INFO - TRAINING - Epoch: [76][170/196]	Time 0.134 (0.143)	Data 0.000 (0.010)	Loss 0.5110 (0.4834)	Prec@1 90.625 (92.663)	Prec@5 99.609 (99.767)
2025-05-20 12:08:10 - INFO - TRAINING - Epoch: [76][180/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.5327 (0.4839)	Prec@1 91.406 (92.667)	Prec@5 100.000 (99.771)
2025-05-20 12:08:11 - INFO - TRAINING - Epoch: [76][190/196]	Time 0.133 (0.142)	Data 0.000 (0.009)	Loss 0.4682 (0.4843)	Prec@1 92.578 (92.660)	Prec@5 100.000 (99.761)
2025-05-20 12:08:13 - INFO - EVALUATING - Epoch: [76][0/40]	Time 0.818 (0.818)	Data 0.729 (0.729)	Loss 0.6142 (0.6142)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
2025-05-20 12:08:14 - INFO - EVALUATING - Epoch: [76][10/40]	Time 0.086 (0.156)	Data 0.000 (0.074)	Loss 0.5916 (0.6336)	Prec@1 88.281 (86.470)	Prec@5 99.609 (98.686)
2025-05-20 12:08:15 - INFO - EVALUATING - Epoch: [76][20/40]	Time 0.091 (0.133)	Data 0.013 (0.051)	Loss 0.6283 (0.6348)	Prec@1 85.938 (86.514)	Prec@5 98.438 (98.568)
2025-05-20 12:08:16 - INFO - EVALUATING - Epoch: [76][30/40]	Time 0.069 (0.124)	Data 0.000 (0.042)	Loss 0.6896 (0.6413)	Prec@1 82.031 (86.240)	Prec@5 99.219 (98.576)
2025-05-20 12:08:17 - INFO - 
 Epoch: 77	Training Loss 0.4842 	Training Prec@1 92.680 	Training Prec@5 99.760 	Validation Loss 0.6419 	Validation Prec@1 86.120 	Validation Prec@5 98.590 

2025-05-20 12:08:17 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:08:17 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:08:17 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:08:17 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:08:17 - INFO - TRAINING - Epoch: [77][0/196]	Time 0.919 (0.919)	Data 0.779 (0.779)	Loss 0.4809 (0.4809)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2025-05-20 12:08:19 - INFO - TRAINING - Epoch: [77][10/196]	Time 0.137 (0.209)	Data 0.005 (0.075)	Loss 0.4983 (0.4912)	Prec@1 92.188 (92.827)	Prec@5 99.609 (99.716)
2025-05-20 12:08:20 - INFO - TRAINING - Epoch: [77][20/196]	Time 0.134 (0.177)	Data 0.001 (0.042)	Loss 0.5289 (0.4973)	Prec@1 89.453 (92.113)	Prec@5 98.828 (99.554)
2025-05-20 12:08:22 - INFO - TRAINING - Epoch: [77][30/196]	Time 0.133 (0.163)	Data 0.011 (0.030)	Loss 0.5331 (0.4934)	Prec@1 91.406 (92.402)	Prec@5 99.609 (99.572)
2025-05-20 12:08:23 - INFO - TRAINING - Epoch: [77][40/196]	Time 0.133 (0.156)	Data 0.000 (0.023)	Loss 0.4777 (0.4921)	Prec@1 92.188 (92.426)	Prec@5 99.609 (99.647)
2025-05-20 12:08:24 - INFO - TRAINING - Epoch: [77][50/196]	Time 0.134 (0.152)	Data 0.007 (0.020)	Loss 0.5106 (0.4914)	Prec@1 91.406 (92.448)	Prec@5 100.000 (99.671)
2025-05-20 12:08:26 - INFO - TRAINING - Epoch: [77][60/196]	Time 0.134 (0.149)	Data 0.000 (0.017)	Loss 0.5028 (0.4925)	Prec@1 92.578 (92.386)	Prec@5 100.000 (99.693)
2025-05-20 12:08:27 - INFO - TRAINING - Epoch: [77][70/196]	Time 0.139 (0.148)	Data 0.002 (0.015)	Loss 0.4941 (0.4936)	Prec@1 92.969 (92.375)	Prec@5 100.000 (99.708)
2025-05-20 12:08:29 - INFO - TRAINING - Epoch: [77][80/196]	Time 0.171 (0.148)	Data 0.000 (0.014)	Loss 0.4241 (0.4912)	Prec@1 94.922 (92.477)	Prec@5 100.000 (99.730)
2025-05-20 12:08:30 - INFO - TRAINING - Epoch: [77][90/196]	Time 0.135 (0.147)	Data 0.000 (0.013)	Loss 0.4605 (0.4914)	Prec@1 93.750 (92.432)	Prec@5 100.000 (99.751)
2025-05-20 12:08:31 - INFO - TRAINING - Epoch: [77][100/196]	Time 0.135 (0.146)	Data 0.007 (0.012)	Loss 0.4941 (0.4914)	Prec@1 91.016 (92.412)	Prec@5 99.219 (99.741)
2025-05-20 12:08:33 - INFO - TRAINING - Epoch: [77][110/196]	Time 0.134 (0.145)	Data 0.003 (0.011)	Loss 0.4469 (0.4909)	Prec@1 93.750 (92.416)	Prec@5 100.000 (99.740)
2025-05-20 12:08:34 - INFO - TRAINING - Epoch: [77][120/196]	Time 0.132 (0.144)	Data 0.007 (0.010)	Loss 0.4598 (0.4902)	Prec@1 94.141 (92.472)	Prec@5 100.000 (99.735)
2025-05-20 12:08:35 - INFO - TRAINING - Epoch: [77][130/196]	Time 0.144 (0.143)	Data 0.013 (0.010)	Loss 0.4903 (0.4894)	Prec@1 94.531 (92.542)	Prec@5 99.219 (99.726)
2025-05-20 12:08:37 - INFO - TRAINING - Epoch: [77][140/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.4990 (0.4881)	Prec@1 91.797 (92.595)	Prec@5 100.000 (99.734)
2025-05-20 12:08:38 - INFO - TRAINING - Epoch: [77][150/196]	Time 0.133 (0.142)	Data 0.000 (0.009)	Loss 0.4500 (0.4876)	Prec@1 92.969 (92.596)	Prec@5 100.000 (99.734)
2025-05-20 12:08:39 - INFO - TRAINING - Epoch: [77][160/196]	Time 0.148 (0.142)	Data 0.002 (0.008)	Loss 0.4878 (0.4887)	Prec@1 92.969 (92.547)	Prec@5 100.000 (99.728)
2025-05-20 12:08:41 - INFO - TRAINING - Epoch: [77][170/196]	Time 0.151 (0.142)	Data 0.011 (0.008)	Loss 0.4562 (0.4886)	Prec@1 92.969 (92.553)	Prec@5 100.000 (99.735)
2025-05-20 12:08:42 - INFO - TRAINING - Epoch: [77][180/196]	Time 0.136 (0.143)	Data 0.000 (0.008)	Loss 0.4983 (0.4879)	Prec@1 90.625 (92.574)	Prec@5 99.219 (99.739)
2025-05-20 12:08:44 - INFO - TRAINING - Epoch: [77][190/196]	Time 0.134 (0.142)	Data 0.000 (0.008)	Loss 0.5356 (0.4876)	Prec@1 90.625 (92.584)	Prec@5 99.609 (99.736)
2025-05-20 12:08:45 - INFO - EVALUATING - Epoch: [77][0/40]	Time 0.537 (0.537)	Data 0.463 (0.463)	Loss 0.6179 (0.6179)	Prec@1 87.891 (87.891)	Prec@5 98.438 (98.438)
2025-05-20 12:08:46 - INFO - EVALUATING - Epoch: [77][10/40]	Time 0.078 (0.151)	Data 0.000 (0.079)	Loss 0.6502 (0.6460)	Prec@1 85.547 (85.689)	Prec@5 99.609 (98.615)
2025-05-20 12:08:47 - INFO - EVALUATING - Epoch: [77][20/40]	Time 0.090 (0.116)	Data 0.015 (0.043)	Loss 0.6754 (0.6424)	Prec@1 84.375 (85.956)	Prec@5 98.828 (98.586)
2025-05-20 12:08:48 - INFO - EVALUATING - Epoch: [77][30/40]	Time 0.070 (0.103)	Data 0.000 (0.030)	Loss 0.6669 (0.6451)	Prec@1 84.766 (85.774)	Prec@5 98.047 (98.715)
2025-05-20 12:08:48 - INFO - 
 Epoch: 78	Training Loss 0.4875 	Training Prec@1 92.586 	Training Prec@5 99.736 	Validation Loss 0.6451 	Validation Prec@1 85.720 	Validation Prec@5 98.720 

2025-05-20 12:08:48 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:08:48 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:08:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:08:48 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:08:49 - INFO - TRAINING - Epoch: [78][0/196]	Time 1.012 (1.012)	Data 0.898 (0.898)	Loss 0.4977 (0.4977)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
2025-05-20 12:08:51 - INFO - TRAINING - Epoch: [78][10/196]	Time 0.130 (0.221)	Data 0.000 (0.089)	Loss 0.4945 (0.4741)	Prec@1 92.578 (92.791)	Prec@5 99.609 (99.751)
2025-05-20 12:08:52 - INFO - TRAINING - Epoch: [78][20/196]	Time 0.143 (0.182)	Data 0.007 (0.048)	Loss 0.4360 (0.4794)	Prec@1 94.531 (92.690)	Prec@5 99.609 (99.758)
2025-05-20 12:08:54 - INFO - TRAINING - Epoch: [78][30/196]	Time 0.145 (0.169)	Data 0.000 (0.035)	Loss 0.4933 (0.4798)	Prec@1 91.406 (92.742)	Prec@5 100.000 (99.786)
2025-05-20 12:08:55 - INFO - TRAINING - Epoch: [78][40/196]	Time 0.148 (0.164)	Data 0.007 (0.027)	Loss 0.4704 (0.4799)	Prec@1 94.531 (92.797)	Prec@5 99.609 (99.809)
2025-05-20 12:08:57 - INFO - TRAINING - Epoch: [78][50/196]	Time 0.133 (0.159)	Data 0.000 (0.022)	Loss 0.4975 (0.4845)	Prec@1 92.969 (92.662)	Prec@5 99.609 (99.786)
2025-05-20 12:08:58 - INFO - TRAINING - Epoch: [78][60/196]	Time 0.133 (0.155)	Data 0.000 (0.019)	Loss 0.5016 (0.4848)	Prec@1 91.797 (92.687)	Prec@5 100.000 (99.795)
2025-05-20 12:08:59 - INFO - TRAINING - Epoch: [78][70/196]	Time 0.134 (0.152)	Data 0.000 (0.016)	Loss 0.5228 (0.4847)	Prec@1 91.797 (92.644)	Prec@5 100.000 (99.791)
2025-05-20 12:09:01 - INFO - TRAINING - Epoch: [78][80/196]	Time 0.132 (0.150)	Data 0.000 (0.015)	Loss 0.4929 (0.4838)	Prec@1 92.969 (92.708)	Prec@5 100.000 (99.807)
2025-05-20 12:09:02 - INFO - TRAINING - Epoch: [78][90/196]	Time 0.135 (0.148)	Data 0.000 (0.013)	Loss 0.5019 (0.4850)	Prec@1 91.016 (92.608)	Prec@5 98.828 (99.790)
2025-05-20 12:09:03 - INFO - TRAINING - Epoch: [78][100/196]	Time 0.134 (0.147)	Data 0.000 (0.012)	Loss 0.5243 (0.4840)	Prec@1 91.406 (92.659)	Prec@5 99.609 (99.795)
2025-05-20 12:09:05 - INFO - TRAINING - Epoch: [78][110/196]	Time 0.133 (0.146)	Data 0.000 (0.011)	Loss 0.4909 (0.4832)	Prec@1 92.188 (92.744)	Prec@5 100.000 (99.796)
2025-05-20 12:09:06 - INFO - TRAINING - Epoch: [78][120/196]	Time 0.147 (0.145)	Data 0.000 (0.010)	Loss 0.5214 (0.4825)	Prec@1 90.625 (92.749)	Prec@5 100.000 (99.797)
2025-05-20 12:09:07 - INFO - TRAINING - Epoch: [78][130/196]	Time 0.137 (0.145)	Data 0.022 (0.010)	Loss 0.5362 (0.4823)	Prec@1 89.453 (92.736)	Prec@5 100.000 (99.806)
2025-05-20 12:09:09 - INFO - TRAINING - Epoch: [78][140/196]	Time 0.154 (0.145)	Data 0.005 (0.010)	Loss 0.4561 (0.4825)	Prec@1 94.531 (92.706)	Prec@5 100.000 (99.803)
2025-05-20 12:09:10 - INFO - TRAINING - Epoch: [78][150/196]	Time 0.139 (0.145)	Data 0.000 (0.010)	Loss 0.4875 (0.4836)	Prec@1 92.578 (92.622)	Prec@5 99.609 (99.790)
2025-05-20 12:09:12 - INFO - TRAINING - Epoch: [78][160/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.5037 (0.4834)	Prec@1 91.406 (92.629)	Prec@5 99.219 (99.794)
2025-05-20 12:09:13 - INFO - TRAINING - Epoch: [78][170/196]	Time 0.133 (0.143)	Data 0.007 (0.009)	Loss 0.4613 (0.4838)	Prec@1 93.359 (92.608)	Prec@5 100.000 (99.792)
2025-05-20 12:09:14 - INFO - TRAINING - Epoch: [78][180/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.4606 (0.4833)	Prec@1 95.312 (92.643)	Prec@5 99.609 (99.786)
2025-05-20 12:09:16 - INFO - TRAINING - Epoch: [78][190/196]	Time 0.133 (0.142)	Data 0.000 (0.008)	Loss 0.4512 (0.4836)	Prec@1 94.141 (92.635)	Prec@5 100.000 (99.789)
2025-05-20 12:09:17 - INFO - EVALUATING - Epoch: [78][0/40]	Time 0.819 (0.819)	Data 0.750 (0.750)	Loss 0.6845 (0.6845)	Prec@1 84.766 (84.766)	Prec@5 98.828 (98.828)
2025-05-20 12:09:18 - INFO - EVALUATING - Epoch: [78][10/40]	Time 0.080 (0.148)	Data 0.011 (0.074)	Loss 0.6199 (0.6594)	Prec@1 87.500 (85.085)	Prec@5 99.219 (98.366)
2025-05-20 12:09:19 - INFO - EVALUATING - Epoch: [78][20/40]	Time 0.083 (0.115)	Data 0.009 (0.041)	Loss 0.5858 (0.6551)	Prec@1 89.453 (85.696)	Prec@5 98.438 (98.065)
2025-05-20 12:09:20 - INFO - EVALUATING - Epoch: [78][30/40]	Time 0.070 (0.103)	Data 0.000 (0.029)	Loss 0.7121 (0.6573)	Prec@1 84.375 (85.572)	Prec@5 97.656 (98.185)
2025-05-20 12:09:20 - INFO - 
 Epoch: 79	Training Loss 0.4835 	Training Prec@1 92.640 	Training Prec@5 99.792 	Validation Loss 0.6578 	Validation Prec@1 85.540 	Validation Prec@5 98.270 

2025-05-20 12:09:20 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:09:20 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:09:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:09:20 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:09:22 - INFO - TRAINING - Epoch: [79][0/196]	Time 1.416 (1.416)	Data 1.251 (1.251)	Loss 0.4504 (0.4504)	Prec@1 94.141 (94.141)	Prec@5 100.000 (100.000)
2025-05-20 12:09:23 - INFO - TRAINING - Epoch: [79][10/196]	Time 0.141 (0.267)	Data 0.020 (0.120)	Loss 0.5195 (0.4833)	Prec@1 90.625 (92.365)	Prec@5 99.219 (99.787)
2025-05-20 12:09:25 - INFO - TRAINING - Epoch: [79][20/196]	Time 0.138 (0.206)	Data 0.007 (0.064)	Loss 0.4812 (0.4846)	Prec@1 92.188 (92.634)	Prec@5 99.609 (99.777)
2025-05-20 12:09:26 - INFO - TRAINING - Epoch: [79][30/196]	Time 0.134 (0.183)	Data 0.000 (0.045)	Loss 0.5091 (0.4804)	Prec@1 91.406 (92.918)	Prec@5 99.609 (99.798)
2025-05-20 12:09:27 - INFO - TRAINING - Epoch: [79][40/196]	Time 0.133 (0.171)	Data 0.000 (0.034)	Loss 0.4671 (0.4805)	Prec@1 92.578 (92.845)	Prec@5 99.609 (99.800)
2025-05-20 12:09:29 - INFO - TRAINING - Epoch: [79][50/196]	Time 0.134 (0.164)	Data 0.005 (0.028)	Loss 0.4914 (0.4788)	Prec@1 91.797 (92.923)	Prec@5 99.609 (99.816)
2025-05-20 12:09:30 - INFO - TRAINING - Epoch: [79][60/196]	Time 0.133 (0.159)	Data 0.010 (0.024)	Loss 0.5021 (0.4805)	Prec@1 92.578 (92.905)	Prec@5 99.219 (99.795)
2025-05-20 12:09:31 - INFO - TRAINING - Epoch: [79][70/196]	Time 0.132 (0.155)	Data 0.001 (0.021)	Loss 0.5125 (0.4801)	Prec@1 92.578 (92.930)	Prec@5 99.609 (99.802)
2025-05-20 12:09:33 - INFO - TRAINING - Epoch: [79][80/196]	Time 0.132 (0.153)	Data 0.000 (0.019)	Loss 0.4405 (0.4799)	Prec@1 94.922 (92.988)	Prec@5 100.000 (99.812)
2025-05-20 12:09:34 - INFO - TRAINING - Epoch: [79][90/196]	Time 0.143 (0.152)	Data 0.000 (0.018)	Loss 0.5420 (0.4825)	Prec@1 88.281 (92.810)	Prec@5 99.609 (99.807)
2025-05-20 12:09:36 - INFO - TRAINING - Epoch: [79][100/196]	Time 0.138 (0.151)	Data 0.000 (0.017)	Loss 0.5128 (0.4821)	Prec@1 92.188 (92.795)	Prec@5 99.609 (99.822)
2025-05-20 12:09:37 - INFO - TRAINING - Epoch: [79][110/196]	Time 0.129 (0.150)	Data 0.000 (0.016)	Loss 0.4597 (0.4808)	Prec@1 92.969 (92.779)	Prec@5 100.000 (99.828)
2025-05-20 12:09:39 - INFO - TRAINING - Epoch: [79][120/196]	Time 0.161 (0.150)	Data 0.004 (0.015)	Loss 0.5318 (0.4821)	Prec@1 91.016 (92.714)	Prec@5 100.000 (99.819)
2025-05-20 12:09:40 - INFO - TRAINING - Epoch: [79][130/196]	Time 0.142 (0.150)	Data 0.011 (0.014)	Loss 0.4787 (0.4813)	Prec@1 92.188 (92.754)	Prec@5 100.000 (99.809)
2025-05-20 12:09:41 - INFO - TRAINING - Epoch: [79][140/196]	Time 0.129 (0.149)	Data 0.010 (0.014)	Loss 0.4524 (0.4827)	Prec@1 94.922 (92.661)	Prec@5 100.000 (99.803)
2025-05-20 12:09:43 - INFO - TRAINING - Epoch: [79][150/196]	Time 0.133 (0.148)	Data 0.000 (0.013)	Loss 0.4458 (0.4821)	Prec@1 94.922 (92.700)	Prec@5 99.609 (99.798)
2025-05-20 12:09:44 - INFO - TRAINING - Epoch: [79][160/196]	Time 0.134 (0.147)	Data 0.000 (0.013)	Loss 0.5067 (0.4832)	Prec@1 91.797 (92.670)	Prec@5 99.609 (99.791)
2025-05-20 12:09:45 - INFO - TRAINING - Epoch: [79][170/196]	Time 0.133 (0.147)	Data 0.000 (0.012)	Loss 0.4594 (0.4837)	Prec@1 93.750 (92.617)	Prec@5 100.000 (99.797)
2025-05-20 12:09:47 - INFO - TRAINING - Epoch: [79][180/196]	Time 0.138 (0.146)	Data 0.000 (0.012)	Loss 0.4424 (0.4848)	Prec@1 93.359 (92.576)	Prec@5 100.000 (99.791)
2025-05-20 12:09:48 - INFO - TRAINING - Epoch: [79][190/196]	Time 0.132 (0.146)	Data 0.000 (0.011)	Loss 0.5018 (0.4846)	Prec@1 89.453 (92.562)	Prec@5 99.609 (99.793)
2025-05-20 12:09:50 - INFO - EVALUATING - Epoch: [79][0/40]	Time 0.891 (0.891)	Data 0.819 (0.819)	Loss 0.6300 (0.6300)	Prec@1 87.109 (87.109)	Prec@5 98.828 (98.828)
2025-05-20 12:09:51 - INFO - EVALUATING - Epoch: [79][10/40]	Time 0.068 (0.151)	Data 0.000 (0.078)	Loss 0.5592 (0.6407)	Prec@1 91.406 (86.328)	Prec@5 98.828 (98.544)
2025-05-20 12:09:51 - INFO - EVALUATING - Epoch: [79][20/40]	Time 0.081 (0.116)	Data 0.003 (0.043)	Loss 0.6273 (0.6405)	Prec@1 86.719 (86.012)	Prec@5 98.438 (98.382)
2025-05-20 12:09:52 - INFO - EVALUATING - Epoch: [79][30/40]	Time 0.069 (0.102)	Data 0.000 (0.030)	Loss 0.6894 (0.6440)	Prec@1 82.422 (85.925)	Prec@5 98.047 (98.450)
2025-05-20 12:09:53 - INFO - 
 Epoch: 80	Training Loss 0.4848 	Training Prec@1 92.558 	Training Prec@5 99.796 	Validation Loss 0.6411 	Validation Prec@1 85.960 	Validation Prec@5 98.450 

2025-05-20 12:09:53 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:09:53 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:09:53 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:09:53 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:09:53 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:09:54 - INFO - TRAINING - Epoch: [80][0/196]	Time 0.911 (0.911)	Data 0.799 (0.799)	Loss 0.4502 (0.4502)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2025-05-20 12:09:55 - INFO - TRAINING - Epoch: [80][10/196]	Time 0.142 (0.213)	Data 0.003 (0.077)	Loss 0.5226 (0.4703)	Prec@1 90.625 (93.146)	Prec@5 99.609 (99.822)
2025-05-20 12:09:57 - INFO - TRAINING - Epoch: [80][20/196]	Time 0.135 (0.178)	Data 0.000 (0.042)	Loss 0.4353 (0.4624)	Prec@1 95.312 (93.527)	Prec@5 100.000 (99.814)
2025-05-20 12:09:58 - INFO - TRAINING - Epoch: [80][30/196]	Time 0.135 (0.164)	Data 0.000 (0.029)	Loss 0.4385 (0.4622)	Prec@1 95.703 (93.561)	Prec@5 100.000 (99.836)
2025-05-20 12:09:59 - INFO - TRAINING - Epoch: [80][40/196]	Time 0.144 (0.158)	Data 0.000 (0.023)	Loss 0.4808 (0.4624)	Prec@1 92.578 (93.550)	Prec@5 100.000 (99.848)
2025-05-20 12:10:01 - INFO - TRAINING - Epoch: [80][50/196]	Time 0.177 (0.156)	Data 0.017 (0.020)	Loss 0.4599 (0.4699)	Prec@1 92.969 (93.206)	Prec@5 100.000 (99.801)
2025-05-20 12:10:02 - INFO - TRAINING - Epoch: [80][60/196]	Time 0.139 (0.153)	Data 0.000 (0.018)	Loss 0.4330 (0.4704)	Prec@1 93.750 (93.142)	Prec@5 100.000 (99.795)
2025-05-20 12:10:04 - INFO - TRAINING - Epoch: [80][70/196]	Time 0.119 (0.151)	Data 0.007 (0.016)	Loss 0.4642 (0.4713)	Prec@1 93.750 (93.101)	Prec@5 100.000 (99.785)
2025-05-20 12:10:05 - INFO - TRAINING - Epoch: [80][80/196]	Time 0.134 (0.149)	Data 0.000 (0.015)	Loss 0.4577 (0.4702)	Prec@1 93.359 (93.157)	Prec@5 100.000 (99.793)
2025-05-20 12:10:06 - INFO - TRAINING - Epoch: [80][90/196]	Time 0.134 (0.147)	Data 0.000 (0.013)	Loss 0.4581 (0.4715)	Prec@1 93.750 (93.080)	Prec@5 100.000 (99.803)
2025-05-20 12:10:08 - INFO - TRAINING - Epoch: [80][100/196]	Time 0.135 (0.146)	Data 0.000 (0.012)	Loss 0.4799 (0.4714)	Prec@1 93.359 (93.054)	Prec@5 99.609 (99.795)
2025-05-20 12:10:09 - INFO - TRAINING - Epoch: [80][110/196]	Time 0.146 (0.145)	Data 0.023 (0.011)	Loss 0.4664 (0.4709)	Prec@1 93.750 (93.071)	Prec@5 99.609 (99.799)
2025-05-20 12:10:10 - INFO - TRAINING - Epoch: [80][120/196]	Time 0.134 (0.144)	Data 0.000 (0.010)	Loss 0.4800 (0.4701)	Prec@1 91.797 (93.104)	Prec@5 99.609 (99.793)
2025-05-20 12:10:12 - INFO - TRAINING - Epoch: [80][130/196]	Time 0.149 (0.143)	Data 0.000 (0.010)	Loss 0.5168 (0.4702)	Prec@1 91.797 (93.106)	Prec@5 99.219 (99.785)
2025-05-20 12:10:13 - INFO - TRAINING - Epoch: [80][140/196]	Time 0.149 (0.143)	Data 0.000 (0.009)	Loss 0.4936 (0.4699)	Prec@1 91.016 (93.129)	Prec@5 100.000 (99.784)
2025-05-20 12:10:15 - INFO - TRAINING - Epoch: [80][150/196]	Time 0.155 (0.144)	Data 0.019 (0.009)	Loss 0.4778 (0.4703)	Prec@1 93.359 (93.088)	Prec@5 99.609 (99.785)
2025-05-20 12:10:16 - INFO - TRAINING - Epoch: [80][160/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.4552 (0.4706)	Prec@1 94.141 (93.088)	Prec@5 100.000 (99.786)
2025-05-20 12:10:17 - INFO - TRAINING - Epoch: [80][170/196]	Time 0.137 (0.143)	Data 0.000 (0.009)	Loss 0.4676 (0.4701)	Prec@1 95.312 (93.124)	Prec@5 100.000 (99.797)
2025-05-20 12:10:19 - INFO - TRAINING - Epoch: [80][180/196]	Time 0.133 (0.142)	Data 0.000 (0.008)	Loss 0.4493 (0.4700)	Prec@1 95.312 (93.118)	Prec@5 99.609 (99.795)
2025-05-20 12:10:20 - INFO - TRAINING - Epoch: [80][190/196]	Time 0.132 (0.142)	Data 0.000 (0.008)	Loss 0.4933 (0.4702)	Prec@1 91.406 (93.134)	Prec@5 99.609 (99.798)
2025-05-20 12:10:21 - INFO - EVALUATING - Epoch: [80][0/40]	Time 0.695 (0.695)	Data 0.621 (0.621)	Loss 0.5921 (0.5921)	Prec@1 87.891 (87.891)	Prec@5 98.047 (98.047)
2025-05-20 12:10:22 - INFO - EVALUATING - Epoch: [80][10/40]	Time 0.079 (0.136)	Data 0.002 (0.060)	Loss 0.5566 (0.6197)	Prec@1 88.672 (86.683)	Prec@5 99.219 (98.438)
2025-05-20 12:10:23 - INFO - EVALUATING - Epoch: [80][20/40]	Time 0.086 (0.108)	Data 0.000 (0.033)	Loss 0.6117 (0.6258)	Prec@1 86.328 (86.254)	Prec@5 98.828 (98.568)
2025-05-20 12:10:24 - INFO - EVALUATING - Epoch: [80][30/40]	Time 0.070 (0.097)	Data 0.000 (0.023)	Loss 0.6432 (0.6248)	Prec@1 83.984 (86.202)	Prec@5 99.219 (98.715)
2025-05-20 12:10:25 - INFO - 
 Epoch: 81	Training Loss 0.4703 	Training Prec@1 93.122 	Training Prec@5 99.790 	Validation Loss 0.6257 	Validation Prec@1 86.280 	Validation Prec@5 98.690 

2025-05-20 12:10:25 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:10:25 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:10:25 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:10:25 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:10:25 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:10:26 - INFO - TRAINING - Epoch: [81][0/196]	Time 1.469 (1.469)	Data 1.305 (1.305)	Loss 0.4543 (0.4543)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
2025-05-20 12:10:27 - INFO - TRAINING - Epoch: [81][10/196]	Time 0.178 (0.265)	Data 0.000 (0.128)	Loss 0.4337 (0.4696)	Prec@1 93.750 (93.324)	Prec@5 100.000 (99.964)
2025-05-20 12:10:29 - INFO - TRAINING - Epoch: [81][20/196]	Time 0.153 (0.209)	Data 0.009 (0.069)	Loss 0.5163 (0.4797)	Prec@1 92.188 (92.857)	Prec@5 99.609 (99.907)
2025-05-20 12:10:30 - INFO - TRAINING - Epoch: [81][30/196]	Time 0.134 (0.186)	Data 0.000 (0.048)	Loss 0.4259 (0.4761)	Prec@1 95.703 (92.881)	Prec@5 100.000 (99.899)
2025-05-20 12:10:32 - INFO - TRAINING - Epoch: [81][40/196]	Time 0.135 (0.173)	Data 0.000 (0.036)	Loss 0.4422 (0.4744)	Prec@1 94.922 (92.988)	Prec@5 99.609 (99.867)
2025-05-20 12:10:33 - INFO - TRAINING - Epoch: [81][50/196]	Time 0.135 (0.166)	Data 0.000 (0.030)	Loss 0.4500 (0.4745)	Prec@1 93.750 (92.999)	Prec@5 100.000 (99.847)
2025-05-20 12:10:34 - INFO - TRAINING - Epoch: [81][60/196]	Time 0.134 (0.160)	Data 0.000 (0.025)	Loss 0.4440 (0.4736)	Prec@1 94.141 (92.994)	Prec@5 99.609 (99.814)
2025-05-20 12:10:36 - INFO - TRAINING - Epoch: [81][70/196]	Time 0.136 (0.157)	Data 0.000 (0.022)	Loss 0.4909 (0.4730)	Prec@1 92.188 (93.084)	Prec@5 100.000 (99.802)
2025-05-20 12:10:37 - INFO - TRAINING - Epoch: [81][80/196]	Time 0.135 (0.154)	Data 0.000 (0.019)	Loss 0.4445 (0.4717)	Prec@1 94.141 (93.147)	Prec@5 100.000 (99.817)
2025-05-20 12:10:38 - INFO - TRAINING - Epoch: [81][90/196]	Time 0.134 (0.152)	Data 0.000 (0.018)	Loss 0.4409 (0.4708)	Prec@1 94.531 (93.175)	Prec@5 100.000 (99.803)
2025-05-20 12:10:40 - INFO - TRAINING - Epoch: [81][100/196]	Time 0.141 (0.151)	Data 0.010 (0.016)	Loss 0.5383 (0.4718)	Prec@1 90.625 (93.135)	Prec@5 100.000 (99.803)
2025-05-20 12:10:41 - INFO - TRAINING - Epoch: [81][110/196]	Time 0.157 (0.152)	Data 0.007 (0.015)	Loss 0.4858 (0.4726)	Prec@1 93.750 (93.113)	Prec@5 100.000 (99.806)
2025-05-20 12:10:43 - INFO - TRAINING - Epoch: [81][120/196]	Time 0.140 (0.150)	Data 0.000 (0.014)	Loss 0.4859 (0.4740)	Prec@1 93.359 (93.037)	Prec@5 99.609 (99.803)
2025-05-20 12:10:44 - INFO - TRAINING - Epoch: [81][130/196]	Time 0.134 (0.149)	Data 0.000 (0.013)	Loss 0.4591 (0.4738)	Prec@1 94.141 (93.002)	Prec@5 99.609 (99.797)
2025-05-20 12:10:45 - INFO - TRAINING - Epoch: [81][140/196]	Time 0.132 (0.148)	Data 0.008 (0.013)	Loss 0.4709 (0.4736)	Prec@1 92.188 (92.996)	Prec@5 99.609 (99.776)
2025-05-20 12:10:47 - INFO - TRAINING - Epoch: [81][150/196]	Time 0.134 (0.147)	Data 0.000 (0.012)	Loss 0.4359 (0.4739)	Prec@1 95.312 (92.969)	Prec@5 100.000 (99.780)
2025-05-20 12:10:48 - INFO - TRAINING - Epoch: [81][160/196]	Time 0.133 (0.146)	Data 0.012 (0.011)	Loss 0.4593 (0.4737)	Prec@1 94.531 (92.957)	Prec@5 100.000 (99.779)
2025-05-20 12:10:49 - INFO - TRAINING - Epoch: [81][170/196]	Time 0.134 (0.146)	Data 0.000 (0.011)	Loss 0.4500 (0.4736)	Prec@1 94.141 (92.960)	Prec@5 100.000 (99.781)
2025-05-20 12:10:51 - INFO - TRAINING - Epoch: [81][180/196]	Time 0.131 (0.145)	Data 0.000 (0.010)	Loss 0.4486 (0.4740)	Prec@1 94.531 (92.934)	Prec@5 100.000 (99.780)
2025-05-20 12:10:52 - INFO - TRAINING - Epoch: [81][190/196]	Time 0.132 (0.144)	Data 0.000 (0.010)	Loss 0.4672 (0.4743)	Prec@1 92.578 (92.924)	Prec@5 100.000 (99.777)
2025-05-20 12:10:54 - INFO - EVALUATING - Epoch: [81][0/40]	Time 1.197 (1.197)	Data 1.112 (1.112)	Loss 0.6113 (0.6113)	Prec@1 87.500 (87.500)	Prec@5 98.047 (98.047)
2025-05-20 12:10:55 - INFO - EVALUATING - Epoch: [81][10/40]	Time 0.081 (0.182)	Data 0.013 (0.105)	Loss 0.6159 (0.6301)	Prec@1 88.672 (86.790)	Prec@5 99.219 (98.757)
2025-05-20 12:10:56 - INFO - EVALUATING - Epoch: [81][20/40]	Time 0.081 (0.133)	Data 0.007 (0.057)	Loss 0.6137 (0.6294)	Prec@1 87.891 (86.756)	Prec@5 98.438 (98.661)
2025-05-20 12:10:56 - INFO - EVALUATING - Epoch: [81][30/40]	Time 0.070 (0.114)	Data 0.000 (0.040)	Loss 0.6714 (0.6327)	Prec@1 83.984 (86.404)	Prec@5 99.219 (98.753)
2025-05-20 12:10:57 - INFO - 
 Epoch: 82	Training Loss 0.4744 	Training Prec@1 92.920 	Training Prec@5 99.770 	Validation Loss 0.6312 	Validation Prec@1 86.420 	Validation Prec@5 98.730 

2025-05-20 12:10:57 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:10:57 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:10:57 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:10:57 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:10:57 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:10:58 - INFO - TRAINING - Epoch: [82][0/196]	Time 0.959 (0.959)	Data 0.848 (0.848)	Loss 0.4500 (0.4500)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
2025-05-20 12:11:00 - INFO - TRAINING - Epoch: [82][10/196]	Time 0.152 (0.220)	Data 0.005 (0.086)	Loss 0.4910 (0.4675)	Prec@1 92.188 (93.572)	Prec@5 99.219 (99.751)
2025-05-20 12:11:01 - INFO - TRAINING - Epoch: [82][20/196]	Time 0.134 (0.180)	Data 0.000 (0.047)	Loss 0.4801 (0.4682)	Prec@1 92.578 (93.527)	Prec@5 99.609 (99.814)
2025-05-20 12:11:02 - INFO - TRAINING - Epoch: [82][30/196]	Time 0.133 (0.165)	Data 0.000 (0.032)	Loss 0.4837 (0.4665)	Prec@1 93.359 (93.473)	Prec@5 100.000 (99.849)
2025-05-20 12:11:04 - INFO - TRAINING - Epoch: [82][40/196]	Time 0.133 (0.158)	Data 0.000 (0.025)	Loss 0.4620 (0.4686)	Prec@1 93.359 (93.388)	Prec@5 100.000 (99.838)
2025-05-20 12:11:05 - INFO - TRAINING - Epoch: [82][50/196]	Time 0.135 (0.155)	Data 0.000 (0.021)	Loss 0.4758 (0.4686)	Prec@1 92.969 (93.405)	Prec@5 99.609 (99.816)
2025-05-20 12:11:07 - INFO - TRAINING - Epoch: [82][60/196]	Time 0.178 (0.153)	Data 0.014 (0.018)	Loss 0.4739 (0.4691)	Prec@1 92.578 (93.385)	Prec@5 100.000 (99.801)
2025-05-20 12:11:08 - INFO - TRAINING - Epoch: [82][70/196]	Time 0.141 (0.152)	Data 0.000 (0.016)	Loss 0.4506 (0.4677)	Prec@1 92.969 (93.381)	Prec@5 100.000 (99.824)
2025-05-20 12:11:09 - INFO - TRAINING - Epoch: [82][80/196]	Time 0.134 (0.150)	Data 0.006 (0.015)	Loss 0.4992 (0.4685)	Prec@1 92.969 (93.403)	Prec@5 100.000 (99.822)
2025-05-20 12:11:11 - INFO - TRAINING - Epoch: [82][90/196]	Time 0.134 (0.148)	Data 0.000 (0.013)	Loss 0.4961 (0.4687)	Prec@1 89.844 (93.359)	Prec@5 99.609 (99.811)
2025-05-20 12:11:12 - INFO - TRAINING - Epoch: [82][100/196]	Time 0.134 (0.147)	Data 0.000 (0.012)	Loss 0.4643 (0.4680)	Prec@1 92.969 (93.371)	Prec@5 100.000 (99.810)
2025-05-20 12:11:13 - INFO - TRAINING - Epoch: [82][110/196]	Time 0.135 (0.146)	Data 0.008 (0.012)	Loss 0.5021 (0.4675)	Prec@1 91.797 (93.409)	Prec@5 99.219 (99.813)
2025-05-20 12:11:15 - INFO - TRAINING - Epoch: [82][120/196]	Time 0.135 (0.145)	Data 0.000 (0.011)	Loss 0.4511 (0.4677)	Prec@1 94.922 (93.408)	Prec@5 100.000 (99.797)
2025-05-20 12:11:16 - INFO - TRAINING - Epoch: [82][130/196]	Time 0.133 (0.144)	Data 0.000 (0.010)	Loss 0.4215 (0.4679)	Prec@1 93.750 (93.383)	Prec@5 100.000 (99.794)
2025-05-20 12:11:17 - INFO - TRAINING - Epoch: [82][140/196]	Time 0.136 (0.143)	Data 0.008 (0.010)	Loss 0.4823 (0.4679)	Prec@1 91.016 (93.395)	Prec@5 100.000 (99.789)
2025-05-20 12:11:19 - INFO - TRAINING - Epoch: [82][150/196]	Time 0.146 (0.143)	Data 0.014 (0.009)	Loss 0.4056 (0.4679)	Prec@1 96.094 (93.372)	Prec@5 100.000 (99.793)
2025-05-20 12:11:20 - INFO - TRAINING - Epoch: [82][160/196]	Time 0.147 (0.144)	Data 0.019 (0.009)	Loss 0.4847 (0.4694)	Prec@1 93.750 (93.308)	Prec@5 99.219 (99.791)
2025-05-20 12:11:22 - INFO - TRAINING - Epoch: [82][170/196]	Time 0.134 (0.143)	Data 0.007 (0.009)	Loss 0.4721 (0.4700)	Prec@1 92.969 (93.273)	Prec@5 99.609 (99.792)
2025-05-20 12:11:23 - INFO - TRAINING - Epoch: [82][180/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.4265 (0.4706)	Prec@1 96.484 (93.264)	Prec@5 100.000 (99.799)
2025-05-20 12:11:24 - INFO - TRAINING - Epoch: [82][190/196]	Time 0.133 (0.142)	Data 0.000 (0.009)	Loss 0.5383 (0.4706)	Prec@1 90.625 (93.251)	Prec@5 99.609 (99.804)
2025-05-20 12:11:26 - INFO - EVALUATING - Epoch: [82][0/40]	Time 0.719 (0.719)	Data 0.651 (0.651)	Loss 0.5917 (0.5917)	Prec@1 89.844 (89.844)	Prec@5 98.828 (98.828)
2025-05-20 12:11:27 - INFO - EVALUATING - Epoch: [82][10/40]	Time 0.082 (0.142)	Data 0.006 (0.067)	Loss 0.5617 (0.6221)	Prec@1 89.062 (86.790)	Prec@5 98.828 (98.615)
2025-05-20 12:11:27 - INFO - EVALUATING - Epoch: [82][20/40]	Time 0.085 (0.111)	Data 0.003 (0.037)	Loss 0.6125 (0.6270)	Prec@1 88.672 (86.756)	Prec@5 98.828 (98.512)
2025-05-20 12:11:28 - INFO - EVALUATING - Epoch: [82][30/40]	Time 0.070 (0.100)	Data 0.000 (0.026)	Loss 0.6379 (0.6283)	Prec@1 85.938 (86.517)	Prec@5 99.219 (98.677)
2025-05-20 12:11:29 - INFO - 
 Epoch: 83	Training Loss 0.4707 	Training Prec@1 93.252 	Training Prec@5 99.804 	Validation Loss 0.6279 	Validation Prec@1 86.470 	Validation Prec@5 98.680 

2025-05-20 12:11:29 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:11:29 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:11:29 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:11:29 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:11:29 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:11:30 - INFO - TRAINING - Epoch: [83][0/196]	Time 0.962 (0.962)	Data 0.845 (0.845)	Loss 0.4559 (0.4559)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2025-05-20 12:11:32 - INFO - TRAINING - Epoch: [83][10/196]	Time 0.154 (0.230)	Data 0.000 (0.081)	Loss 0.4988 (0.4797)	Prec@1 92.188 (93.288)	Prec@5 99.609 (99.716)
2025-05-20 12:11:33 - INFO - TRAINING - Epoch: [83][20/196]	Time 0.135 (0.197)	Data 0.000 (0.048)	Loss 0.4279 (0.4785)	Prec@1 95.312 (93.006)	Prec@5 99.609 (99.647)
2025-05-20 12:11:35 - INFO - TRAINING - Epoch: [83][30/196]	Time 0.152 (0.181)	Data 0.002 (0.035)	Loss 0.4414 (0.4768)	Prec@1 94.531 (93.007)	Prec@5 100.000 (99.698)
2025-05-20 12:11:36 - INFO - TRAINING - Epoch: [83][40/196]	Time 0.134 (0.170)	Data 0.007 (0.027)	Loss 0.4810 (0.4743)	Prec@1 91.797 (93.131)	Prec@5 100.000 (99.733)
2025-05-20 12:11:37 - INFO - TRAINING - Epoch: [83][50/196]	Time 0.134 (0.163)	Data 0.007 (0.022)	Loss 0.4966 (0.4691)	Prec@1 91.016 (93.313)	Prec@5 100.000 (99.763)
2025-05-20 12:11:39 - INFO - TRAINING - Epoch: [83][60/196]	Time 0.128 (0.158)	Data 0.000 (0.019)	Loss 0.4755 (0.4691)	Prec@1 91.797 (93.302)	Prec@5 99.609 (99.776)
2025-05-20 12:11:40 - INFO - TRAINING - Epoch: [83][70/196]	Time 0.133 (0.155)	Data 0.000 (0.017)	Loss 0.4735 (0.4692)	Prec@1 93.359 (93.299)	Prec@5 99.609 (99.763)
2025-05-20 12:11:41 - INFO - TRAINING - Epoch: [83][80/196]	Time 0.132 (0.152)	Data 0.000 (0.015)	Loss 0.5208 (0.4710)	Prec@1 91.406 (93.191)	Prec@5 99.219 (99.773)
2025-05-20 12:11:43 - INFO - TRAINING - Epoch: [83][90/196]	Time 0.132 (0.151)	Data 0.000 (0.013)	Loss 0.4550 (0.4720)	Prec@1 94.531 (93.140)	Prec@5 100.000 (99.781)
2025-05-20 12:11:44 - INFO - TRAINING - Epoch: [83][100/196]	Time 0.136 (0.149)	Data 0.009 (0.012)	Loss 0.5359 (0.4738)	Prec@1 90.625 (93.077)	Prec@5 100.000 (99.787)
2025-05-20 12:11:46 - INFO - TRAINING - Epoch: [83][110/196]	Time 0.148 (0.149)	Data 0.012 (0.012)	Loss 0.4165 (0.4734)	Prec@1 96.484 (93.092)	Prec@5 100.000 (99.796)
2025-05-20 12:11:47 - INFO - TRAINING - Epoch: [83][120/196]	Time 0.143 (0.149)	Data 0.005 (0.012)	Loss 0.4510 (0.4724)	Prec@1 94.531 (93.159)	Prec@5 100.000 (99.793)
2025-05-20 12:11:48 - INFO - TRAINING - Epoch: [83][130/196]	Time 0.135 (0.148)	Data 0.008 (0.011)	Loss 0.4449 (0.4721)	Prec@1 96.094 (93.219)	Prec@5 100.000 (99.794)
2025-05-20 12:11:50 - INFO - TRAINING - Epoch: [83][140/196]	Time 0.133 (0.147)	Data 0.000 (0.010)	Loss 0.5042 (0.4722)	Prec@1 91.016 (93.229)	Prec@5 99.609 (99.795)
2025-05-20 12:11:51 - INFO - TRAINING - Epoch: [83][150/196]	Time 0.132 (0.146)	Data 0.000 (0.010)	Loss 0.4581 (0.4724)	Prec@1 94.141 (93.220)	Prec@5 99.609 (99.793)
2025-05-20 12:11:52 - INFO - TRAINING - Epoch: [83][160/196]	Time 0.133 (0.145)	Data 0.000 (0.009)	Loss 0.4799 (0.4722)	Prec@1 90.625 (93.216)	Prec@5 100.000 (99.789)
2025-05-20 12:11:54 - INFO - TRAINING - Epoch: [83][170/196]	Time 0.133 (0.144)	Data 0.007 (0.009)	Loss 0.4784 (0.4723)	Prec@1 92.188 (93.225)	Prec@5 100.000 (99.785)
2025-05-20 12:11:55 - INFO - TRAINING - Epoch: [83][180/196]	Time 0.131 (0.144)	Data 0.000 (0.008)	Loss 0.4825 (0.4720)	Prec@1 91.797 (93.230)	Prec@5 99.609 (99.776)
2025-05-20 12:11:56 - INFO - TRAINING - Epoch: [83][190/196]	Time 0.132 (0.143)	Data 0.000 (0.008)	Loss 0.4244 (0.4710)	Prec@1 96.094 (93.271)	Prec@5 99.609 (99.779)
2025-05-20 12:11:58 - INFO - EVALUATING - Epoch: [83][0/40]	Time 1.198 (1.198)	Data 1.099 (1.099)	Loss 0.5715 (0.5715)	Prec@1 87.891 (87.891)	Prec@5 99.219 (99.219)
2025-05-20 12:11:59 - INFO - EVALUATING - Epoch: [83][10/40]	Time 0.084 (0.200)	Data 0.000 (0.119)	Loss 0.5873 (0.6238)	Prec@1 87.500 (86.435)	Prec@5 98.828 (98.295)
2025-05-20 12:12:00 - INFO - EVALUATING - Epoch: [83][20/40]	Time 0.076 (0.147)	Data 0.000 (0.068)	Loss 0.5896 (0.6251)	Prec@1 87.109 (86.347)	Prec@5 99.219 (98.233)
2025-05-20 12:12:01 - INFO - EVALUATING - Epoch: [83][30/40]	Time 0.070 (0.123)	Data 0.000 (0.047)	Loss 0.6513 (0.6248)	Prec@1 85.938 (86.328)	Prec@5 98.828 (98.387)
2025-05-20 12:12:02 - INFO - 
 Epoch: 84	Training Loss 0.4715 	Training Prec@1 93.254 	Training Prec@5 99.776 	Validation Loss 0.6237 	Validation Prec@1 86.260 	Validation Prec@5 98.440 

2025-05-20 12:12:02 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:12:02 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:12:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:12:02 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:12:02 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:12:03 - INFO - TRAINING - Epoch: [84][0/196]	Time 1.055 (1.055)	Data 0.941 (0.941)	Loss 0.4475 (0.4475)	Prec@1 94.922 (94.922)	Prec@5 99.609 (99.609)
2025-05-20 12:12:04 - INFO - TRAINING - Epoch: [84][10/196]	Time 0.137 (0.224)	Data 0.017 (0.091)	Loss 0.4762 (0.4768)	Prec@1 95.312 (93.324)	Prec@5 99.609 (99.680)
2025-05-20 12:12:06 - INFO - TRAINING - Epoch: [84][20/196]	Time 0.133 (0.182)	Data 0.000 (0.050)	Loss 0.4632 (0.4724)	Prec@1 93.750 (93.248)	Prec@5 100.000 (99.758)
2025-05-20 12:12:07 - INFO - TRAINING - Epoch: [84][30/196]	Time 0.135 (0.166)	Data 0.000 (0.035)	Loss 0.4944 (0.4698)	Prec@1 91.797 (93.435)	Prec@5 100.000 (99.811)
2025-05-20 12:12:08 - INFO - TRAINING - Epoch: [84][40/196]	Time 0.134 (0.158)	Data 0.003 (0.027)	Loss 0.4674 (0.4682)	Prec@1 93.359 (93.464)	Prec@5 100.000 (99.790)
2025-05-20 12:12:10 - INFO - TRAINING - Epoch: [84][50/196]	Time 0.134 (0.153)	Data 0.006 (0.022)	Loss 0.5388 (0.4700)	Prec@1 90.625 (93.336)	Prec@5 100.000 (99.747)
2025-05-20 12:12:11 - INFO - TRAINING - Epoch: [84][60/196]	Time 0.153 (0.152)	Data 0.000 (0.019)	Loss 0.4498 (0.4711)	Prec@1 92.969 (93.276)	Prec@5 100.000 (99.750)
2025-05-20 12:12:13 - INFO - TRAINING - Epoch: [84][70/196]	Time 0.137 (0.151)	Data 0.000 (0.017)	Loss 0.4593 (0.4705)	Prec@1 92.969 (93.249)	Prec@5 99.609 (99.774)
2025-05-20 12:12:14 - INFO - TRAINING - Epoch: [84][80/196]	Time 0.160 (0.150)	Data 0.000 (0.016)	Loss 0.4848 (0.4723)	Prec@1 92.969 (93.142)	Prec@5 99.219 (99.754)
2025-05-20 12:12:15 - INFO - TRAINING - Epoch: [84][90/196]	Time 0.133 (0.148)	Data 0.000 (0.014)	Loss 0.5339 (0.4729)	Prec@1 89.844 (93.098)	Prec@5 99.219 (99.738)
2025-05-20 12:12:17 - INFO - TRAINING - Epoch: [84][100/196]	Time 0.133 (0.147)	Data 0.000 (0.013)	Loss 0.4717 (0.4720)	Prec@1 94.141 (93.123)	Prec@5 99.609 (99.756)
2025-05-20 12:12:18 - INFO - TRAINING - Epoch: [84][110/196]	Time 0.132 (0.146)	Data 0.000 (0.012)	Loss 0.5024 (0.4731)	Prec@1 90.625 (93.113)	Prec@5 99.609 (99.747)
2025-05-20 12:12:19 - INFO - TRAINING - Epoch: [84][120/196]	Time 0.133 (0.145)	Data 0.000 (0.011)	Loss 0.4575 (0.4727)	Prec@1 94.141 (93.159)	Prec@5 100.000 (99.764)
2025-05-20 12:12:21 - INFO - TRAINING - Epoch: [84][130/196]	Time 0.133 (0.144)	Data 0.007 (0.011)	Loss 0.5249 (0.4723)	Prec@1 90.625 (93.139)	Prec@5 99.609 (99.770)
2025-05-20 12:12:22 - INFO - TRAINING - Epoch: [84][140/196]	Time 0.143 (0.143)	Data 0.000 (0.010)	Loss 0.4895 (0.4724)	Prec@1 93.359 (93.171)	Prec@5 100.000 (99.770)
2025-05-20 12:12:23 - INFO - TRAINING - Epoch: [84][150/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.4897 (0.4736)	Prec@1 92.969 (93.127)	Prec@5 100.000 (99.770)
2025-05-20 12:12:25 - INFO - TRAINING - Epoch: [84][160/196]	Time 0.144 (0.142)	Data 0.002 (0.009)	Loss 0.4904 (0.4729)	Prec@1 93.750 (93.163)	Prec@5 99.219 (99.772)
2025-05-20 12:12:26 - INFO - TRAINING - Epoch: [84][170/196]	Time 0.156 (0.143)	Data 0.013 (0.009)	Loss 0.4782 (0.4730)	Prec@1 92.578 (93.170)	Prec@5 100.000 (99.778)
2025-05-20 12:12:28 - INFO - TRAINING - Epoch: [84][180/196]	Time 0.129 (0.143)	Data 0.000 (0.009)	Loss 0.4872 (0.4730)	Prec@1 92.188 (93.169)	Prec@5 99.219 (99.773)
2025-05-20 12:12:29 - INFO - TRAINING - Epoch: [84][190/196]	Time 0.132 (0.142)	Data 0.000 (0.008)	Loss 0.4397 (0.4718)	Prec@1 94.531 (93.235)	Prec@5 99.609 (99.775)
2025-05-20 12:12:30 - INFO - EVALUATING - Epoch: [84][0/40]	Time 0.724 (0.724)	Data 0.651 (0.651)	Loss 0.6119 (0.6119)	Prec@1 86.328 (86.328)	Prec@5 99.219 (99.219)
2025-05-20 12:12:31 - INFO - EVALUATING - Epoch: [84][10/40]	Time 0.075 (0.139)	Data 0.000 (0.063)	Loss 0.5780 (0.6231)	Prec@1 89.453 (86.506)	Prec@5 99.609 (98.757)
2025-05-20 12:12:32 - INFO - EVALUATING - Epoch: [84][20/40]	Time 0.074 (0.110)	Data 0.000 (0.036)	Loss 0.5993 (0.6268)	Prec@1 87.891 (86.310)	Prec@5 98.828 (98.568)
2025-05-20 12:12:33 - INFO - EVALUATING - Epoch: [84][30/40]	Time 0.070 (0.098)	Data 0.000 (0.024)	Loss 0.6540 (0.6277)	Prec@1 83.984 (86.227)	Prec@5 98.828 (98.677)
2025-05-20 12:12:34 - INFO - 
 Epoch: 85	Training Loss 0.4712 	Training Prec@1 93.274 	Training Prec@5 99.780 	Validation Loss 0.6287 	Validation Prec@1 86.260 	Validation Prec@5 98.670 

2025-05-20 12:12:34 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:12:34 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:12:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:12:34 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:12:34 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:12:35 - INFO - TRAINING - Epoch: [85][0/196]	Time 0.994 (0.994)	Data 0.881 (0.881)	Loss 0.4214 (0.4214)	Prec@1 95.312 (95.312)	Prec@5 99.609 (99.609)
2025-05-20 12:12:36 - INFO - TRAINING - Epoch: [85][10/196]	Time 0.150 (0.220)	Data 0.001 (0.086)	Loss 0.4939 (0.4555)	Prec@1 92.188 (93.892)	Prec@5 99.609 (99.822)
2025-05-20 12:12:37 - INFO - TRAINING - Epoch: [85][20/196]	Time 0.155 (0.184)	Data 0.000 (0.048)	Loss 0.5072 (0.4665)	Prec@1 92.188 (93.378)	Prec@5 100.000 (99.721)
2025-05-20 12:12:39 - INFO - TRAINING - Epoch: [85][30/196]	Time 0.153 (0.171)	Data 0.000 (0.033)	Loss 0.4585 (0.4692)	Prec@1 93.750 (93.208)	Prec@5 100.000 (99.761)
2025-05-20 12:12:40 - INFO - TRAINING - Epoch: [85][40/196]	Time 0.154 (0.165)	Data 0.008 (0.027)	Loss 0.4764 (0.4678)	Prec@1 92.578 (93.207)	Prec@5 99.609 (99.762)
2025-05-20 12:12:42 - INFO - TRAINING - Epoch: [85][50/196]	Time 0.133 (0.159)	Data 0.000 (0.023)	Loss 0.5234 (0.4716)	Prec@1 91.797 (93.099)	Prec@5 99.609 (99.763)
2025-05-20 12:12:43 - INFO - TRAINING - Epoch: [85][60/196]	Time 0.133 (0.155)	Data 0.008 (0.020)	Loss 0.4594 (0.4703)	Prec@1 92.969 (93.154)	Prec@5 100.000 (99.769)
2025-05-20 12:12:44 - INFO - TRAINING - Epoch: [85][70/196]	Time 0.142 (0.153)	Data 0.000 (0.018)	Loss 0.4495 (0.4703)	Prec@1 94.141 (93.134)	Prec@5 100.000 (99.769)
2025-05-20 12:12:46 - INFO - TRAINING - Epoch: [85][80/196]	Time 0.133 (0.150)	Data 0.001 (0.016)	Loss 0.4817 (0.4687)	Prec@1 91.406 (93.195)	Prec@5 100.000 (99.788)
2025-05-20 12:12:47 - INFO - TRAINING - Epoch: [85][90/196]	Time 0.133 (0.149)	Data 0.000 (0.014)	Loss 0.4995 (0.4693)	Prec@1 91.406 (93.166)	Prec@5 99.609 (99.794)
2025-05-20 12:12:48 - INFO - TRAINING - Epoch: [85][100/196]	Time 0.134 (0.147)	Data 0.000 (0.013)	Loss 0.4145 (0.4680)	Prec@1 95.703 (93.189)	Prec@5 100.000 (99.799)
2025-05-20 12:12:50 - INFO - TRAINING - Epoch: [85][110/196]	Time 0.134 (0.146)	Data 0.007 (0.012)	Loss 0.4691 (0.4675)	Prec@1 94.531 (93.250)	Prec@5 99.609 (99.799)
2025-05-20 12:12:51 - INFO - TRAINING - Epoch: [85][120/196]	Time 0.137 (0.145)	Data 0.000 (0.011)	Loss 0.4825 (0.4667)	Prec@1 92.188 (93.295)	Prec@5 99.609 (99.803)
2025-05-20 12:12:53 - INFO - TRAINING - Epoch: [85][130/196]	Time 0.121 (0.146)	Data 0.000 (0.011)	Loss 0.4590 (0.4672)	Prec@1 94.141 (93.303)	Prec@5 99.609 (99.797)
2025-05-20 12:12:54 - INFO - TRAINING - Epoch: [85][140/196]	Time 0.133 (0.146)	Data 0.000 (0.010)	Loss 0.4675 (0.4677)	Prec@1 93.750 (93.257)	Prec@5 99.609 (99.795)
2025-05-20 12:12:55 - INFO - TRAINING - Epoch: [85][150/196]	Time 0.132 (0.145)	Data 0.000 (0.010)	Loss 0.5005 (0.4688)	Prec@1 91.797 (93.212)	Prec@5 100.000 (99.780)
2025-05-20 12:12:57 - INFO - TRAINING - Epoch: [85][160/196]	Time 0.133 (0.144)	Data 0.000 (0.010)	Loss 0.4675 (0.4682)	Prec@1 93.750 (93.226)	Prec@5 100.000 (99.779)
2025-05-20 12:12:58 - INFO - TRAINING - Epoch: [85][170/196]	Time 0.137 (0.144)	Data 0.000 (0.009)	Loss 0.4648 (0.4680)	Prec@1 92.969 (93.241)	Prec@5 100.000 (99.785)
2025-05-20 12:12:59 - INFO - TRAINING - Epoch: [85][180/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.4801 (0.4682)	Prec@1 93.359 (93.230)	Prec@5 99.609 (99.789)
2025-05-20 12:13:01 - INFO - TRAINING - Epoch: [85][190/196]	Time 0.132 (0.143)	Data 0.000 (0.008)	Loss 0.5079 (0.4686)	Prec@1 91.797 (93.200)	Prec@5 99.219 (99.789)
2025-05-20 12:13:02 - INFO - EVALUATING - Epoch: [85][0/40]	Time 0.660 (0.660)	Data 0.581 (0.581)	Loss 0.6290 (0.6290)	Prec@1 85.547 (85.547)	Prec@5 98.438 (98.438)
2025-05-20 12:13:03 - INFO - EVALUATING - Epoch: [85][10/40]	Time 0.079 (0.138)	Data 0.000 (0.062)	Loss 0.6179 (0.6553)	Prec@1 86.719 (85.156)	Prec@5 99.219 (98.189)
2025-05-20 12:13:04 - INFO - EVALUATING - Epoch: [85][20/40]	Time 0.070 (0.110)	Data 0.000 (0.035)	Loss 0.6326 (0.6501)	Prec@1 88.281 (85.658)	Prec@5 98.828 (98.047)
2025-05-20 12:13:05 - INFO - EVALUATING - Epoch: [85][30/40]	Time 0.079 (0.101)	Data 0.000 (0.025)	Loss 0.6934 (0.6505)	Prec@1 81.641 (85.685)	Prec@5 98.047 (98.072)
2025-05-20 12:13:06 - INFO - 
 Epoch: 86	Training Loss 0.4687 	Training Prec@1 93.196 	Training Prec@5 99.792 	Validation Loss 0.6523 	Validation Prec@1 85.650 	Validation Prec@5 98.100 

2025-05-20 12:13:06 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:13:06 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:13:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:13:06 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:13:06 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:13:07 - INFO - TRAINING - Epoch: [86][0/196]	Time 1.381 (1.381)	Data 1.262 (1.262)	Loss 0.4556 (0.4556)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2025-05-20 12:13:08 - INFO - TRAINING - Epoch: [86][10/196]	Time 0.135 (0.256)	Data 0.000 (0.120)	Loss 0.4371 (0.4680)	Prec@1 94.922 (93.786)	Prec@5 100.000 (99.929)
2025-05-20 12:13:10 - INFO - TRAINING - Epoch: [86][20/196]	Time 0.133 (0.199)	Data 0.009 (0.065)	Loss 0.4962 (0.4666)	Prec@1 93.359 (93.769)	Prec@5 99.609 (99.907)
2025-05-20 12:13:11 - INFO - TRAINING - Epoch: [86][30/196]	Time 0.132 (0.178)	Data 0.000 (0.044)	Loss 0.4410 (0.4650)	Prec@1 94.922 (93.788)	Prec@5 100.000 (99.874)
2025-05-20 12:13:12 - INFO - TRAINING - Epoch: [86][40/196]	Time 0.132 (0.167)	Data 0.000 (0.034)	Loss 0.4455 (0.4603)	Prec@1 94.922 (94.026)	Prec@5 100.000 (99.905)
2025-05-20 12:13:14 - INFO - TRAINING - Epoch: [86][50/196]	Time 0.134 (0.161)	Data 0.000 (0.028)	Loss 0.4598 (0.4619)	Prec@1 93.750 (93.903)	Prec@5 99.609 (99.870)
2025-05-20 12:13:15 - INFO - TRAINING - Epoch: [86][60/196]	Time 0.146 (0.157)	Data 0.020 (0.024)	Loss 0.5260 (0.4637)	Prec@1 89.844 (93.782)	Prec@5 100.000 (99.840)
2025-05-20 12:13:17 - INFO - TRAINING - Epoch: [86][70/196]	Time 0.135 (0.154)	Data 0.000 (0.021)	Loss 0.5132 (0.4651)	Prec@1 92.578 (93.695)	Prec@5 100.000 (99.857)
2025-05-20 12:13:18 - INFO - TRAINING - Epoch: [86][80/196]	Time 0.137 (0.152)	Data 0.012 (0.019)	Loss 0.5011 (0.4669)	Prec@1 92.969 (93.557)	Prec@5 99.219 (99.851)
2025-05-20 12:13:19 - INFO - TRAINING - Epoch: [86][90/196]	Time 0.150 (0.151)	Data 0.000 (0.018)	Loss 0.4468 (0.4666)	Prec@1 94.531 (93.574)	Prec@5 99.609 (99.850)
2025-05-20 12:13:21 - INFO - TRAINING - Epoch: [86][100/196]	Time 0.133 (0.150)	Data 0.007 (0.017)	Loss 0.4632 (0.4662)	Prec@1 92.578 (93.560)	Prec@5 100.000 (99.841)
2025-05-20 12:13:22 - INFO - TRAINING - Epoch: [86][110/196]	Time 0.132 (0.148)	Data 0.000 (0.016)	Loss 0.4596 (0.4672)	Prec@1 93.750 (93.500)	Prec@5 100.000 (99.828)
2025-05-20 12:13:23 - INFO - TRAINING - Epoch: [86][120/196]	Time 0.134 (0.147)	Data 0.000 (0.014)	Loss 0.4526 (0.4676)	Prec@1 92.969 (93.463)	Prec@5 100.000 (99.826)
2025-05-20 12:13:25 - INFO - TRAINING - Epoch: [86][130/196]	Time 0.133 (0.146)	Data 0.000 (0.013)	Loss 0.4794 (0.4677)	Prec@1 92.969 (93.508)	Prec@5 100.000 (99.818)
2025-05-20 12:13:26 - INFO - TRAINING - Epoch: [86][140/196]	Time 0.133 (0.145)	Data 0.000 (0.013)	Loss 0.4678 (0.4681)	Prec@1 93.359 (93.467)	Prec@5 99.219 (99.798)
2025-05-20 12:13:27 - INFO - TRAINING - Epoch: [86][150/196]	Time 0.134 (0.145)	Data 0.000 (0.012)	Loss 0.4584 (0.4682)	Prec@1 94.531 (93.463)	Prec@5 100.000 (99.801)
2025-05-20 12:13:29 - INFO - TRAINING - Epoch: [86][160/196]	Time 0.133 (0.144)	Data 0.008 (0.011)	Loss 0.4038 (0.4678)	Prec@1 96.875 (93.444)	Prec@5 100.000 (99.801)
2025-05-20 12:13:30 - INFO - TRAINING - Epoch: [86][170/196]	Time 0.134 (0.143)	Data 0.002 (0.011)	Loss 0.4670 (0.4676)	Prec@1 93.359 (93.414)	Prec@5 99.609 (99.806)
2025-05-20 12:13:32 - INFO - TRAINING - Epoch: [86][180/196]	Time 0.139 (0.143)	Data 0.000 (0.011)	Loss 0.5483 (0.4681)	Prec@1 91.797 (93.420)	Prec@5 99.219 (99.808)
2025-05-20 12:13:33 - INFO - TRAINING - Epoch: [86][190/196]	Time 0.136 (0.143)	Data 0.000 (0.010)	Loss 0.4507 (0.4679)	Prec@1 93.750 (93.427)	Prec@5 99.609 (99.812)
2025-05-20 12:13:34 - INFO - EVALUATING - Epoch: [86][0/40]	Time 0.650 (0.650)	Data 0.578 (0.578)	Loss 0.6023 (0.6023)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
2025-05-20 12:13:35 - INFO - EVALUATING - Epoch: [86][10/40]	Time 0.077 (0.135)	Data 0.000 (0.061)	Loss 0.6041 (0.6322)	Prec@1 87.500 (86.186)	Prec@5 97.266 (98.189)
2025-05-20 12:13:36 - INFO - EVALUATING - Epoch: [86][20/40]	Time 0.081 (0.107)	Data 0.000 (0.033)	Loss 0.5835 (0.6336)	Prec@1 89.062 (86.496)	Prec@5 98.438 (97.954)
2025-05-20 12:13:37 - INFO - EVALUATING - Epoch: [86][30/40]	Time 0.070 (0.097)	Data 0.000 (0.023)	Loss 0.7099 (0.6334)	Prec@1 83.984 (86.492)	Prec@5 97.656 (98.097)
2025-05-20 12:13:37 - INFO - 
 Epoch: 87	Training Loss 0.4680 	Training Prec@1 93.436 	Training Prec@5 99.812 	Validation Loss 0.6347 	Validation Prec@1 86.440 	Validation Prec@5 98.120 

2025-05-20 12:13:37 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:13:37 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:13:37 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:13:37 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:13:37 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:13:38 - INFO - TRAINING - Epoch: [87][0/196]	Time 0.910 (0.910)	Data 0.815 (0.815)	Loss 0.4818 (0.4818)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
2025-05-20 12:13:40 - INFO - TRAINING - Epoch: [87][10/196]	Time 0.145 (0.213)	Data 0.003 (0.081)	Loss 0.4657 (0.4835)	Prec@1 92.578 (92.685)	Prec@5 100.000 (99.858)
2025-05-20 12:13:41 - INFO - TRAINING - Epoch: [87][20/196]	Time 0.132 (0.178)	Data 0.000 (0.045)	Loss 0.4519 (0.4745)	Prec@1 93.359 (92.950)	Prec@5 100.000 (99.795)
2025-05-20 12:13:42 - INFO - TRAINING - Epoch: [87][30/196]	Time 0.133 (0.163)	Data 0.003 (0.031)	Loss 0.5090 (0.4774)	Prec@1 91.016 (92.855)	Prec@5 100.000 (99.773)
2025-05-20 12:13:44 - INFO - TRAINING - Epoch: [87][40/196]	Time 0.140 (0.157)	Data 0.000 (0.024)	Loss 0.4681 (0.4786)	Prec@1 93.359 (92.912)	Prec@5 100.000 (99.743)
2025-05-20 12:13:45 - INFO - TRAINING - Epoch: [87][50/196]	Time 0.140 (0.155)	Data 0.000 (0.020)	Loss 0.4679 (0.4774)	Prec@1 92.969 (92.984)	Prec@5 100.000 (99.747)
2025-05-20 12:13:47 - INFO - TRAINING - Epoch: [87][60/196]	Time 0.141 (0.155)	Data 0.001 (0.017)	Loss 0.4483 (0.4729)	Prec@1 94.141 (93.180)	Prec@5 100.000 (99.763)
2025-05-20 12:13:48 - INFO - TRAINING - Epoch: [87][70/196]	Time 0.134 (0.152)	Data 0.000 (0.015)	Loss 0.4681 (0.4705)	Prec@1 92.969 (93.271)	Prec@5 100.000 (99.780)
2025-05-20 12:13:50 - INFO - TRAINING - Epoch: [87][80/196]	Time 0.133 (0.150)	Data 0.003 (0.014)	Loss 0.4950 (0.4718)	Prec@1 92.188 (93.191)	Prec@5 99.609 (99.793)
2025-05-20 12:13:51 - INFO - TRAINING - Epoch: [87][90/196]	Time 0.140 (0.148)	Data 0.001 (0.012)	Loss 0.4926 (0.4710)	Prec@1 93.359 (93.222)	Prec@5 100.000 (99.798)
2025-05-20 12:13:52 - INFO - TRAINING - Epoch: [87][100/196]	Time 0.135 (0.147)	Data 0.000 (0.011)	Loss 0.4788 (0.4698)	Prec@1 93.750 (93.317)	Prec@5 100.000 (99.799)
2025-05-20 12:13:54 - INFO - TRAINING - Epoch: [87][110/196]	Time 0.132 (0.146)	Data 0.000 (0.011)	Loss 0.4811 (0.4691)	Prec@1 91.797 (93.303)	Prec@5 100.000 (99.817)
2025-05-20 12:13:55 - INFO - TRAINING - Epoch: [87][120/196]	Time 0.133 (0.145)	Data 0.000 (0.010)	Loss 0.4577 (0.4689)	Prec@1 94.531 (93.311)	Prec@5 99.609 (99.826)
2025-05-20 12:13:56 - INFO - TRAINING - Epoch: [87][130/196]	Time 0.137 (0.144)	Data 0.000 (0.009)	Loss 0.4641 (0.4693)	Prec@1 94.531 (93.300)	Prec@5 99.219 (99.821)
2025-05-20 12:13:58 - INFO - TRAINING - Epoch: [87][140/196]	Time 0.133 (0.144)	Data 0.000 (0.008)	Loss 0.4873 (0.4692)	Prec@1 92.578 (93.293)	Prec@5 99.609 (99.809)
2025-05-20 12:13:59 - INFO - TRAINING - Epoch: [87][150/196]	Time 0.139 (0.144)	Data 0.004 (0.009)	Loss 0.4684 (0.4693)	Prec@1 93.359 (93.258)	Prec@5 99.219 (99.803)
2025-05-20 12:14:01 - INFO - TRAINING - Epoch: [87][160/196]	Time 0.148 (0.145)	Data 0.000 (0.009)	Loss 0.4812 (0.4701)	Prec@1 91.797 (93.231)	Prec@5 100.000 (99.803)
2025-05-20 12:14:02 - INFO - TRAINING - Epoch: [87][170/196]	Time 0.140 (0.145)	Data 0.001 (0.008)	Loss 0.4407 (0.4696)	Prec@1 94.922 (93.263)	Prec@5 100.000 (99.801)
2025-05-20 12:14:04 - INFO - TRAINING - Epoch: [87][180/196]	Time 0.140 (0.145)	Data 0.000 (0.008)	Loss 0.4673 (0.4699)	Prec@1 93.359 (93.249)	Prec@5 100.000 (99.806)
2025-05-20 12:14:05 - INFO - TRAINING - Epoch: [87][190/196]	Time 0.135 (0.144)	Data 0.000 (0.008)	Loss 0.4975 (0.4695)	Prec@1 91.016 (93.259)	Prec@5 99.609 (99.806)
2025-05-20 12:14:07 - INFO - EVALUATING - Epoch: [87][0/40]	Time 0.769 (0.769)	Data 0.699 (0.699)	Loss 0.5743 (0.5743)	Prec@1 88.672 (88.672)	Prec@5 98.047 (98.047)
2025-05-20 12:14:07 - INFO - EVALUATING - Epoch: [87][10/40]	Time 0.073 (0.142)	Data 0.003 (0.067)	Loss 0.5683 (0.6065)	Prec@1 87.500 (87.180)	Prec@5 99.219 (98.686)
2025-05-20 12:14:08 - INFO - EVALUATING - Epoch: [87][20/40]	Time 0.075 (0.111)	Data 0.000 (0.036)	Loss 0.5942 (0.6178)	Prec@1 89.062 (87.091)	Prec@5 98.438 (98.642)
2025-05-20 12:14:09 - INFO - EVALUATING - Epoch: [87][30/40]	Time 0.070 (0.100)	Data 0.000 (0.025)	Loss 0.6618 (0.6242)	Prec@1 85.156 (86.870)	Prec@5 98.828 (98.652)
2025-05-20 12:14:10 - INFO - 
 Epoch: 88	Training Loss 0.4702 	Training Prec@1 93.230 	Training Prec@5 99.802 	Validation Loss 0.6240 	Validation Prec@1 86.860 	Validation Prec@5 98.730 

2025-05-20 12:14:10 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:14:10 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:14:10 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:14:10 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:14:10 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:14:11 - INFO - TRAINING - Epoch: [88][0/196]	Time 1.460 (1.460)	Data 1.274 (1.274)	Loss 0.4496 (0.4496)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2025-05-20 12:14:13 - INFO - TRAINING - Epoch: [88][10/196]	Time 0.157 (0.274)	Data 0.005 (0.124)	Loss 0.5015 (0.4660)	Prec@1 91.406 (93.501)	Prec@5 99.219 (99.751)
2025-05-20 12:14:14 - INFO - TRAINING - Epoch: [88][20/196]	Time 0.141 (0.216)	Data 0.000 (0.067)	Loss 0.4867 (0.4676)	Prec@1 92.969 (93.545)	Prec@5 100.000 (99.740)
2025-05-20 12:14:16 - INFO - TRAINING - Epoch: [88][30/196]	Time 0.140 (0.192)	Data 0.006 (0.047)	Loss 0.4437 (0.4653)	Prec@1 94.141 (93.586)	Prec@5 100.000 (99.761)
2025-05-20 12:14:17 - INFO - TRAINING - Epoch: [88][40/196]	Time 0.136 (0.179)	Data 0.000 (0.037)	Loss 0.4091 (0.4616)	Prec@1 96.094 (93.693)	Prec@5 99.609 (99.762)
2025-05-20 12:14:18 - INFO - TRAINING - Epoch: [88][50/196]	Time 0.135 (0.170)	Data 0.000 (0.030)	Loss 0.4996 (0.4637)	Prec@1 92.578 (93.566)	Prec@5 99.609 (99.763)
2025-05-20 12:14:20 - INFO - TRAINING - Epoch: [88][60/196]	Time 0.132 (0.164)	Data 0.000 (0.025)	Loss 0.5086 (0.4648)	Prec@1 92.578 (93.571)	Prec@5 99.609 (99.763)
2025-05-20 12:14:21 - INFO - TRAINING - Epoch: [88][70/196]	Time 0.132 (0.160)	Data 0.000 (0.022)	Loss 0.4397 (0.4671)	Prec@1 94.531 (93.442)	Prec@5 100.000 (99.769)
2025-05-20 12:14:22 - INFO - TRAINING - Epoch: [88][80/196]	Time 0.136 (0.157)	Data 0.009 (0.020)	Loss 0.4769 (0.4685)	Prec@1 92.578 (93.379)	Prec@5 99.609 (99.769)
2025-05-20 12:14:24 - INFO - TRAINING - Epoch: [88][90/196]	Time 0.137 (0.154)	Data 0.018 (0.018)	Loss 0.4880 (0.4686)	Prec@1 91.797 (93.385)	Prec@5 100.000 (99.781)
2025-05-20 12:14:25 - INFO - TRAINING - Epoch: [88][100/196]	Time 0.136 (0.153)	Data 0.017 (0.017)	Loss 0.4264 (0.4672)	Prec@1 95.312 (93.456)	Prec@5 100.000 (99.791)
2025-05-20 12:14:27 - INFO - TRAINING - Epoch: [88][110/196]	Time 0.136 (0.153)	Data 0.031 (0.017)	Loss 0.4494 (0.4663)	Prec@1 94.922 (93.504)	Prec@5 100.000 (99.799)
2025-05-20 12:14:28 - INFO - TRAINING - Epoch: [88][120/196]	Time 0.134 (0.152)	Data 0.012 (0.016)	Loss 0.4966 (0.4670)	Prec@1 92.578 (93.421)	Prec@5 100.000 (99.806)
2025-05-20 12:14:29 - INFO - TRAINING - Epoch: [88][130/196]	Time 0.134 (0.150)	Data 0.000 (0.015)	Loss 0.4543 (0.4671)	Prec@1 93.359 (93.419)	Prec@5 100.000 (99.812)
2025-05-20 12:14:31 - INFO - TRAINING - Epoch: [88][140/196]	Time 0.135 (0.149)	Data 0.010 (0.014)	Loss 0.4628 (0.4677)	Prec@1 94.141 (93.404)	Prec@5 99.219 (99.806)
2025-05-20 12:14:32 - INFO - TRAINING - Epoch: [88][150/196]	Time 0.133 (0.148)	Data 0.000 (0.013)	Loss 0.4987 (0.4674)	Prec@1 91.797 (93.398)	Prec@5 100.000 (99.801)
2025-05-20 12:14:33 - INFO - TRAINING - Epoch: [88][160/196]	Time 0.136 (0.147)	Data 0.000 (0.012)	Loss 0.4431 (0.4664)	Prec@1 95.312 (93.447)	Prec@5 100.000 (99.803)
2025-05-20 12:14:35 - INFO - TRAINING - Epoch: [88][170/196]	Time 0.134 (0.146)	Data 0.006 (0.012)	Loss 0.4901 (0.4666)	Prec@1 91.797 (93.453)	Prec@5 99.219 (99.797)
2025-05-20 12:14:36 - INFO - TRAINING - Epoch: [88][180/196]	Time 0.133 (0.146)	Data 0.000 (0.011)	Loss 0.4552 (0.4672)	Prec@1 94.531 (93.433)	Prec@5 100.000 (99.801)
2025-05-20 12:14:37 - INFO - TRAINING - Epoch: [88][190/196]	Time 0.133 (0.145)	Data 0.000 (0.011)	Loss 0.4732 (0.4673)	Prec@1 92.578 (93.427)	Prec@5 100.000 (99.798)
2025-05-20 12:14:39 - INFO - EVALUATING - Epoch: [88][0/40]	Time 0.943 (0.943)	Data 0.863 (0.863)	Loss 0.6064 (0.6064)	Prec@1 85.547 (85.547)	Prec@5 99.219 (99.219)
2025-05-20 12:14:40 - INFO - EVALUATING - Epoch: [88][10/40]	Time 0.073 (0.176)	Data 0.003 (0.101)	Loss 0.6101 (0.6337)	Prec@1 87.500 (86.151)	Prec@5 98.828 (98.260)
2025-05-20 12:14:41 - INFO - EVALUATING - Epoch: [88][20/40]	Time 0.081 (0.129)	Data 0.001 (0.054)	Loss 0.5832 (0.6320)	Prec@1 89.062 (86.607)	Prec@5 99.609 (98.400)
2025-05-20 12:14:42 - INFO - EVALUATING - Epoch: [88][30/40]	Time 0.069 (0.111)	Data 0.000 (0.037)	Loss 0.6774 (0.6323)	Prec@1 82.422 (86.555)	Prec@5 98.438 (98.538)
2025-05-20 12:14:42 - INFO - 
 Epoch: 89	Training Loss 0.4670 	Training Prec@1 93.434 	Training Prec@5 99.798 	Validation Loss 0.6322 	Validation Prec@1 86.390 	Validation Prec@5 98.540 

2025-05-20 12:14:42 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:14:42 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:14:42 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:14:42 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:14:42 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:14:43 - INFO - TRAINING - Epoch: [89][0/196]	Time 0.928 (0.928)	Data 0.825 (0.825)	Loss 0.5155 (0.5155)	Prec@1 90.234 (90.234)	Prec@5 98.828 (98.828)
2025-05-20 12:14:45 - INFO - TRAINING - Epoch: [89][10/196]	Time 0.139 (0.212)	Data 0.002 (0.084)	Loss 0.4979 (0.4673)	Prec@1 93.359 (93.537)	Prec@5 99.609 (99.716)
2025-05-20 12:14:46 - INFO - TRAINING - Epoch: [89][20/196]	Time 0.133 (0.177)	Data 0.007 (0.047)	Loss 0.4842 (0.4656)	Prec@1 92.578 (93.731)	Prec@5 100.000 (99.721)
2025-05-20 12:14:47 - INFO - TRAINING - Epoch: [89][30/196]	Time 0.138 (0.164)	Data 0.000 (0.033)	Loss 0.4590 (0.4671)	Prec@1 94.922 (93.561)	Prec@5 100.000 (99.748)
2025-05-20 12:14:49 - INFO - TRAINING - Epoch: [89][40/196]	Time 0.134 (0.157)	Data 0.000 (0.025)	Loss 0.4427 (0.4636)	Prec@1 94.922 (93.579)	Prec@5 99.609 (99.781)
2025-05-20 12:14:50 - INFO - TRAINING - Epoch: [89][50/196]	Time 0.137 (0.153)	Data 0.010 (0.021)	Loss 0.4536 (0.4627)	Prec@1 93.750 (93.589)	Prec@5 100.000 (99.793)
2025-05-20 12:14:52 - INFO - TRAINING - Epoch: [89][60/196]	Time 0.165 (0.152)	Data 0.012 (0.019)	Loss 0.4095 (0.4610)	Prec@1 95.703 (93.680)	Prec@5 100.000 (99.801)
2025-05-20 12:14:53 - INFO - TRAINING - Epoch: [89][70/196]	Time 0.136 (0.151)	Data 0.000 (0.017)	Loss 0.5314 (0.4612)	Prec@1 88.672 (93.684)	Prec@5 100.000 (99.796)
2025-05-20 12:14:55 - INFO - TRAINING - Epoch: [89][80/196]	Time 0.135 (0.149)	Data 0.000 (0.015)	Loss 0.4530 (0.4610)	Prec@1 93.359 (93.707)	Prec@5 100.000 (99.802)
2025-05-20 12:14:56 - INFO - TRAINING - Epoch: [89][90/196]	Time 0.133 (0.147)	Data 0.000 (0.014)	Loss 0.4165 (0.4622)	Prec@1 95.703 (93.617)	Prec@5 100.000 (99.785)
2025-05-20 12:14:57 - INFO - TRAINING - Epoch: [89][100/196]	Time 0.135 (0.146)	Data 0.000 (0.013)	Loss 0.4619 (0.4626)	Prec@1 92.969 (93.588)	Prec@5 99.219 (99.783)
2025-05-20 12:14:59 - INFO - TRAINING - Epoch: [89][110/196]	Time 0.133 (0.145)	Data 0.000 (0.011)	Loss 0.4996 (0.4626)	Prec@1 91.797 (93.588)	Prec@5 99.219 (99.778)
2025-05-20 12:15:00 - INFO - TRAINING - Epoch: [89][120/196]	Time 0.136 (0.144)	Data 0.004 (0.011)	Loss 0.5419 (0.4644)	Prec@1 91.016 (93.498)	Prec@5 99.609 (99.787)
2025-05-20 12:15:01 - INFO - TRAINING - Epoch: [89][130/196]	Time 0.134 (0.143)	Data 0.000 (0.010)	Loss 0.4526 (0.4641)	Prec@1 93.359 (93.550)	Prec@5 99.219 (99.779)
2025-05-20 12:15:03 - INFO - TRAINING - Epoch: [89][140/196]	Time 0.132 (0.143)	Data 0.000 (0.009)	Loss 0.4713 (0.4639)	Prec@1 93.750 (93.537)	Prec@5 100.000 (99.784)
2025-05-20 12:15:04 - INFO - TRAINING - Epoch: [89][150/196]	Time 0.147 (0.142)	Data 0.007 (0.009)	Loss 0.4252 (0.4640)	Prec@1 94.531 (93.538)	Prec@5 100.000 (99.785)
2025-05-20 12:15:05 - INFO - TRAINING - Epoch: [89][160/196]	Time 0.150 (0.143)	Data 0.011 (0.009)	Loss 0.4577 (0.4637)	Prec@1 91.406 (93.517)	Prec@5 100.000 (99.789)
2025-05-20 12:15:07 - INFO - TRAINING - Epoch: [89][170/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.5136 (0.4645)	Prec@1 90.234 (93.501)	Prec@5 100.000 (99.794)
2025-05-20 12:15:08 - INFO - TRAINING - Epoch: [89][180/196]	Time 0.132 (0.142)	Data 0.000 (0.008)	Loss 0.4561 (0.4641)	Prec@1 95.703 (93.502)	Prec@5 100.000 (99.797)
2025-05-20 12:15:09 - INFO - TRAINING - Epoch: [89][190/196]	Time 0.129 (0.142)	Data 0.000 (0.008)	Loss 0.4690 (0.4645)	Prec@1 93.750 (93.484)	Prec@5 99.609 (99.793)
2025-05-20 12:15:11 - INFO - EVALUATING - Epoch: [89][0/40]	Time 0.653 (0.653)	Data 0.574 (0.574)	Loss 0.6417 (0.6417)	Prec@1 86.719 (86.719)	Prec@5 97.266 (97.266)
2025-05-20 12:15:12 - INFO - EVALUATING - Epoch: [89][10/40]	Time 0.076 (0.148)	Data 0.003 (0.073)	Loss 0.5627 (0.6319)	Prec@1 88.672 (86.080)	Prec@5 99.609 (98.224)
2025-05-20 12:15:13 - INFO - EVALUATING - Epoch: [89][20/40]	Time 0.078 (0.115)	Data 0.010 (0.041)	Loss 0.6463 (0.6331)	Prec@1 85.938 (86.365)	Prec@5 97.266 (98.251)
2025-05-20 12:15:13 - INFO - EVALUATING - Epoch: [89][30/40]	Time 0.070 (0.102)	Data 0.000 (0.029)	Loss 0.7053 (0.6334)	Prec@1 82.812 (86.328)	Prec@5 98.828 (98.425)
2025-05-20 12:15:14 - INFO - 
 Epoch: 90	Training Loss 0.4646 	Training Prec@1 93.498 	Training Prec@5 99.786 	Validation Loss 0.6320 	Validation Prec@1 86.360 	Validation Prec@5 98.510 

2025-05-20 12:15:14 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:15:14 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:15:14 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:15:14 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:15:14 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:15:15 - INFO - TRAINING - Epoch: [90][0/196]	Time 0.987 (0.987)	Data 0.866 (0.866)	Loss 0.4157 (0.4157)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2025-05-20 12:15:17 - INFO - TRAINING - Epoch: [90][10/196]	Time 0.139 (0.223)	Data 0.006 (0.083)	Loss 0.4520 (0.4583)	Prec@1 94.141 (93.679)	Prec@5 100.000 (99.787)
2025-05-20 12:15:18 - INFO - TRAINING - Epoch: [90][20/196]	Time 0.196 (0.205)	Data 0.001 (0.046)	Loss 0.4251 (0.4630)	Prec@1 94.531 (93.173)	Prec@5 100.000 (99.777)
2025-05-20 12:15:20 - INFO - TRAINING - Epoch: [90][30/196]	Time 0.133 (0.193)	Data 0.008 (0.032)	Loss 0.4515 (0.4647)	Prec@1 94.531 (93.511)	Prec@5 99.219 (99.786)
2025-05-20 12:15:22 - INFO - TRAINING - Epoch: [90][40/196]	Time 0.137 (0.181)	Data 0.015 (0.026)	Loss 0.4891 (0.4654)	Prec@1 91.797 (93.388)	Prec@5 100.000 (99.809)
2025-05-20 12:15:23 - INFO - TRAINING - Epoch: [90][50/196]	Time 0.133 (0.172)	Data 0.000 (0.022)	Loss 0.4582 (0.4629)	Prec@1 94.141 (93.551)	Prec@5 100.000 (99.847)
2025-05-20 12:15:24 - INFO - TRAINING - Epoch: [90][60/196]	Time 0.132 (0.166)	Data 0.013 (0.019)	Loss 0.4151 (0.4621)	Prec@1 94.531 (93.584)	Prec@5 100.000 (99.853)
2025-05-20 12:15:26 - INFO - TRAINING - Epoch: [90][70/196]	Time 0.133 (0.162)	Data 0.000 (0.016)	Loss 0.4617 (0.4641)	Prec@1 93.359 (93.458)	Prec@5 99.219 (99.846)
2025-05-20 12:15:27 - INFO - TRAINING - Epoch: [90][80/196]	Time 0.135 (0.158)	Data 0.000 (0.015)	Loss 0.4616 (0.4647)	Prec@1 94.531 (93.456)	Prec@5 100.000 (99.846)
2025-05-20 12:15:28 - INFO - TRAINING - Epoch: [90][90/196]	Time 0.134 (0.156)	Data 0.000 (0.013)	Loss 0.4582 (0.4639)	Prec@1 92.578 (93.484)	Prec@5 99.609 (99.811)
2025-05-20 12:15:30 - INFO - TRAINING - Epoch: [90][100/196]	Time 0.130 (0.154)	Data 0.000 (0.012)	Loss 0.4308 (0.4654)	Prec@1 95.312 (93.437)	Prec@5 99.609 (99.807)
2025-05-20 12:15:31 - INFO - TRAINING - Epoch: [90][110/196]	Time 0.140 (0.153)	Data 0.015 (0.012)	Loss 0.4772 (0.4668)	Prec@1 93.750 (93.402)	Prec@5 100.000 (99.806)
2025-05-20 12:15:33 - INFO - TRAINING - Epoch: [90][120/196]	Time 0.138 (0.152)	Data 0.006 (0.012)	Loss 0.4609 (0.4663)	Prec@1 93.359 (93.447)	Prec@5 100.000 (99.803)
2025-05-20 12:15:34 - INFO - TRAINING - Epoch: [90][130/196]	Time 0.134 (0.151)	Data 0.007 (0.011)	Loss 0.4703 (0.4670)	Prec@1 94.922 (93.458)	Prec@5 100.000 (99.815)
2025-05-20 12:15:35 - INFO - TRAINING - Epoch: [90][140/196]	Time 0.129 (0.150)	Data 0.000 (0.011)	Loss 0.4219 (0.4663)	Prec@1 94.922 (93.509)	Prec@5 100.000 (99.817)
2025-05-20 12:15:37 - INFO - TRAINING - Epoch: [90][150/196]	Time 0.134 (0.149)	Data 0.011 (0.010)	Loss 0.4639 (0.4669)	Prec@1 94.141 (93.471)	Prec@5 99.609 (99.819)
2025-05-20 12:15:38 - INFO - TRAINING - Epoch: [90][160/196]	Time 0.134 (0.148)	Data 0.000 (0.010)	Loss 0.4558 (0.4672)	Prec@1 94.531 (93.473)	Prec@5 100.000 (99.818)
2025-05-20 12:15:39 - INFO - TRAINING - Epoch: [90][170/196]	Time 0.134 (0.147)	Data 0.011 (0.009)	Loss 0.5232 (0.4674)	Prec@1 90.234 (93.458)	Prec@5 100.000 (99.815)
2025-05-20 12:15:41 - INFO - TRAINING - Epoch: [90][180/196]	Time 0.134 (0.147)	Data 0.000 (0.009)	Loss 0.4275 (0.4674)	Prec@1 94.922 (93.469)	Prec@5 100.000 (99.810)
2025-05-20 12:15:42 - INFO - TRAINING - Epoch: [90][190/196]	Time 0.133 (0.146)	Data 0.000 (0.009)	Loss 0.4332 (0.4678)	Prec@1 93.359 (93.451)	Prec@5 100.000 (99.810)
2025-05-20 12:15:44 - INFO - EVALUATING - Epoch: [90][0/40]	Time 1.380 (1.380)	Data 1.215 (1.215)	Loss 0.6370 (0.6370)	Prec@1 86.719 (86.719)	Prec@5 98.828 (98.828)
2025-05-20 12:15:45 - INFO - EVALUATING - Epoch: [90][10/40]	Time 0.073 (0.209)	Data 0.000 (0.122)	Loss 0.5974 (0.6194)	Prec@1 86.719 (86.541)	Prec@5 99.219 (98.793)
2025-05-20 12:15:46 - INFO - EVALUATING - Epoch: [90][20/40]	Time 0.081 (0.154)	Data 0.000 (0.072)	Loss 0.6335 (0.6240)	Prec@1 85.938 (86.347)	Prec@5 98.438 (98.642)
2025-05-20 12:15:47 - INFO - EVALUATING - Epoch: [90][30/40]	Time 0.070 (0.129)	Data 0.000 (0.049)	Loss 0.6286 (0.6284)	Prec@1 83.594 (86.101)	Prec@5 97.656 (98.551)
2025-05-20 12:15:48 - INFO - 
 Epoch: 91	Training Loss 0.4683 	Training Prec@1 93.426 	Training Prec@5 99.810 	Validation Loss 0.6259 	Validation Prec@1 86.270 	Validation Prec@5 98.620 

2025-05-20 12:15:48 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:15:48 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:15:48 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:15:48 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:15:48 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:15:49 - INFO - TRAINING - Epoch: [91][0/196]	Time 1.645 (1.645)	Data 1.452 (1.452)	Loss 0.4496 (0.4496)	Prec@1 93.750 (93.750)	Prec@5 99.609 (99.609)
2025-05-20 12:15:51 - INFO - TRAINING - Epoch: [91][10/196]	Time 0.121 (0.290)	Data 0.005 (0.140)	Loss 0.4282 (0.4595)	Prec@1 95.312 (93.572)	Prec@5 100.000 (99.858)
2025-05-20 12:15:52 - INFO - TRAINING - Epoch: [91][20/196]	Time 0.138 (0.219)	Data 0.005 (0.076)	Loss 0.4361 (0.4697)	Prec@1 94.141 (92.987)	Prec@5 99.609 (99.833)
2025-05-20 12:15:54 - INFO - TRAINING - Epoch: [91][30/196]	Time 0.136 (0.192)	Data 0.000 (0.053)	Loss 0.4876 (0.4709)	Prec@1 92.188 (93.107)	Prec@5 99.219 (99.811)
2025-05-20 12:15:55 - INFO - TRAINING - Epoch: [91][40/196]	Time 0.133 (0.178)	Data 0.000 (0.040)	Loss 0.5039 (0.4684)	Prec@1 90.625 (93.216)	Prec@5 100.000 (99.781)
2025-05-20 12:15:56 - INFO - TRAINING - Epoch: [91][50/196]	Time 0.136 (0.170)	Data 0.000 (0.033)	Loss 0.4616 (0.4681)	Prec@1 94.141 (93.313)	Prec@5 100.000 (99.740)
2025-05-20 12:15:58 - INFO - TRAINING - Epoch: [91][60/196]	Time 0.148 (0.166)	Data 0.000 (0.029)	Loss 0.4760 (0.4686)	Prec@1 93.359 (93.315)	Prec@5 100.000 (99.744)
2025-05-20 12:15:59 - INFO - TRAINING - Epoch: [91][70/196]	Time 0.137 (0.163)	Data 0.000 (0.026)	Loss 0.4929 (0.4689)	Prec@1 90.234 (93.310)	Prec@5 100.000 (99.752)
2025-05-20 12:16:01 - INFO - TRAINING - Epoch: [91][80/196]	Time 0.133 (0.160)	Data 0.007 (0.023)	Loss 0.5196 (0.4709)	Prec@1 91.016 (93.200)	Prec@5 99.219 (99.754)
2025-05-20 12:16:02 - INFO - TRAINING - Epoch: [91][90/196]	Time 0.138 (0.157)	Data 0.000 (0.021)	Loss 0.4629 (0.4709)	Prec@1 93.359 (93.183)	Prec@5 99.219 (99.751)
2025-05-20 12:16:03 - INFO - TRAINING - Epoch: [91][100/196]	Time 0.132 (0.154)	Data 0.000 (0.019)	Loss 0.4070 (0.4690)	Prec@1 96.484 (93.274)	Prec@5 100.000 (99.756)
2025-05-20 12:16:05 - INFO - TRAINING - Epoch: [91][110/196]	Time 0.132 (0.153)	Data 0.009 (0.017)	Loss 0.4523 (0.4693)	Prec@1 91.797 (93.282)	Prec@5 100.000 (99.757)
2025-05-20 12:16:06 - INFO - TRAINING - Epoch: [91][120/196]	Time 0.132 (0.151)	Data 0.000 (0.016)	Loss 0.4336 (0.4684)	Prec@1 94.922 (93.337)	Prec@5 99.609 (99.755)
2025-05-20 12:16:07 - INFO - TRAINING - Epoch: [91][130/196]	Time 0.135 (0.150)	Data 0.007 (0.015)	Loss 0.4604 (0.4690)	Prec@1 94.922 (93.330)	Prec@5 100.000 (99.767)
2025-05-20 12:16:09 - INFO - TRAINING - Epoch: [91][140/196]	Time 0.134 (0.149)	Data 0.007 (0.014)	Loss 0.4168 (0.4676)	Prec@1 95.312 (93.368)	Prec@5 100.000 (99.776)
2025-05-20 12:16:10 - INFO - TRAINING - Epoch: [91][150/196]	Time 0.150 (0.148)	Data 0.000 (0.014)	Loss 0.4313 (0.4662)	Prec@1 95.312 (93.416)	Prec@5 100.000 (99.783)
2025-05-20 12:16:12 - INFO - TRAINING - Epoch: [91][160/196]	Time 0.152 (0.148)	Data 0.013 (0.013)	Loss 0.4428 (0.4660)	Prec@1 94.531 (93.435)	Prec@5 99.609 (99.777)
2025-05-20 12:16:13 - INFO - TRAINING - Epoch: [91][170/196]	Time 0.133 (0.148)	Data 0.000 (0.013)	Loss 0.5112 (0.4661)	Prec@1 92.188 (93.435)	Prec@5 100.000 (99.781)
2025-05-20 12:16:14 - INFO - TRAINING - Epoch: [91][180/196]	Time 0.134 (0.147)	Data 0.000 (0.012)	Loss 0.4785 (0.4662)	Prec@1 92.188 (93.396)	Prec@5 99.609 (99.782)
2025-05-20 12:16:16 - INFO - TRAINING - Epoch: [91][190/196]	Time 0.133 (0.146)	Data 0.000 (0.011)	Loss 0.4579 (0.4656)	Prec@1 94.141 (93.429)	Prec@5 100.000 (99.791)
2025-05-20 12:16:17 - INFO - EVALUATING - Epoch: [91][0/40]	Time 0.757 (0.757)	Data 0.686 (0.686)	Loss 0.6409 (0.6409)	Prec@1 87.109 (87.109)	Prec@5 98.047 (98.047)
2025-05-20 12:16:18 - INFO - EVALUATING - Epoch: [91][10/40]	Time 0.072 (0.140)	Data 0.000 (0.069)	Loss 0.5897 (0.6349)	Prec@1 86.719 (86.186)	Prec@5 98.828 (98.615)
2025-05-20 12:16:19 - INFO - EVALUATING - Epoch: [91][20/40]	Time 0.083 (0.111)	Data 0.004 (0.039)	Loss 0.6114 (0.6325)	Prec@1 85.938 (86.272)	Prec@5 99.219 (98.642)
2025-05-20 12:16:19 - INFO - EVALUATING - Epoch: [91][30/40]	Time 0.069 (0.099)	Data 0.000 (0.027)	Loss 0.6774 (0.6361)	Prec@1 82.031 (85.938)	Prec@5 98.047 (98.765)
2025-05-20 12:16:20 - INFO - 
 Epoch: 92	Training Loss 0.4661 	Training Prec@1 93.400 	Training Prec@5 99.796 	Validation Loss 0.6341 	Validation Prec@1 86.070 	Validation Prec@5 98.880 

2025-05-20 12:16:20 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:16:20 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:16:20 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:16:20 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:16:20 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:16:21 - INFO - TRAINING - Epoch: [92][0/196]	Time 1.032 (1.032)	Data 0.915 (0.915)	Loss 0.4939 (0.4939)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
2025-05-20 12:16:23 - INFO - TRAINING - Epoch: [92][10/196]	Time 0.138 (0.230)	Data 0.000 (0.086)	Loss 0.4741 (0.4734)	Prec@1 92.578 (93.111)	Prec@5 99.609 (99.645)
2025-05-20 12:16:24 - INFO - TRAINING - Epoch: [92][20/196]	Time 0.179 (0.199)	Data 0.012 (0.048)	Loss 0.4478 (0.4757)	Prec@1 94.531 (93.118)	Prec@5 99.219 (99.628)
2025-05-20 12:16:26 - INFO - TRAINING - Epoch: [92][30/196]	Time 0.145 (0.184)	Data 0.000 (0.034)	Loss 0.4561 (0.4698)	Prec@1 94.141 (93.422)	Prec@5 100.000 (99.672)
2025-05-20 12:16:27 - INFO - TRAINING - Epoch: [92][40/196]	Time 0.136 (0.172)	Data 0.000 (0.027)	Loss 0.4836 (0.4680)	Prec@1 92.188 (93.540)	Prec@5 99.609 (99.705)
2025-05-20 12:16:29 - INFO - TRAINING - Epoch: [92][50/196]	Time 0.132 (0.165)	Data 0.003 (0.022)	Loss 0.4429 (0.4671)	Prec@1 94.531 (93.536)	Prec@5 100.000 (99.732)
2025-05-20 12:16:30 - INFO - TRAINING - Epoch: [92][60/196]	Time 0.135 (0.160)	Data 0.002 (0.018)	Loss 0.4624 (0.4664)	Prec@1 94.141 (93.507)	Prec@5 100.000 (99.744)
2025-05-20 12:16:31 - INFO - TRAINING - Epoch: [92][70/196]	Time 0.133 (0.156)	Data 0.010 (0.016)	Loss 0.4581 (0.4662)	Prec@1 94.531 (93.524)	Prec@5 100.000 (99.747)
2025-05-20 12:16:33 - INFO - TRAINING - Epoch: [92][80/196]	Time 0.134 (0.153)	Data 0.006 (0.015)	Loss 0.4214 (0.4660)	Prec@1 95.703 (93.543)	Prec@5 100.000 (99.764)
2025-05-20 12:16:34 - INFO - TRAINING - Epoch: [92][90/196]	Time 0.133 (0.151)	Data 0.000 (0.013)	Loss 0.5090 (0.4648)	Prec@1 91.797 (93.561)	Prec@5 100.000 (99.785)
2025-05-20 12:16:35 - INFO - TRAINING - Epoch: [92][100/196]	Time 0.134 (0.150)	Data 0.000 (0.012)	Loss 0.4556 (0.4649)	Prec@1 94.141 (93.483)	Prec@5 100.000 (99.783)
2025-05-20 12:16:37 - INFO - TRAINING - Epoch: [92][110/196]	Time 0.145 (0.149)	Data 0.012 (0.012)	Loss 0.5024 (0.4653)	Prec@1 91.797 (93.514)	Prec@5 100.000 (99.775)
2025-05-20 12:16:38 - INFO - TRAINING - Epoch: [92][120/196]	Time 0.125 (0.149)	Data 0.008 (0.012)	Loss 0.4465 (0.4648)	Prec@1 95.703 (93.543)	Prec@5 100.000 (99.774)
2025-05-20 12:16:40 - INFO - TRAINING - Epoch: [92][130/196]	Time 0.136 (0.148)	Data 0.000 (0.012)	Loss 0.5086 (0.4650)	Prec@1 91.016 (93.514)	Prec@5 100.000 (99.776)
2025-05-20 12:16:41 - INFO - TRAINING - Epoch: [92][140/196]	Time 0.133 (0.147)	Data 0.000 (0.011)	Loss 0.4694 (0.4647)	Prec@1 92.969 (93.553)	Prec@5 99.609 (99.773)
2025-05-20 12:16:42 - INFO - TRAINING - Epoch: [92][150/196]	Time 0.133 (0.146)	Data 0.000 (0.010)	Loss 0.4424 (0.4653)	Prec@1 93.750 (93.533)	Prec@5 100.000 (99.783)
2025-05-20 12:16:44 - INFO - TRAINING - Epoch: [92][160/196]	Time 0.134 (0.145)	Data 0.000 (0.010)	Loss 0.5303 (0.4658)	Prec@1 90.625 (93.520)	Prec@5 99.219 (99.784)
2025-05-20 12:16:45 - INFO - TRAINING - Epoch: [92][170/196]	Time 0.134 (0.145)	Data 0.007 (0.010)	Loss 0.4553 (0.4656)	Prec@1 94.141 (93.494)	Prec@5 100.000 (99.783)
2025-05-20 12:16:46 - INFO - TRAINING - Epoch: [92][180/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.4534 (0.4663)	Prec@1 94.531 (93.476)	Prec@5 100.000 (99.793)
2025-05-20 12:16:48 - INFO - TRAINING - Epoch: [92][190/196]	Time 0.133 (0.144)	Data 0.000 (0.009)	Loss 0.4565 (0.4668)	Prec@1 92.969 (93.443)	Prec@5 99.609 (99.793)
2025-05-20 12:16:50 - INFO - EVALUATING - Epoch: [92][0/40]	Time 1.290 (1.290)	Data 1.209 (1.209)	Loss 0.6384 (0.6384)	Prec@1 87.109 (87.109)	Prec@5 98.828 (98.828)
2025-05-20 12:16:51 - INFO - EVALUATING - Epoch: [92][10/40]	Time 0.078 (0.210)	Data 0.011 (0.131)	Loss 0.5998 (0.6344)	Prec@1 89.453 (86.754)	Prec@5 99.219 (98.509)
2025-05-20 12:16:52 - INFO - EVALUATING - Epoch: [92][20/40]	Time 0.107 (0.162)	Data 0.008 (0.079)	Loss 0.6363 (0.6402)	Prec@1 87.891 (86.663)	Prec@5 97.266 (98.363)
2025-05-20 12:16:53 - INFO - EVALUATING - Epoch: [92][30/40]	Time 0.070 (0.139)	Data 0.000 (0.059)	Loss 0.6955 (0.6428)	Prec@1 84.375 (86.391)	Prec@5 98.828 (98.475)
2025-05-20 12:16:54 - INFO - 
 Epoch: 93	Training Loss 0.4668 	Training Prec@1 93.440 	Training Prec@5 99.796 	Validation Loss 0.6404 	Validation Prec@1 86.300 	Validation Prec@5 98.550 

2025-05-20 12:16:54 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:16:54 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:16:54 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:16:54 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:16:54 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:16:55 - INFO - TRAINING - Epoch: [93][0/196]	Time 1.086 (1.086)	Data 0.953 (0.953)	Loss 0.4806 (0.4806)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
2025-05-20 12:16:56 - INFO - TRAINING - Epoch: [93][10/196]	Time 0.139 (0.236)	Data 0.007 (0.099)	Loss 0.4292 (0.4665)	Prec@1 95.312 (93.430)	Prec@5 99.609 (99.822)
2025-05-20 12:16:58 - INFO - TRAINING - Epoch: [93][20/196]	Time 0.133 (0.188)	Data 0.000 (0.054)	Loss 0.5260 (0.4633)	Prec@1 91.016 (93.713)	Prec@5 99.219 (99.777)
2025-05-20 12:16:59 - INFO - TRAINING - Epoch: [93][30/196]	Time 0.137 (0.171)	Data 0.000 (0.037)	Loss 0.4912 (0.4657)	Prec@1 92.188 (93.611)	Prec@5 100.000 (99.773)
2025-05-20 12:17:00 - INFO - TRAINING - Epoch: [93][40/196]	Time 0.133 (0.162)	Data 0.007 (0.028)	Loss 0.4655 (0.4668)	Prec@1 93.359 (93.493)	Prec@5 99.219 (99.771)
2025-05-20 12:17:02 - INFO - TRAINING - Epoch: [93][50/196]	Time 0.133 (0.157)	Data 0.000 (0.023)	Loss 0.4480 (0.4683)	Prec@1 93.750 (93.413)	Prec@5 99.609 (99.786)
2025-05-20 12:17:03 - INFO - TRAINING - Epoch: [93][60/196]	Time 0.153 (0.154)	Data 0.000 (0.019)	Loss 0.4589 (0.4681)	Prec@1 94.922 (93.385)	Prec@5 100.000 (99.789)
2025-05-20 12:17:04 - INFO - TRAINING - Epoch: [93][70/196]	Time 0.154 (0.154)	Data 0.012 (0.017)	Loss 0.4405 (0.4672)	Prec@1 94.922 (93.431)	Prec@5 99.219 (99.785)
2025-05-20 12:17:06 - INFO - TRAINING - Epoch: [93][80/196]	Time 0.137 (0.152)	Data 0.007 (0.016)	Loss 0.5113 (0.4668)	Prec@1 89.453 (93.427)	Prec@5 100.000 (99.788)
2025-05-20 12:17:07 - INFO - TRAINING - Epoch: [93][90/196]	Time 0.137 (0.150)	Data 0.000 (0.014)	Loss 0.5135 (0.4689)	Prec@1 91.016 (93.364)	Prec@5 100.000 (99.772)
2025-05-20 12:17:09 - INFO - TRAINING - Epoch: [93][100/196]	Time 0.134 (0.148)	Data 0.000 (0.013)	Loss 0.4940 (0.4684)	Prec@1 92.578 (93.417)	Prec@5 100.000 (99.768)
2025-05-20 12:17:10 - INFO - TRAINING - Epoch: [93][110/196]	Time 0.134 (0.147)	Data 0.000 (0.012)	Loss 0.4659 (0.4677)	Prec@1 92.188 (93.402)	Prec@5 99.609 (99.771)
2025-05-20 12:17:11 - INFO - TRAINING - Epoch: [93][120/196]	Time 0.135 (0.146)	Data 0.000 (0.011)	Loss 0.4630 (0.4672)	Prec@1 94.141 (93.443)	Prec@5 100.000 (99.784)
2025-05-20 12:17:13 - INFO - TRAINING - Epoch: [93][130/196]	Time 0.133 (0.145)	Data 0.000 (0.011)	Loss 0.4379 (0.4666)	Prec@1 95.703 (93.458)	Prec@5 100.000 (99.794)
2025-05-20 12:17:14 - INFO - TRAINING - Epoch: [93][140/196]	Time 0.135 (0.144)	Data 0.000 (0.010)	Loss 0.4628 (0.4671)	Prec@1 93.359 (93.418)	Prec@5 100.000 (99.789)
2025-05-20 12:17:15 - INFO - TRAINING - Epoch: [93][150/196]	Time 0.140 (0.144)	Data 0.007 (0.010)	Loss 0.4815 (0.4681)	Prec@1 93.750 (93.398)	Prec@5 100.000 (99.788)
2025-05-20 12:17:17 - INFO - TRAINING - Epoch: [93][160/196]	Time 0.159 (0.144)	Data 0.003 (0.009)	Loss 0.5236 (0.4686)	Prec@1 90.625 (93.335)	Prec@5 99.609 (99.789)
2025-05-20 12:17:18 - INFO - TRAINING - Epoch: [93][170/196]	Time 0.178 (0.144)	Data 0.000 (0.009)	Loss 0.4626 (0.4687)	Prec@1 94.922 (93.323)	Prec@5 99.609 (99.790)
2025-05-20 12:17:20 - INFO - TRAINING - Epoch: [93][180/196]	Time 0.132 (0.144)	Data 0.000 (0.009)	Loss 0.4739 (0.4693)	Prec@1 93.750 (93.292)	Prec@5 99.609 (99.784)
2025-05-20 12:17:21 - INFO - TRAINING - Epoch: [93][190/196]	Time 0.131 (0.143)	Data 0.000 (0.008)	Loss 0.4500 (0.4689)	Prec@1 95.312 (93.335)	Prec@5 99.609 (99.791)
2025-05-20 12:17:23 - INFO - EVALUATING - Epoch: [93][0/40]	Time 1.108 (1.108)	Data 1.040 (1.040)	Loss 0.6245 (0.6245)	Prec@1 86.328 (86.328)	Prec@5 98.047 (98.047)
2025-05-20 12:17:23 - INFO - EVALUATING - Epoch: [93][10/40]	Time 0.084 (0.172)	Data 0.009 (0.098)	Loss 0.6210 (0.6413)	Prec@1 83.984 (85.085)	Prec@5 99.219 (98.580)
2025-05-20 12:17:24 - INFO - EVALUATING - Epoch: [93][20/40]	Time 0.081 (0.127)	Data 0.003 (0.053)	Loss 0.6454 (0.6399)	Prec@1 85.547 (85.640)	Prec@5 98.047 (98.549)
2025-05-20 12:17:25 - INFO - EVALUATING - Epoch: [93][30/40]	Time 0.070 (0.109)	Data 0.000 (0.036)	Loss 0.6497 (0.6417)	Prec@1 85.547 (85.711)	Prec@5 98.828 (98.601)
2025-05-20 12:17:26 - INFO - 
 Epoch: 94	Training Loss 0.4684 	Training Prec@1 93.358 	Training Prec@5 99.794 	Validation Loss 0.6420 	Validation Prec@1 85.780 	Validation Prec@5 98.600 

2025-05-20 12:17:26 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:17:26 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:17:26 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:17:26 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:17:26 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:17:27 - INFO - TRAINING - Epoch: [94][0/196]	Time 0.928 (0.928)	Data 0.822 (0.822)	Loss 0.4515 (0.4515)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
2025-05-20 12:17:28 - INFO - TRAINING - Epoch: [94][10/196]	Time 0.132 (0.216)	Data 0.004 (0.079)	Loss 0.5161 (0.4648)	Prec@1 91.797 (93.928)	Prec@5 99.609 (99.822)
2025-05-20 12:17:30 - INFO - TRAINING - Epoch: [94][20/196]	Time 0.134 (0.184)	Data 0.007 (0.043)	Loss 0.4755 (0.4616)	Prec@1 92.578 (94.085)	Prec@5 100.000 (99.870)
2025-05-20 12:17:31 - INFO - TRAINING - Epoch: [94][30/196]	Time 0.141 (0.175)	Data 0.004 (0.031)	Loss 0.4313 (0.4625)	Prec@1 95.312 (93.901)	Prec@5 100.000 (99.824)
2025-05-20 12:17:33 - INFO - TRAINING - Epoch: [94][40/196]	Time 0.133 (0.167)	Data 0.000 (0.025)	Loss 0.4633 (0.4578)	Prec@1 93.750 (94.122)	Prec@5 100.000 (99.857)
2025-05-20 12:17:34 - INFO - TRAINING - Epoch: [94][50/196]	Time 0.133 (0.160)	Data 0.001 (0.020)	Loss 0.4565 (0.4584)	Prec@1 93.750 (94.056)	Prec@5 100.000 (99.847)
2025-05-20 12:17:35 - INFO - TRAINING - Epoch: [94][60/196]	Time 0.134 (0.156)	Data 0.000 (0.018)	Loss 0.4975 (0.4601)	Prec@1 92.578 (93.968)	Prec@5 100.000 (99.859)
2025-05-20 12:17:37 - INFO - TRAINING - Epoch: [94][70/196]	Time 0.135 (0.153)	Data 0.000 (0.015)	Loss 0.4781 (0.4609)	Prec@1 92.969 (93.970)	Prec@5 99.609 (99.851)
2025-05-20 12:17:38 - INFO - TRAINING - Epoch: [94][80/196]	Time 0.134 (0.150)	Data 0.000 (0.014)	Loss 0.4667 (0.4627)	Prec@1 92.188 (93.842)	Prec@5 100.000 (99.836)
2025-05-20 12:17:39 - INFO - TRAINING - Epoch: [94][90/196]	Time 0.134 (0.148)	Data 0.000 (0.012)	Loss 0.4436 (0.4617)	Prec@1 94.141 (93.879)	Prec@5 100.000 (99.828)
2025-05-20 12:17:41 - INFO - TRAINING - Epoch: [94][100/196]	Time 0.134 (0.147)	Data 0.006 (0.011)	Loss 0.4317 (0.4618)	Prec@1 94.922 (93.866)	Prec@5 100.000 (99.818)
2025-05-20 12:17:42 - INFO - TRAINING - Epoch: [94][110/196]	Time 0.147 (0.146)	Data 0.000 (0.011)	Loss 0.4905 (0.4621)	Prec@1 92.969 (93.831)	Prec@5 100.000 (99.813)
2025-05-20 12:17:43 - INFO - TRAINING - Epoch: [94][120/196]	Time 0.144 (0.146)	Data 0.018 (0.010)	Loss 0.4119 (0.4611)	Prec@1 96.094 (93.866)	Prec@5 99.609 (99.813)
2025-05-20 12:17:45 - INFO - TRAINING - Epoch: [94][130/196]	Time 0.132 (0.146)	Data 0.004 (0.010)	Loss 0.4557 (0.4616)	Prec@1 92.969 (93.833)	Prec@5 100.000 (99.809)
2025-05-20 12:17:46 - INFO - TRAINING - Epoch: [94][140/196]	Time 0.134 (0.145)	Data 0.000 (0.010)	Loss 0.4308 (0.4621)	Prec@1 94.531 (93.764)	Prec@5 100.000 (99.809)
2025-05-20 12:17:48 - INFO - TRAINING - Epoch: [94][150/196]	Time 0.137 (0.144)	Data 0.000 (0.009)	Loss 0.4604 (0.4623)	Prec@1 92.969 (93.732)	Prec@5 99.609 (99.809)
2025-05-20 12:17:49 - INFO - TRAINING - Epoch: [94][160/196]	Time 0.136 (0.144)	Data 0.000 (0.009)	Loss 0.4839 (0.4625)	Prec@1 92.578 (93.711)	Prec@5 99.609 (99.816)
2025-05-20 12:17:50 - INFO - TRAINING - Epoch: [94][170/196]	Time 0.133 (0.143)	Data 0.000 (0.009)	Loss 0.4592 (0.4621)	Prec@1 93.359 (93.700)	Prec@5 100.000 (99.817)
2025-05-20 12:17:52 - INFO - TRAINING - Epoch: [94][180/196]	Time 0.133 (0.143)	Data 0.000 (0.008)	Loss 0.4678 (0.4619)	Prec@1 93.359 (93.696)	Prec@5 99.609 (99.821)
2025-05-20 12:17:53 - INFO - TRAINING - Epoch: [94][190/196]	Time 0.134 (0.142)	Data 0.000 (0.008)	Loss 0.4630 (0.4617)	Prec@1 92.969 (93.701)	Prec@5 99.609 (99.820)
2025-05-20 12:17:54 - INFO - EVALUATING - Epoch: [94][0/40]	Time 0.648 (0.648)	Data 0.579 (0.579)	Loss 0.6148 (0.6148)	Prec@1 87.109 (87.109)	Prec@5 98.438 (98.438)
2025-05-20 12:17:55 - INFO - EVALUATING - Epoch: [94][10/40]	Time 0.080 (0.164)	Data 0.000 (0.085)	Loss 0.6126 (0.6293)	Prec@1 88.672 (86.577)	Prec@5 98.047 (98.224)
2025-05-20 12:17:57 - INFO - EVALUATING - Epoch: [94][20/40]	Time 0.091 (0.138)	Data 0.010 (0.059)	Loss 0.6242 (0.6361)	Prec@1 85.938 (86.570)	Prec@5 98.828 (98.140)
2025-05-20 12:17:58 - INFO - EVALUATING - Epoch: [94][30/40]	Time 0.068 (0.126)	Data 0.000 (0.048)	Loss 0.6617 (0.6384)	Prec@1 85.156 (86.442)	Prec@5 98.047 (98.173)
2025-05-20 12:17:58 - INFO - 
 Epoch: 95	Training Loss 0.4622 	Training Prec@1 93.684 	Training Prec@5 99.822 	Validation Loss 0.6381 	Validation Prec@1 86.480 	Validation Prec@5 98.260 

2025-05-20 12:17:58 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:17:58 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:17:58 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:17:58 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:17:58 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:17:59 - INFO - TRAINING - Epoch: [95][0/196]	Time 0.953 (0.953)	Data 0.835 (0.835)	Loss 0.4677 (0.4677)	Prec@1 94.531 (94.531)	Prec@5 99.609 (99.609)
2025-05-20 12:18:01 - INFO - TRAINING - Epoch: [95][10/196]	Time 0.141 (0.220)	Data 0.009 (0.083)	Loss 0.4706 (0.4540)	Prec@1 93.750 (94.460)	Prec@5 100.000 (99.822)
2025-05-20 12:18:02 - INFO - TRAINING - Epoch: [95][20/196]	Time 0.134 (0.181)	Data 0.000 (0.047)	Loss 0.4563 (0.4536)	Prec@1 92.969 (94.141)	Prec@5 100.000 (99.814)
2025-05-20 12:18:04 - INFO - TRAINING - Epoch: [95][30/196]	Time 0.134 (0.166)	Data 0.000 (0.033)	Loss 0.4677 (0.4589)	Prec@1 92.578 (93.914)	Prec@5 99.609 (99.773)
2025-05-20 12:18:05 - INFO - TRAINING - Epoch: [95][40/196]	Time 0.134 (0.158)	Data 0.001 (0.025)	Loss 0.4346 (0.4572)	Prec@1 94.922 (93.998)	Prec@5 100.000 (99.771)
2025-05-20 12:18:06 - INFO - TRAINING - Epoch: [95][50/196]	Time 0.134 (0.154)	Data 0.000 (0.021)	Loss 0.5129 (0.4569)	Prec@1 90.625 (93.934)	Prec@5 100.000 (99.786)
2025-05-20 12:18:08 - INFO - TRAINING - Epoch: [95][60/196]	Time 0.133 (0.150)	Data 0.007 (0.018)	Loss 0.4885 (0.4583)	Prec@1 92.578 (93.949)	Prec@5 99.609 (99.757)
2025-05-20 12:18:09 - INFO - TRAINING - Epoch: [95][70/196]	Time 0.136 (0.149)	Data 0.008 (0.016)	Loss 0.4292 (0.4599)	Prec@1 96.094 (93.838)	Prec@5 100.000 (99.747)
2025-05-20 12:18:10 - INFO - TRAINING - Epoch: [95][80/196]	Time 0.146 (0.149)	Data 0.014 (0.016)	Loss 0.4582 (0.4604)	Prec@1 93.359 (93.769)	Prec@5 100.000 (99.764)
2025-05-20 12:18:12 - INFO - TRAINING - Epoch: [95][90/196]	Time 0.138 (0.148)	Data 0.008 (0.014)	Loss 0.4833 (0.4618)	Prec@1 92.578 (93.664)	Prec@5 99.609 (99.755)
2025-05-20 12:18:13 - INFO - TRAINING - Epoch: [95][100/196]	Time 0.150 (0.147)	Data 0.000 (0.013)	Loss 0.4978 (0.4630)	Prec@1 90.234 (93.580)	Prec@5 100.000 (99.760)
2025-05-20 12:18:15 - INFO - TRAINING - Epoch: [95][110/196]	Time 0.137 (0.146)	Data 0.000 (0.012)	Loss 0.5204 (0.4647)	Prec@1 90.625 (93.497)	Prec@5 99.609 (99.771)
2025-05-20 12:18:16 - INFO - TRAINING - Epoch: [95][120/196]	Time 0.134 (0.145)	Data 0.000 (0.011)	Loss 0.4474 (0.4643)	Prec@1 94.531 (93.489)	Prec@5 99.219 (99.761)
2025-05-20 12:18:17 - INFO - TRAINING - Epoch: [95][130/196]	Time 0.134 (0.144)	Data 0.000 (0.011)	Loss 0.4476 (0.4631)	Prec@1 94.922 (93.565)	Prec@5 99.219 (99.755)
2025-05-20 12:18:19 - INFO - TRAINING - Epoch: [95][140/196]	Time 0.134 (0.143)	Data 0.007 (0.010)	Loss 0.4943 (0.4639)	Prec@1 91.016 (93.539)	Prec@5 99.609 (99.759)
2025-05-20 12:18:20 - INFO - TRAINING - Epoch: [95][150/196]	Time 0.136 (0.143)	Data 0.000 (0.010)	Loss 0.4464 (0.4652)	Prec@1 94.922 (93.504)	Prec@5 99.609 (99.754)
2025-05-20 12:18:21 - INFO - TRAINING - Epoch: [95][160/196]	Time 0.147 (0.142)	Data 0.000 (0.009)	Loss 0.4672 (0.4652)	Prec@1 92.188 (93.481)	Prec@5 100.000 (99.760)
2025-05-20 12:18:23 - INFO - TRAINING - Epoch: [95][170/196]	Time 0.154 (0.143)	Data 0.016 (0.009)	Loss 0.4410 (0.4649)	Prec@1 95.703 (93.522)	Prec@5 100.000 (99.767)
2025-05-20 12:18:24 - INFO - TRAINING - Epoch: [95][180/196]	Time 0.153 (0.143)	Data 0.000 (0.009)	Loss 0.4932 (0.4651)	Prec@1 91.797 (93.515)	Prec@5 100.000 (99.771)
2025-05-20 12:18:26 - INFO - TRAINING - Epoch: [95][190/196]	Time 0.132 (0.143)	Data 0.000 (0.008)	Loss 0.4315 (0.4647)	Prec@1 93.359 (93.531)	Prec@5 100.000 (99.773)
2025-05-20 12:18:27 - INFO - EVALUATING - Epoch: [95][0/40]	Time 0.761 (0.761)	Data 0.683 (0.683)	Loss 0.6237 (0.6237)	Prec@1 86.719 (86.719)	Prec@5 99.609 (99.609)
2025-05-20 12:18:28 - INFO - EVALUATING - Epoch: [95][10/40]	Time 0.077 (0.142)	Data 0.008 (0.068)	Loss 0.6218 (0.6241)	Prec@1 87.500 (86.577)	Prec@5 98.438 (98.793)
2025-05-20 12:18:29 - INFO - EVALUATING - Epoch: [95][20/40]	Time 0.071 (0.112)	Data 0.002 (0.037)	Loss 0.6401 (0.6336)	Prec@1 85.938 (86.161)	Prec@5 99.609 (98.717)
2025-05-20 12:18:29 - INFO - EVALUATING - Epoch: [95][30/40]	Time 0.070 (0.100)	Data 0.000 (0.025)	Loss 0.6740 (0.6322)	Prec@1 82.422 (86.177)	Prec@5 99.219 (98.664)
2025-05-20 12:18:30 - INFO - 
 Epoch: 96	Training Loss 0.4643 	Training Prec@1 93.554 	Training Prec@5 99.774 	Validation Loss 0.6297 	Validation Prec@1 86.210 	Validation Prec@5 98.690 

2025-05-20 12:18:30 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:18:30 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:18:30 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:18:30 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:18:30 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:18:31 - INFO - TRAINING - Epoch: [96][0/196]	Time 1.042 (1.042)	Data 0.930 (0.930)	Loss 0.5116 (0.5116)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
2025-05-20 12:18:33 - INFO - TRAINING - Epoch: [96][10/196]	Time 0.140 (0.225)	Data 0.003 (0.088)	Loss 0.4386 (0.4732)	Prec@1 94.531 (93.324)	Prec@5 100.000 (99.929)
2025-05-20 12:18:34 - INFO - TRAINING - Epoch: [96][20/196]	Time 0.135 (0.184)	Data 0.007 (0.048)	Loss 0.4541 (0.4732)	Prec@1 94.141 (93.229)	Prec@5 99.219 (99.870)
2025-05-20 12:18:35 - INFO - TRAINING - Epoch: [96][30/196]	Time 0.141 (0.169)	Data 0.000 (0.033)	Loss 0.4529 (0.4715)	Prec@1 94.141 (93.322)	Prec@5 99.609 (99.811)
2025-05-20 12:18:37 - INFO - TRAINING - Epoch: [96][40/196]	Time 0.134 (0.163)	Data 0.000 (0.025)	Loss 0.4964 (0.4712)	Prec@1 92.188 (93.340)	Prec@5 100.000 (99.838)
2025-05-20 12:18:38 - INFO - TRAINING - Epoch: [96][50/196]	Time 0.136 (0.159)	Data 0.000 (0.022)	Loss 0.4348 (0.4684)	Prec@1 95.312 (93.543)	Prec@5 100.000 (99.831)
2025-05-20 12:18:40 - INFO - TRAINING - Epoch: [96][60/196]	Time 0.133 (0.155)	Data 0.000 (0.019)	Loss 0.4513 (0.4649)	Prec@1 94.531 (93.628)	Prec@5 99.219 (99.840)
2025-05-20 12:18:41 - INFO - TRAINING - Epoch: [96][70/196]	Time 0.135 (0.152)	Data 0.000 (0.016)	Loss 0.4511 (0.4635)	Prec@1 94.922 (93.733)	Prec@5 99.609 (99.835)
2025-05-20 12:18:42 - INFO - TRAINING - Epoch: [96][80/196]	Time 0.132 (0.150)	Data 0.003 (0.015)	Loss 0.4478 (0.4639)	Prec@1 94.531 (93.697)	Prec@5 100.000 (99.846)
2025-05-20 12:18:44 - INFO - TRAINING - Epoch: [96][90/196]	Time 0.134 (0.148)	Data 0.000 (0.013)	Loss 0.4923 (0.4631)	Prec@1 92.969 (93.703)	Prec@5 100.000 (99.845)
2025-05-20 12:18:45 - INFO - TRAINING - Epoch: [96][100/196]	Time 0.136 (0.147)	Data 0.000 (0.012)	Loss 0.5012 (0.4617)	Prec@1 91.797 (93.738)	Prec@5 99.609 (99.849)
2025-05-20 12:18:46 - INFO - TRAINING - Epoch: [96][110/196]	Time 0.132 (0.145)	Data 0.000 (0.011)	Loss 0.4716 (0.4613)	Prec@1 93.359 (93.715)	Prec@5 100.000 (99.845)
2025-05-20 12:18:48 - INFO - TRAINING - Epoch: [96][120/196]	Time 0.132 (0.144)	Data 0.005 (0.010)	Loss 0.4292 (0.4616)	Prec@1 95.703 (93.721)	Prec@5 100.000 (99.835)
2025-05-20 12:18:49 - INFO - TRAINING - Epoch: [96][130/196]	Time 0.144 (0.144)	Data 0.012 (0.010)	Loss 0.4873 (0.4632)	Prec@1 92.188 (93.625)	Prec@5 99.609 (99.830)
2025-05-20 12:18:51 - INFO - TRAINING - Epoch: [96][140/196]	Time 0.152 (0.144)	Data 0.012 (0.010)	Loss 0.4592 (0.4626)	Prec@1 92.188 (93.628)	Prec@5 100.000 (99.831)
2025-05-20 12:18:52 - INFO - TRAINING - Epoch: [96][150/196]	Time 0.133 (0.144)	Data 0.007 (0.010)	Loss 0.4393 (0.4636)	Prec@1 95.312 (93.608)	Prec@5 100.000 (99.827)
2025-05-20 12:18:53 - INFO - TRAINING - Epoch: [96][160/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.4357 (0.4632)	Prec@1 95.312 (93.614)	Prec@5 100.000 (99.825)
2025-05-20 12:18:55 - INFO - TRAINING - Epoch: [96][170/196]	Time 0.132 (0.143)	Data 0.000 (0.009)	Loss 0.4652 (0.4639)	Prec@1 93.750 (93.592)	Prec@5 100.000 (99.824)
2025-05-20 12:18:56 - INFO - TRAINING - Epoch: [96][180/196]	Time 0.132 (0.143)	Data 0.000 (0.008)	Loss 0.4811 (0.4644)	Prec@1 92.969 (93.551)	Prec@5 99.609 (99.823)
2025-05-20 12:18:57 - INFO - TRAINING - Epoch: [96][190/196]	Time 0.133 (0.142)	Data 0.000 (0.008)	Loss 0.4206 (0.4642)	Prec@1 94.922 (93.558)	Prec@5 100.000 (99.824)
2025-05-20 12:18:59 - INFO - EVALUATING - Epoch: [96][0/40]	Time 0.650 (0.650)	Data 0.582 (0.582)	Loss 0.5951 (0.5951)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
2025-05-20 12:19:00 - INFO - EVALUATING - Epoch: [96][10/40]	Time 0.073 (0.139)	Data 0.004 (0.065)	Loss 0.5925 (0.6439)	Prec@1 87.500 (85.973)	Prec@5 98.438 (98.189)
2025-05-20 12:19:00 - INFO - EVALUATING - Epoch: [96][20/40]	Time 0.077 (0.110)	Data 0.007 (0.036)	Loss 0.6230 (0.6457)	Prec@1 85.547 (85.919)	Prec@5 98.047 (98.140)
2025-05-20 12:19:01 - INFO - EVALUATING - Epoch: [96][30/40]	Time 0.069 (0.099)	Data 0.000 (0.025)	Loss 0.6502 (0.6468)	Prec@1 85.938 (86.076)	Prec@5 98.047 (98.198)
2025-05-20 12:19:02 - INFO - 
 Epoch: 97	Training Loss 0.4638 	Training Prec@1 93.576 	Training Prec@5 99.824 	Validation Loss 0.6468 	Validation Prec@1 86.180 	Validation Prec@5 98.290 

2025-05-20 12:19:02 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:19:02 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:19:02 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:19:02 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:19:02 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:19:04 - INFO - TRAINING - Epoch: [97][0/196]	Time 1.428 (1.428)	Data 1.302 (1.302)	Loss 0.4083 (0.4083)	Prec@1 97.266 (97.266)	Prec@5 100.000 (100.000)
2025-05-20 12:19:05 - INFO - TRAINING - Epoch: [97][10/196]	Time 0.148 (0.262)	Data 0.010 (0.122)	Loss 0.4337 (0.4673)	Prec@1 94.531 (93.466)	Prec@5 99.609 (99.858)
2025-05-20 12:19:06 - INFO - TRAINING - Epoch: [97][20/196]	Time 0.140 (0.203)	Data 0.000 (0.066)	Loss 0.4558 (0.4665)	Prec@1 92.578 (93.471)	Prec@5 100.000 (99.833)
2025-05-20 12:19:08 - INFO - TRAINING - Epoch: [97][30/196]	Time 0.137 (0.181)	Data 0.000 (0.046)	Loss 0.5066 (0.4634)	Prec@1 90.625 (93.674)	Prec@5 99.609 (99.811)
2025-05-20 12:19:09 - INFO - TRAINING - Epoch: [97][40/196]	Time 0.132 (0.169)	Data 0.009 (0.036)	Loss 0.4730 (0.4681)	Prec@1 92.969 (93.521)	Prec@5 99.609 (99.771)
2025-05-20 12:19:10 - INFO - TRAINING - Epoch: [97][50/196]	Time 0.134 (0.162)	Data 0.000 (0.029)	Loss 0.4777 (0.4688)	Prec@1 93.750 (93.497)	Prec@5 100.000 (99.793)
2025-05-20 12:19:12 - INFO - TRAINING - Epoch: [97][60/196]	Time 0.133 (0.158)	Data 0.000 (0.025)	Loss 0.4405 (0.4662)	Prec@1 94.531 (93.513)	Prec@5 100.000 (99.821)
2025-05-20 12:19:13 - INFO - TRAINING - Epoch: [97][70/196]	Time 0.134 (0.154)	Data 0.000 (0.021)	Loss 0.4310 (0.4661)	Prec@1 94.922 (93.590)	Prec@5 100.000 (99.813)
2025-05-20 12:19:14 - INFO - TRAINING - Epoch: [97][80/196]	Time 0.149 (0.152)	Data 0.000 (0.019)	Loss 0.4662 (0.4652)	Prec@1 92.578 (93.591)	Prec@5 100.000 (99.822)
2025-05-20 12:19:16 - INFO - TRAINING - Epoch: [97][90/196]	Time 0.148 (0.152)	Data 0.000 (0.018)	Loss 0.4874 (0.4651)	Prec@1 93.359 (93.591)	Prec@5 100.000 (99.824)
2025-05-20 12:19:17 - INFO - TRAINING - Epoch: [97][100/196]	Time 0.137 (0.151)	Data 0.000 (0.016)	Loss 0.4908 (0.4637)	Prec@1 91.797 (93.626)	Prec@5 100.000 (99.834)
2025-05-20 12:19:19 - INFO - TRAINING - Epoch: [97][110/196]	Time 0.137 (0.150)	Data 0.000 (0.015)	Loss 0.5615 (0.4648)	Prec@1 87.891 (93.525)	Prec@5 99.609 (99.831)
2025-05-20 12:19:20 - INFO - TRAINING - Epoch: [97][120/196]	Time 0.135 (0.149)	Data 0.008 (0.014)	Loss 0.4997 (0.4655)	Prec@1 92.188 (93.459)	Prec@5 100.000 (99.822)
2025-05-20 12:19:21 - INFO - TRAINING - Epoch: [97][130/196]	Time 0.134 (0.148)	Data 0.012 (0.014)	Loss 0.4914 (0.4651)	Prec@1 91.016 (93.494)	Prec@5 100.000 (99.827)
2025-05-20 12:19:23 - INFO - TRAINING - Epoch: [97][140/196]	Time 0.134 (0.147)	Data 0.000 (0.013)	Loss 0.4843 (0.4647)	Prec@1 92.969 (93.509)	Prec@5 100.000 (99.825)
2025-05-20 12:19:24 - INFO - TRAINING - Epoch: [97][150/196]	Time 0.132 (0.146)	Data 0.000 (0.012)	Loss 0.4585 (0.4644)	Prec@1 94.141 (93.553)	Prec@5 99.609 (99.822)
2025-05-20 12:19:25 - INFO - TRAINING - Epoch: [97][160/196]	Time 0.138 (0.145)	Data 0.013 (0.012)	Loss 0.4304 (0.4648)	Prec@1 95.703 (93.534)	Prec@5 100.000 (99.823)
2025-05-20 12:19:27 - INFO - TRAINING - Epoch: [97][170/196]	Time 0.148 (0.145)	Data 0.000 (0.011)	Loss 0.4439 (0.4647)	Prec@1 94.531 (93.515)	Prec@5 99.219 (99.822)
2025-05-20 12:19:28 - INFO - TRAINING - Epoch: [97][180/196]	Time 0.140 (0.145)	Data 0.000 (0.011)	Loss 0.4424 (0.4645)	Prec@1 94.922 (93.543)	Prec@5 99.609 (99.819)
2025-05-20 12:19:30 - INFO - TRAINING - Epoch: [97][190/196]	Time 0.134 (0.144)	Data 0.000 (0.010)	Loss 0.4221 (0.4651)	Prec@1 96.094 (93.507)	Prec@5 100.000 (99.812)
2025-05-20 12:19:31 - INFO - EVALUATING - Epoch: [97][0/40]	Time 0.898 (0.898)	Data 0.823 (0.823)	Loss 0.6802 (0.6802)	Prec@1 85.547 (85.547)	Prec@5 98.047 (98.047)
2025-05-20 12:19:32 - INFO - EVALUATING - Epoch: [97][10/40]	Time 0.072 (0.151)	Data 0.002 (0.078)	Loss 0.6043 (0.6480)	Prec@1 87.109 (85.866)	Prec@5 100.000 (98.615)
2025-05-20 12:19:33 - INFO - EVALUATING - Epoch: [97][20/40]	Time 0.094 (0.118)	Data 0.011 (0.043)	Loss 0.6377 (0.6484)	Prec@1 86.719 (86.031)	Prec@5 98.828 (98.419)
2025-05-20 12:19:34 - INFO - EVALUATING - Epoch: [97][30/40]	Time 0.070 (0.103)	Data 0.000 (0.030)	Loss 0.6871 (0.6484)	Prec@1 82.812 (85.824)	Prec@5 97.656 (98.526)
2025-05-20 12:19:34 - INFO - 
 Epoch: 98	Training Loss 0.4657 	Training Prec@1 93.490 	Training Prec@5 99.808 	Validation Loss 0.6457 	Validation Prec@1 85.890 	Validation Prec@5 98.540 

2025-05-20 12:19:34 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:19:34 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:19:34 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:19:34 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:19:34 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:19:35 - INFO - TRAINING - Epoch: [98][0/196]	Time 0.997 (0.997)	Data 0.860 (0.860)	Loss 0.5376 (0.5376)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
2025-05-20 12:19:37 - INFO - TRAINING - Epoch: [98][10/196]	Time 0.135 (0.223)	Data 0.005 (0.084)	Loss 0.4428 (0.4626)	Prec@1 93.750 (93.963)	Prec@5 100.000 (99.893)
2025-05-20 12:19:38 - INFO - TRAINING - Epoch: [98][20/196]	Time 0.126 (0.184)	Data 0.013 (0.047)	Loss 0.4734 (0.4552)	Prec@1 93.359 (94.048)	Prec@5 100.000 (99.926)
2025-05-20 12:19:40 - INFO - TRAINING - Epoch: [98][30/196]	Time 0.135 (0.168)	Data 0.007 (0.033)	Loss 0.4350 (0.4569)	Prec@1 94.531 (93.788)	Prec@5 100.000 (99.849)
2025-05-20 12:19:41 - INFO - TRAINING - Epoch: [98][40/196]	Time 0.144 (0.162)	Data 0.028 (0.026)	Loss 0.4339 (0.4601)	Prec@1 95.312 (93.740)	Prec@5 100.000 (99.809)
2025-05-20 12:19:42 - INFO - TRAINING - Epoch: [98][50/196]	Time 0.158 (0.159)	Data 0.007 (0.024)	Loss 0.5010 (0.4645)	Prec@1 91.797 (93.666)	Prec@5 99.609 (99.786)
2025-05-20 12:19:44 - INFO - TRAINING - Epoch: [98][60/196]	Time 0.134 (0.156)	Data 0.000 (0.021)	Loss 0.4342 (0.4649)	Prec@1 93.359 (93.648)	Prec@5 100.000 (99.795)
2025-05-20 12:19:45 - INFO - TRAINING - Epoch: [98][70/196]	Time 0.134 (0.153)	Data 0.000 (0.019)	Loss 0.4183 (0.4631)	Prec@1 94.531 (93.640)	Prec@5 100.000 (99.791)
2025-05-20 12:19:47 - INFO - TRAINING - Epoch: [98][80/196]	Time 0.135 (0.151)	Data 0.000 (0.017)	Loss 0.4227 (0.4620)	Prec@1 96.484 (93.721)	Prec@5 100.000 (99.797)
2025-05-20 12:19:48 - INFO - TRAINING - Epoch: [98][90/196]	Time 0.137 (0.149)	Data 0.000 (0.015)	Loss 0.4580 (0.4635)	Prec@1 93.750 (93.656)	Prec@5 100.000 (99.807)
2025-05-20 12:19:49 - INFO - TRAINING - Epoch: [98][100/196]	Time 0.134 (0.148)	Data 0.000 (0.014)	Loss 0.5387 (0.4629)	Prec@1 89.844 (93.622)	Prec@5 99.609 (99.803)
2025-05-20 12:19:51 - INFO - TRAINING - Epoch: [98][110/196]	Time 0.133 (0.146)	Data 0.000 (0.013)	Loss 0.4564 (0.4638)	Prec@1 94.141 (93.581)	Prec@5 99.609 (99.796)
2025-05-20 12:19:52 - INFO - TRAINING - Epoch: [98][120/196]	Time 0.137 (0.145)	Data 0.000 (0.012)	Loss 0.4343 (0.4632)	Prec@1 95.703 (93.611)	Prec@5 100.000 (99.803)
2025-05-20 12:19:53 - INFO - TRAINING - Epoch: [98][130/196]	Time 0.136 (0.145)	Data 0.000 (0.011)	Loss 0.4850 (0.4629)	Prec@1 91.797 (93.598)	Prec@5 100.000 (99.812)
2025-05-20 12:19:55 - INFO - TRAINING - Epoch: [98][140/196]	Time 0.149 (0.145)	Data 0.010 (0.011)	Loss 0.4656 (0.4626)	Prec@1 93.359 (93.625)	Prec@5 100.000 (99.806)
2025-05-20 12:19:56 - INFO - TRAINING - Epoch: [98][150/196]	Time 0.165 (0.145)	Data 0.016 (0.011)	Loss 0.4697 (0.4630)	Prec@1 93.750 (93.605)	Prec@5 99.609 (99.803)
2025-05-20 12:19:58 - INFO - TRAINING - Epoch: [98][160/196]	Time 0.132 (0.145)	Data 0.007 (0.010)	Loss 0.4057 (0.4634)	Prec@1 96.094 (93.587)	Prec@5 100.000 (99.801)
2025-05-20 12:19:59 - INFO - TRAINING - Epoch: [98][170/196]	Time 0.134 (0.144)	Data 0.000 (0.010)	Loss 0.4373 (0.4633)	Prec@1 95.312 (93.606)	Prec@5 100.000 (99.799)
2025-05-20 12:20:00 - INFO - TRAINING - Epoch: [98][180/196]	Time 0.133 (0.144)	Data 0.000 (0.010)	Loss 0.4477 (0.4629)	Prec@1 93.359 (93.616)	Prec@5 100.000 (99.799)
2025-05-20 12:20:02 - INFO - TRAINING - Epoch: [98][190/196]	Time 0.134 (0.143)	Data 0.000 (0.009)	Loss 0.4897 (0.4630)	Prec@1 93.359 (93.629)	Prec@5 100.000 (99.800)
2025-05-20 12:20:03 - INFO - EVALUATING - Epoch: [98][0/40]	Time 0.728 (0.728)	Data 0.657 (0.657)	Loss 0.6218 (0.6218)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
2025-05-20 12:20:04 - INFO - EVALUATING - Epoch: [98][10/40]	Time 0.070 (0.138)	Data 0.000 (0.064)	Loss 0.5879 (0.6318)	Prec@1 89.453 (86.719)	Prec@5 98.438 (98.686)
2025-05-20 12:20:05 - INFO - EVALUATING - Epoch: [98][20/40]	Time 0.090 (0.110)	Data 0.010 (0.036)	Loss 0.6379 (0.6367)	Prec@1 85.938 (86.682)	Prec@5 97.656 (98.382)
2025-05-20 12:20:05 - INFO - EVALUATING - Epoch: [98][30/40]	Time 0.070 (0.098)	Data 0.000 (0.025)	Loss 0.6307 (0.6386)	Prec@1 86.719 (86.492)	Prec@5 99.219 (98.488)
2025-05-20 12:20:06 - INFO - 
 Epoch: 99	Training Loss 0.4630 	Training Prec@1 93.624 	Training Prec@5 99.800 	Validation Loss 0.6396 	Validation Prec@1 86.360 	Validation Prec@5 98.580 

2025-05-20 12:20:06 - DEBUG - OPTIMIZER - setting method = Adam
2025-05-20 12:20:06 - DEBUG - OPTIMIZER - setting lr = 0.005
2025-05-20 12:20:06 - DEBUG - OPTIMIZER - setting betas = (0.9, 0.999)
2025-05-20 12:20:06 - DEBUG - OPTIMIZER - setting lr = 0.001
2025-05-20 12:20:06 - DEBUG - OPTIMIZER - setting lr = 0.0005
2025-05-20 12:20:08 - INFO - TRAINING - Epoch: [99][0/196]	Time 1.481 (1.481)	Data 1.329 (1.329)	Loss 0.4441 (0.4441)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
2025-05-20 12:20:09 - INFO - TRAINING - Epoch: [99][10/196]	Time 0.148 (0.292)	Data 0.005 (0.143)	Loss 0.4687 (0.4625)	Prec@1 93.750 (93.643)	Prec@5 99.219 (99.822)
2025-05-20 12:20:11 - INFO - TRAINING - Epoch: [99][20/196]	Time 0.146 (0.222)	Data 0.006 (0.078)	Loss 0.4406 (0.4627)	Prec@1 94.531 (93.713)	Prec@5 100.000 (99.795)
2025-05-20 12:20:12 - INFO - TRAINING - Epoch: [99][30/196]	Time 0.133 (0.194)	Data 0.001 (0.054)	Loss 0.4523 (0.4630)	Prec@1 92.969 (93.687)	Prec@5 100.000 (99.811)
2025-05-20 12:20:14 - INFO - TRAINING - Epoch: [99][40/196]	Time 0.133 (0.179)	Data 0.002 (0.042)	Loss 0.4612 (0.4629)	Prec@1 93.359 (93.664)	Prec@5 100.000 (99.829)
2025-05-20 12:20:15 - INFO - TRAINING - Epoch: [99][50/196]	Time 0.133 (0.170)	Data 0.000 (0.034)	Loss 0.4626 (0.4640)	Prec@1 93.359 (93.581)	Prec@5 100.000 (99.824)
2025-05-20 12:20:16 - INFO - TRAINING - Epoch: [99][60/196]	Time 0.133 (0.164)	Data 0.007 (0.029)	Loss 0.5006 (0.4629)	Prec@1 91.406 (93.648)	Prec@5 100.000 (99.846)
2025-05-20 12:20:18 - INFO - TRAINING - Epoch: [99][70/196]	Time 0.134 (0.160)	Data 0.000 (0.025)	Loss 0.4900 (0.4635)	Prec@1 92.188 (93.557)	Prec@5 100.000 (99.835)
2025-05-20 12:20:19 - INFO - TRAINING - Epoch: [99][80/196]	Time 0.133 (0.157)	Data 0.000 (0.023)	Loss 0.4624 (0.4641)	Prec@1 92.969 (93.523)	Prec@5 100.000 (99.812)
2025-05-20 12:20:20 - INFO - TRAINING - Epoch: [99][90/196]	Time 0.141 (0.155)	Data 0.014 (0.021)	Loss 0.4520 (0.4651)	Prec@1 92.969 (93.518)	Prec@5 100.000 (99.811)
2025-05-20 12:20:22 - INFO - TRAINING - Epoch: [99][100/196]	Time 0.141 (0.155)	Data 0.000 (0.020)	Loss 0.4856 (0.4644)	Prec@1 92.969 (93.537)	Prec@5 100.000 (99.818)
2025-05-20 12:20:23 - INFO - TRAINING - Epoch: [99][110/196]	Time 0.135 (0.153)	Data 0.000 (0.019)	Loss 0.4416 (0.4649)	Prec@1 94.141 (93.511)	Prec@5 100.000 (99.817)
2025-05-20 12:20:25 - INFO - TRAINING - Epoch: [99][120/196]	Time 0.133 (0.152)	Data 0.000 (0.017)	Loss 0.4573 (0.4641)	Prec@1 94.141 (93.566)	Prec@5 100.000 (99.819)
2025-05-20 12:20:26 - INFO - TRAINING - Epoch: [99][130/196]	Time 0.133 (0.150)	Data 0.000 (0.016)	Loss 0.4273 (0.4645)	Prec@1 95.312 (93.583)	Prec@5 100.000 (99.809)
2025-05-20 12:20:27 - INFO - TRAINING - Epoch: [99][140/196]	Time 0.138 (0.149)	Data 0.000 (0.015)	Loss 0.4712 (0.4649)	Prec@1 91.797 (93.559)	Prec@5 99.219 (99.801)
2025-05-20 12:20:29 - INFO - TRAINING - Epoch: [99][150/196]	Time 0.135 (0.149)	Data 0.000 (0.015)	Loss 0.4364 (0.4648)	Prec@1 96.094 (93.582)	Prec@5 100.000 (99.809)
2025-05-20 12:20:30 - INFO - TRAINING - Epoch: [99][160/196]	Time 0.131 (0.148)	Data 0.000 (0.014)	Loss 0.4513 (0.4652)	Prec@1 94.141 (93.558)	Prec@5 100.000 (99.806)
2025-05-20 12:20:31 - INFO - TRAINING - Epoch: [99][170/196]	Time 0.133 (0.147)	Data 0.000 (0.013)	Loss 0.4557 (0.4648)	Prec@1 94.141 (93.560)	Prec@5 100.000 (99.808)
2025-05-20 12:20:33 - INFO - TRAINING - Epoch: [99][180/196]	Time 0.134 (0.146)	Data 0.000 (0.013)	Loss 0.4513 (0.4653)	Prec@1 94.922 (93.534)	Prec@5 100.000 (99.817)
2025-05-20 12:20:34 - INFO - TRAINING - Epoch: [99][190/196]	Time 0.133 (0.146)	Data 0.000 (0.012)	Loss 0.4703 (0.4658)	Prec@1 94.141 (93.500)	Prec@5 100.000 (99.820)
2025-05-20 12:20:36 - INFO - EVALUATING - Epoch: [99][0/40]	Time 0.754 (0.754)	Data 0.680 (0.680)	Loss 0.5791 (0.5791)	Prec@1 88.672 (88.672)	Prec@5 98.047 (98.047)
2025-05-20 12:20:36 - INFO - EVALUATING - Epoch: [99][10/40]	Time 0.086 (0.138)	Data 0.014 (0.065)	Loss 0.6235 (0.6284)	Prec@1 87.109 (86.825)	Prec@5 97.656 (98.402)
2025-05-20 12:20:37 - INFO - EVALUATING - Epoch: [99][20/40]	Time 0.079 (0.108)	Data 0.006 (0.036)	Loss 0.6148 (0.6264)	Prec@1 86.719 (86.905)	Prec@5 98.438 (98.363)
2025-05-20 12:20:38 - INFO - EVALUATING - Epoch: [99][30/40]	Time 0.070 (0.098)	Data 0.000 (0.025)	Loss 0.5986 (0.6294)	Prec@1 88.672 (86.542)	Prec@5 98.828 (98.286)
2025-05-20 12:20:39 - INFO - 
 Epoch: 100	Training Loss 0.4655 	Training Prec@1 93.526 	Training Prec@5 99.818 	Validation Loss 0.6285 	Validation Prec@1 86.600 	Validation Prec@5 98.460 

